{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b43411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, classification_report\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchmetrics.regression import MeanSquaredError, MeanAbsoluteError\n",
    "from torchmetrics.classification import BinaryAUROC, BinaryAveragePrecision\n",
    "from torchmetrics.classification import BinaryAccuracy, BinaryPrecision, BinaryRecall, BinaryF1Score\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a431bcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_MAKER = \"yeonseo\"\n",
    "if DATA_MAKER == \"jiseock\":\n",
    "    DATA_PATH = \"../dataset/jiseock\"\n",
    "else:\n",
    "    DATA_PATH = \"../dataset/yeonseo\"\n",
    "\n",
    "X_train = pd.read_csv(f\"{DATA_PATH}/X_train.csv\")\n",
    "y_train = pd.read_csv(f\"{DATA_PATH}/y_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87c42fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>나이</th>\n",
       "      <th>성별 (M:1,F:2)</th>\n",
       "      <th>Rt:1,Lt:2</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Tearsize (AP,cm)</th>\n",
       "      <th>Tearsize (ML)</th>\n",
       "      <th>Tearsize (retraction)</th>\n",
       "      <th>흡연여부 (비흡연:1,흡연:2)</th>\n",
       "      <th>흡연여부 (비흡연:1,흡연:2) Missing flag</th>\n",
       "      <th>...</th>\n",
       "      <th>6M Goutallier (ISP)</th>\n",
       "      <th>6M Goutallier (TM)</th>\n",
       "      <th>Pre Goutallier (SSP) Missing flag</th>\n",
       "      <th>Pre Goutallier (SSC) Missing flag</th>\n",
       "      <th>Pre Goutallier (ISP) Missing flag</th>\n",
       "      <th>Pre Goutallier (TM) Missing flag</th>\n",
       "      <th>6M Goutallier (SSP) Missing flag</th>\n",
       "      <th>6M Goutallier (SSC) Missing flag</th>\n",
       "      <th>6M Goutallier (ISP) Missing flag</th>\n",
       "      <th>6M Goutallier (TM) Missing flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.695229</td>\n",
       "      <td>-1.339841</td>\n",
       "      <td>-0.666718</td>\n",
       "      <td>-0.098987</td>\n",
       "      <td>-0.102130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230515</td>\n",
       "      <td>-0.202217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.478311</td>\n",
       "      <td>-0.456936</td>\n",
       "      <td>-0.666718</td>\n",
       "      <td>-0.568482</td>\n",
       "      <td>-0.554538</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230515</td>\n",
       "      <td>-0.202217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.268850</td>\n",
       "      <td>1.325693</td>\n",
       "      <td>-0.666718</td>\n",
       "      <td>-0.098987</td>\n",
       "      <td>-0.102130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230515</td>\n",
       "      <td>-0.202217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.132850</td>\n",
       "      <td>0.678229</td>\n",
       "      <td>-0.666718</td>\n",
       "      <td>-0.685856</td>\n",
       "      <td>-0.667640</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230515</td>\n",
       "      <td>-0.202217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.454209</td>\n",
       "      <td>-0.498979</td>\n",
       "      <td>-0.666718</td>\n",
       "      <td>-0.685856</td>\n",
       "      <td>-0.667640</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230515</td>\n",
       "      <td>-0.202217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8441</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.551094</td>\n",
       "      <td>0.699066</td>\n",
       "      <td>0.760231</td>\n",
       "      <td>1.485044</td>\n",
       "      <td>1.424252</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.588878</td>\n",
       "      <td>3.359851</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8442</th>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.354153</td>\n",
       "      <td>0.306110</td>\n",
       "      <td>1.107813</td>\n",
       "      <td>1.032095</td>\n",
       "      <td>0.987788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230515</td>\n",
       "      <td>-0.202217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8443</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456311</td>\n",
       "      <td>0.204000</td>\n",
       "      <td>-0.184000</td>\n",
       "      <td>-0.218529</td>\n",
       "      <td>-0.217322</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230515</td>\n",
       "      <td>-0.202217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8444</th>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.144777</td>\n",
       "      <td>0.987286</td>\n",
       "      <td>1.074749</td>\n",
       "      <td>1.028890</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230515</td>\n",
       "      <td>-0.202217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8445</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.397248</td>\n",
       "      <td>0.260919</td>\n",
       "      <td>0.424636</td>\n",
       "      <td>0.605061</td>\n",
       "      <td>0.576295</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230515</td>\n",
       "      <td>-0.202217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8446 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      나이  성별 (M:1,F:2)  Rt:1,Lt:2    Height    Weight  Tearsize (AP,cm)  \\\n",
       "0     83             2          2 -0.695229 -1.339841         -0.666718   \n",
       "1     55             2          1 -0.478311 -0.456936         -0.666718   \n",
       "2     70             2          2  0.268850  1.325693         -0.666718   \n",
       "3     75             2          1 -0.132850  0.678229         -0.666718   \n",
       "4     57             2          1 -0.454209 -0.498979         -0.666718   \n",
       "...   ..           ...        ...       ...       ...               ...   \n",
       "8441  72             1          1  0.551094  0.699066          0.760231   \n",
       "8442  59             2          1  0.354153  0.306110          1.107813   \n",
       "8443  59             1          1  0.456311  0.204000         -0.184000   \n",
       "8444  73             2          2  0.000185  0.144777          0.987286   \n",
       "8445  63             1          1  0.397248  0.260919          0.424636   \n",
       "\n",
       "      Tearsize (ML)  Tearsize (retraction)  흡연여부 (비흡연:1,흡연:2)  \\\n",
       "0         -0.098987              -0.102130                1.0   \n",
       "1         -0.568482              -0.554538                1.0   \n",
       "2         -0.098987              -0.102130                1.0   \n",
       "3         -0.685856              -0.667640                1.0   \n",
       "4         -0.685856              -0.667640                1.0   \n",
       "...             ...                    ...                ...   \n",
       "8441       1.485044               1.424252                1.0   \n",
       "8442       1.032095               0.987788                1.0   \n",
       "8443      -0.218529              -0.217322                1.0   \n",
       "8444       1.074749               1.028890                1.0   \n",
       "8445       0.605061               0.576295                1.0   \n",
       "\n",
       "      흡연여부 (비흡연:1,흡연:2) Missing flag  ...  6M Goutallier (ISP)  \\\n",
       "0                                1.0  ...            -0.230515   \n",
       "1                                1.0  ...            -0.230515   \n",
       "2                                1.0  ...            -0.230515   \n",
       "3                                1.0  ...            -0.230515   \n",
       "4                                1.0  ...            -0.230515   \n",
       "...                              ...  ...                  ...   \n",
       "8441                             1.0  ...             2.588878   \n",
       "8442                             1.0  ...            -0.230515   \n",
       "8443                             1.0  ...            -0.230515   \n",
       "8444                             1.0  ...            -0.230515   \n",
       "8445                             1.0  ...            -0.230515   \n",
       "\n",
       "      6M Goutallier (TM)  Pre Goutallier (SSP) Missing flag  \\\n",
       "0              -0.202217                                1.0   \n",
       "1              -0.202217                                1.0   \n",
       "2              -0.202217                                1.0   \n",
       "3              -0.202217                                1.0   \n",
       "4              -0.202217                                1.0   \n",
       "...                  ...                                ...   \n",
       "8441            3.359851                                1.0   \n",
       "8442           -0.202217                                1.0   \n",
       "8443           -0.202217                                1.0   \n",
       "8444           -0.202217                                1.0   \n",
       "8445           -0.202217                                1.0   \n",
       "\n",
       "      Pre Goutallier (SSC) Missing flag  Pre Goutallier (ISP) Missing flag  \\\n",
       "0                                   1.0                                1.0   \n",
       "1                                   1.0                                1.0   \n",
       "2                                   1.0                                1.0   \n",
       "3                                   1.0                                1.0   \n",
       "4                                   1.0                                1.0   \n",
       "...                                 ...                                ...   \n",
       "8441                                1.0                                1.0   \n",
       "8442                                1.0                                1.0   \n",
       "8443                                1.0                                1.0   \n",
       "8444                                1.0                                1.0   \n",
       "8445                                1.0                                1.0   \n",
       "\n",
       "      Pre Goutallier (TM) Missing flag  6M Goutallier (SSP) Missing flag  \\\n",
       "0                                  1.0                               1.0   \n",
       "1                                  1.0                               1.0   \n",
       "2                                  1.0                               1.0   \n",
       "3                                  1.0                               1.0   \n",
       "4                                  1.0                               1.0   \n",
       "...                                ...                               ...   \n",
       "8441                               1.0                               1.0   \n",
       "8442                               1.0                               1.0   \n",
       "8443                               1.0                               1.0   \n",
       "8444                               1.0                               1.0   \n",
       "8445                               1.0                               1.0   \n",
       "\n",
       "      6M Goutallier (SSC) Missing flag  6M Goutallier (ISP) Missing flag  \\\n",
       "0                                  1.0                               1.0   \n",
       "1                                  1.0                               1.0   \n",
       "2                                  1.0                               1.0   \n",
       "3                                  1.0                               1.0   \n",
       "4                                  1.0                               1.0   \n",
       "...                                ...                               ...   \n",
       "8441                               1.0                               1.0   \n",
       "8442                               1.0                               1.0   \n",
       "8443                               1.0                               1.0   \n",
       "8444                               1.0                               1.0   \n",
       "8445                               1.0                               1.0   \n",
       "\n",
       "      6M Goutallier (TM) Missing flag  \n",
       "0                                 1.0  \n",
       "1                                 1.0  \n",
       "2                                 1.0  \n",
       "3                                 1.0  \n",
       "4                                 1.0  \n",
       "...                               ...  \n",
       "8441                              1.0  \n",
       "8442                              1.0  \n",
       "8443                              1.0  \n",
       "8444                              1.0  \n",
       "8445                              1.0  \n",
       "\n",
       "[8446 rows x 96 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa0fd065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POD 6M retear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8441</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8442</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8443</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8444</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8445</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8446 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      POD 6M retear\n",
       "0                 0\n",
       "1                 0\n",
       "2                 0\n",
       "3                 0\n",
       "4                 0\n",
       "...             ...\n",
       "8441              1\n",
       "8442              1\n",
       "8443              1\n",
       "8444              1\n",
       "8445              1\n",
       "\n",
       "[8446 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfb8c992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['나이',\n",
       " '성별 (M:1,F:2)',\n",
       " 'Rt:1,Lt:2',\n",
       " 'Height',\n",
       " 'Weight',\n",
       " 'Tearsize (AP,cm)',\n",
       " 'Tearsize (ML)',\n",
       " 'Tearsize (retraction)',\n",
       " '흡연여부 (비흡연:1,흡연:2)',\n",
       " '흡연여부 (비흡연:1,흡연:2) Missing flag',\n",
       " 'Hospital 0',\n",
       " 'Hospital 1',\n",
       " 'Hospital 2',\n",
       " 'Hospital 3',\n",
       " 'Hospital 4',\n",
       " 'Hospital 5',\n",
       " 'Hospital 6',\n",
       " 'Disease 0',\n",
       " 'Disease 1',\n",
       " 'Disease 2',\n",
       " 'Disease 3',\n",
       " 'Disease 4',\n",
       " 'Disease 5',\n",
       " 'Disease 6',\n",
       " 'Disease 7',\n",
       " '0M ASES',\n",
       " '0M CSS',\n",
       " '0M ERabd',\n",
       " '0M ERside',\n",
       " '0M FF',\n",
       " '0M IR',\n",
       " '0M KSS',\n",
       " '0M MMTgrade',\n",
       " '0M MMTsec',\n",
       " '0M VAS(activity)',\n",
       " '0M VAS(resting)',\n",
       " '0M add',\n",
       " '2M ERabd',\n",
       " '2M ERside',\n",
       " '2M FF',\n",
       " '2M IR',\n",
       " '2M MMTgrade',\n",
       " '2M MMTsec',\n",
       " '2M add',\n",
       " '3M ASES',\n",
       " '3M CSS',\n",
       " '3M ERabd',\n",
       " '3M ERside',\n",
       " '3M FF',\n",
       " '3M IR',\n",
       " '3M KSS',\n",
       " '3M MMTgrade',\n",
       " '3M MMTsec',\n",
       " '3M VAS(activity)',\n",
       " '3M VAS(resting)',\n",
       " '3M add',\n",
       " '4M ASES',\n",
       " '4M CSS',\n",
       " '4M ERabd',\n",
       " '4M ERside',\n",
       " '4M FF',\n",
       " '4M IR',\n",
       " '4M KSS',\n",
       " '4M MMTgrade',\n",
       " '4M MMTsec',\n",
       " '4M VAS(activity)',\n",
       " '4M VAS(resting)',\n",
       " '4M add',\n",
       " '6M ASES',\n",
       " '6M CSS',\n",
       " '6M ERabd',\n",
       " '6M ERside',\n",
       " '6M FF',\n",
       " '6M IR',\n",
       " '6M KSS',\n",
       " '6M MMTgrade',\n",
       " '6M MMTsec',\n",
       " '6M VAS(activity)',\n",
       " '6M VAS(resting)',\n",
       " '6M add',\n",
       " 'Pre Goutallier (SSP)',\n",
       " 'Pre Goutallier (SSC)',\n",
       " 'Pre Goutallier (ISP)',\n",
       " 'Pre Goutallier (TM)',\n",
       " '6M Goutallier (SSP)',\n",
       " '6M Goutallier (SSC)',\n",
       " '6M Goutallier (ISP)',\n",
       " '6M Goutallier (TM)',\n",
       " 'Pre Goutallier (SSP) Missing flag',\n",
       " 'Pre Goutallier (SSC) Missing flag',\n",
       " 'Pre Goutallier (ISP) Missing flag',\n",
       " 'Pre Goutallier (TM) Missing flag',\n",
       " '6M Goutallier (SSP) Missing flag',\n",
       " '6M Goutallier (SSC) Missing flag',\n",
       " '6M Goutallier (ISP) Missing flag',\n",
       " '6M Goutallier (TM) Missing flag']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = list(X_train.columns)\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44e04aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['나이',\n",
       " '성별 (M:1,F:2)',\n",
       " 'Rt:1,Lt:2',\n",
       " 'Height',\n",
       " 'Weight',\n",
       " 'Tearsize (AP,cm)',\n",
       " 'Tearsize (ML)',\n",
       " 'Tearsize (retraction)',\n",
       " '흡연여부 (비흡연:1,흡연:2)',\n",
       " '흡연여부 (비흡연:1,흡연:2) Missing flag',\n",
       " 'Hospital 0',\n",
       " 'Hospital 1',\n",
       " 'Hospital 2',\n",
       " 'Hospital 3',\n",
       " 'Hospital 4',\n",
       " 'Hospital 5',\n",
       " 'Hospital 6',\n",
       " 'Disease 0',\n",
       " 'Disease 1',\n",
       " 'Disease 2',\n",
       " 'Disease 3',\n",
       " 'Disease 4',\n",
       " 'Disease 5',\n",
       " 'Disease 6',\n",
       " 'Disease 7']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_columns = columns[:25]\n",
    "\n",
    "# static 데이터 칼럼\n",
    "static_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7862c6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0M ASES', '0M CSS', '0M ERabd', '0M ERside', '0M FF', '0M IR', '0M KSS', '0M MMTgrade', '0M MMTsec', '0M VAS(activity)', '0M VAS(resting)', '0M add']\n",
      "['2M ERabd', '2M ERside', '2M FF', '2M IR', '2M MMTgrade', '2M MMTsec', '2M add']\n",
      "['3M ASES', '3M CSS', '3M ERabd', '3M ERside', '3M FF', '3M IR', '3M KSS', '3M MMTgrade', '3M MMTsec', '3M VAS(activity)', '3M VAS(resting)', '3M add']\n",
      "['4M ASES', '4M CSS', '4M ERabd', '4M ERside', '4M FF', '4M IR', '4M KSS', '4M MMTgrade', '4M MMTsec', '4M VAS(activity)', '4M VAS(resting)', '4M add']\n",
      "['6M ASES', '6M CSS', '6M ERabd', '6M ERside', '6M FF', '6M IR', '6M KSS', '6M MMTgrade', '6M MMTsec', '6M VAS(activity)', '6M VAS(resting)', '6M add']\n"
     ]
    }
   ],
   "source": [
    "seq_columns = columns[25:-16]\n",
    "\n",
    "# 시퀀셜 데이터 관련 칼럼들\n",
    "seq_columns_0M = seq_columns[:12]\n",
    "seq_columns_2M = seq_columns[12:19]\n",
    "seq_columns_3M = seq_columns[19:31]\n",
    "seq_columns_4M = seq_columns[31:43]\n",
    "seq_columns_6M = seq_columns[43:]\n",
    "\n",
    "seq_columns_all = [seq_columns_0M, seq_columns_2M, seq_columns_3M, seq_columns_4M, seq_columns_6M]\n",
    "\n",
    "for seq_col in seq_columns_all:\n",
    "    print(seq_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86ed4d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pre Goutallier (SSP)', 'Pre Goutallier (SSC)', 'Pre Goutallier (ISP)', 'Pre Goutallier (TM)']\n",
      "['6M Goutallier (SSP)', '6M Goutallier (SSC)', '6M Goutallier (ISP)', '6M Goutallier (TM)']\n",
      "['Pre Goutallier (SSP) Missing flag', 'Pre Goutallier (SSC) Missing flag', 'Pre Goutallier (ISP) Missing flag', 'Pre Goutallier (TM) Missing flag']\n",
      "['6M Goutallier (SSP) Missing flag', '6M Goutallier (SSC) Missing flag', '6M Goutallier (ISP) Missing flag', '6M Goutallier (TM) Missing flag']\n"
     ]
    }
   ],
   "source": [
    "goutallier_columns = columns[-16:]\n",
    "\n",
    "# goutaliar 관련 칼럼들\n",
    "goutallier_columns_0M = goutallier_columns [:4]\n",
    "goutallier_columns_6M = goutallier_columns [4:8]\n",
    "goutallier_columns_0M_missing = goutallier_columns [8:12]\n",
    "goutallier_columns_6M_missing = goutallier_columns [12:]\n",
    "\n",
    "print(goutallier_columns_0M)\n",
    "print(goutallier_columns_6M)\n",
    "print(goutallier_columns_0M_missing)\n",
    "print(goutallier_columns_6M_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a663ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns) == len(static_columns) + len(seq_columns) + len(goutallier_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cb95606",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column = \"POD 6M retear\"\n",
    "output_columns = [\"6M ASES\", \"6M CSS\", \"6M KSS\", \"6M VAS(activity)\", \"6M VAS(resting)\"]\n",
    "input_columns = static_columns + [column for column in seq_columns if column not in output_columns] + goutallier_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "690b23f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6M ASES', '6M CSS', '6M KSS', '6M VAS(activity)', '6M VAS(resting)']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23baa483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['나이',\n",
       " '성별 (M:1,F:2)',\n",
       " 'Rt:1,Lt:2',\n",
       " 'Height',\n",
       " 'Weight',\n",
       " 'Tearsize (AP,cm)',\n",
       " 'Tearsize (ML)',\n",
       " 'Tearsize (retraction)',\n",
       " '흡연여부 (비흡연:1,흡연:2)',\n",
       " '흡연여부 (비흡연:1,흡연:2) Missing flag',\n",
       " 'Hospital 0',\n",
       " 'Hospital 1',\n",
       " 'Hospital 2',\n",
       " 'Hospital 3',\n",
       " 'Hospital 4',\n",
       " 'Hospital 5',\n",
       " 'Hospital 6',\n",
       " 'Disease 0',\n",
       " 'Disease 1',\n",
       " 'Disease 2',\n",
       " 'Disease 3',\n",
       " 'Disease 4',\n",
       " 'Disease 5',\n",
       " 'Disease 6',\n",
       " 'Disease 7',\n",
       " '0M ASES',\n",
       " '0M CSS',\n",
       " '0M ERabd',\n",
       " '0M ERside',\n",
       " '0M FF',\n",
       " '0M IR',\n",
       " '0M KSS',\n",
       " '0M MMTgrade',\n",
       " '0M MMTsec',\n",
       " '0M VAS(activity)',\n",
       " '0M VAS(resting)',\n",
       " '0M add',\n",
       " '2M ERabd',\n",
       " '2M ERside',\n",
       " '2M FF',\n",
       " '2M IR',\n",
       " '2M MMTgrade',\n",
       " '2M MMTsec',\n",
       " '2M add',\n",
       " '3M ASES',\n",
       " '3M CSS',\n",
       " '3M ERabd',\n",
       " '3M ERside',\n",
       " '3M FF',\n",
       " '3M IR',\n",
       " '3M KSS',\n",
       " '3M MMTgrade',\n",
       " '3M MMTsec',\n",
       " '3M VAS(activity)',\n",
       " '3M VAS(resting)',\n",
       " '3M add',\n",
       " '4M ASES',\n",
       " '4M CSS',\n",
       " '4M ERabd',\n",
       " '4M ERside',\n",
       " '4M FF',\n",
       " '4M IR',\n",
       " '4M KSS',\n",
       " '4M MMTgrade',\n",
       " '4M MMTsec',\n",
       " '4M VAS(activity)',\n",
       " '4M VAS(resting)',\n",
       " '4M add',\n",
       " '6M ERabd',\n",
       " '6M ERside',\n",
       " '6M FF',\n",
       " '6M IR',\n",
       " '6M MMTgrade',\n",
       " '6M MMTsec',\n",
       " '6M add',\n",
       " 'Pre Goutallier (SSP)',\n",
       " 'Pre Goutallier (SSC)',\n",
       " 'Pre Goutallier (ISP)',\n",
       " 'Pre Goutallier (TM)',\n",
       " '6M Goutallier (SSP)',\n",
       " '6M Goutallier (SSC)',\n",
       " '6M Goutallier (ISP)',\n",
       " '6M Goutallier (TM)',\n",
       " 'Pre Goutallier (SSP) Missing flag',\n",
       " 'Pre Goutallier (SSC) Missing flag',\n",
       " 'Pre Goutallier (ISP) Missing flag',\n",
       " 'Pre Goutallier (TM) Missing flag',\n",
       " '6M Goutallier (SSP) Missing flag',\n",
       " '6M Goutallier (SSC) Missing flag',\n",
       " '6M Goutallier (ISP) Missing flag',\n",
       " '6M Goutallier (TM) Missing flag']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80ba6ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>나이</th>\n",
       "      <th>성별 (M:1,F:2)</th>\n",
       "      <th>Rt:1,Lt:2</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Tearsize (AP,cm)</th>\n",
       "      <th>Tearsize (ML)</th>\n",
       "      <th>Tearsize (retraction)</th>\n",
       "      <th>흡연여부 (비흡연:1,흡연:2)</th>\n",
       "      <th>흡연여부 (비흡연:1,흡연:2) Missing flag</th>\n",
       "      <th>...</th>\n",
       "      <th>6M Goutallier (ISP)</th>\n",
       "      <th>6M Goutallier (TM)</th>\n",
       "      <th>Pre Goutallier (SSP) Missing flag</th>\n",
       "      <th>Pre Goutallier (SSC) Missing flag</th>\n",
       "      <th>Pre Goutallier (ISP) Missing flag</th>\n",
       "      <th>Pre Goutallier (TM) Missing flag</th>\n",
       "      <th>6M Goutallier (SSP) Missing flag</th>\n",
       "      <th>6M Goutallier (SSC) Missing flag</th>\n",
       "      <th>6M Goutallier (ISP) Missing flag</th>\n",
       "      <th>6M Goutallier (TM) Missing flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.695229</td>\n",
       "      <td>-1.339841</td>\n",
       "      <td>-0.666718</td>\n",
       "      <td>-0.098987</td>\n",
       "      <td>-0.102130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230515</td>\n",
       "      <td>-0.202217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.478311</td>\n",
       "      <td>-0.456936</td>\n",
       "      <td>-0.666718</td>\n",
       "      <td>-0.568482</td>\n",
       "      <td>-0.554538</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230515</td>\n",
       "      <td>-0.202217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.268850</td>\n",
       "      <td>1.325693</td>\n",
       "      <td>-0.666718</td>\n",
       "      <td>-0.098987</td>\n",
       "      <td>-0.102130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230515</td>\n",
       "      <td>-0.202217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.132850</td>\n",
       "      <td>0.678229</td>\n",
       "      <td>-0.666718</td>\n",
       "      <td>-0.685856</td>\n",
       "      <td>-0.667640</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230515</td>\n",
       "      <td>-0.202217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.454209</td>\n",
       "      <td>-0.498979</td>\n",
       "      <td>-0.666718</td>\n",
       "      <td>-0.685856</td>\n",
       "      <td>-0.667640</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230515</td>\n",
       "      <td>-0.202217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8441</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.551094</td>\n",
       "      <td>0.699066</td>\n",
       "      <td>0.760231</td>\n",
       "      <td>1.485044</td>\n",
       "      <td>1.424252</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.588878</td>\n",
       "      <td>3.359851</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8442</th>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.354153</td>\n",
       "      <td>0.306110</td>\n",
       "      <td>1.107813</td>\n",
       "      <td>1.032095</td>\n",
       "      <td>0.987788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230515</td>\n",
       "      <td>-0.202217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8443</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456311</td>\n",
       "      <td>0.204000</td>\n",
       "      <td>-0.184000</td>\n",
       "      <td>-0.218529</td>\n",
       "      <td>-0.217322</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230515</td>\n",
       "      <td>-0.202217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8444</th>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.144777</td>\n",
       "      <td>0.987286</td>\n",
       "      <td>1.074749</td>\n",
       "      <td>1.028890</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230515</td>\n",
       "      <td>-0.202217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8445</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.397248</td>\n",
       "      <td>0.260919</td>\n",
       "      <td>0.424636</td>\n",
       "      <td>0.605061</td>\n",
       "      <td>0.576295</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230515</td>\n",
       "      <td>-0.202217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8446 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      나이  성별 (M:1,F:2)  Rt:1,Lt:2    Height    Weight  Tearsize (AP,cm)  \\\n",
       "0     83             2          2 -0.695229 -1.339841         -0.666718   \n",
       "1     55             2          1 -0.478311 -0.456936         -0.666718   \n",
       "2     70             2          2  0.268850  1.325693         -0.666718   \n",
       "3     75             2          1 -0.132850  0.678229         -0.666718   \n",
       "4     57             2          1 -0.454209 -0.498979         -0.666718   \n",
       "...   ..           ...        ...       ...       ...               ...   \n",
       "8441  72             1          1  0.551094  0.699066          0.760231   \n",
       "8442  59             2          1  0.354153  0.306110          1.107813   \n",
       "8443  59             1          1  0.456311  0.204000         -0.184000   \n",
       "8444  73             2          2  0.000185  0.144777          0.987286   \n",
       "8445  63             1          1  0.397248  0.260919          0.424636   \n",
       "\n",
       "      Tearsize (ML)  Tearsize (retraction)  흡연여부 (비흡연:1,흡연:2)  \\\n",
       "0         -0.098987              -0.102130                1.0   \n",
       "1         -0.568482              -0.554538                1.0   \n",
       "2         -0.098987              -0.102130                1.0   \n",
       "3         -0.685856              -0.667640                1.0   \n",
       "4         -0.685856              -0.667640                1.0   \n",
       "...             ...                    ...                ...   \n",
       "8441       1.485044               1.424252                1.0   \n",
       "8442       1.032095               0.987788                1.0   \n",
       "8443      -0.218529              -0.217322                1.0   \n",
       "8444       1.074749               1.028890                1.0   \n",
       "8445       0.605061               0.576295                1.0   \n",
       "\n",
       "      흡연여부 (비흡연:1,흡연:2) Missing flag  ...  6M Goutallier (ISP)  \\\n",
       "0                                1.0  ...            -0.230515   \n",
       "1                                1.0  ...            -0.230515   \n",
       "2                                1.0  ...            -0.230515   \n",
       "3                                1.0  ...            -0.230515   \n",
       "4                                1.0  ...            -0.230515   \n",
       "...                              ...  ...                  ...   \n",
       "8441                             1.0  ...             2.588878   \n",
       "8442                             1.0  ...            -0.230515   \n",
       "8443                             1.0  ...            -0.230515   \n",
       "8444                             1.0  ...            -0.230515   \n",
       "8445                             1.0  ...            -0.230515   \n",
       "\n",
       "      6M Goutallier (TM)  Pre Goutallier (SSP) Missing flag  \\\n",
       "0              -0.202217                                1.0   \n",
       "1              -0.202217                                1.0   \n",
       "2              -0.202217                                1.0   \n",
       "3              -0.202217                                1.0   \n",
       "4              -0.202217                                1.0   \n",
       "...                  ...                                ...   \n",
       "8441            3.359851                                1.0   \n",
       "8442           -0.202217                                1.0   \n",
       "8443           -0.202217                                1.0   \n",
       "8444           -0.202217                                1.0   \n",
       "8445           -0.202217                                1.0   \n",
       "\n",
       "      Pre Goutallier (SSC) Missing flag  Pre Goutallier (ISP) Missing flag  \\\n",
       "0                                   1.0                                1.0   \n",
       "1                                   1.0                                1.0   \n",
       "2                                   1.0                                1.0   \n",
       "3                                   1.0                                1.0   \n",
       "4                                   1.0                                1.0   \n",
       "...                                 ...                                ...   \n",
       "8441                                1.0                                1.0   \n",
       "8442                                1.0                                1.0   \n",
       "8443                                1.0                                1.0   \n",
       "8444                                1.0                                1.0   \n",
       "8445                                1.0                                1.0   \n",
       "\n",
       "      Pre Goutallier (TM) Missing flag  6M Goutallier (SSP) Missing flag  \\\n",
       "0                                  1.0                               1.0   \n",
       "1                                  1.0                               1.0   \n",
       "2                                  1.0                               1.0   \n",
       "3                                  1.0                               1.0   \n",
       "4                                  1.0                               1.0   \n",
       "...                                ...                               ...   \n",
       "8441                               1.0                               1.0   \n",
       "8442                               1.0                               1.0   \n",
       "8443                               1.0                               1.0   \n",
       "8444                               1.0                               1.0   \n",
       "8445                               1.0                               1.0   \n",
       "\n",
       "      6M Goutallier (SSC) Missing flag  6M Goutallier (ISP) Missing flag  \\\n",
       "0                                  1.0                               1.0   \n",
       "1                                  1.0                               1.0   \n",
       "2                                  1.0                               1.0   \n",
       "3                                  1.0                               1.0   \n",
       "4                                  1.0                               1.0   \n",
       "...                                ...                               ...   \n",
       "8441                               1.0                               1.0   \n",
       "8442                               1.0                               1.0   \n",
       "8443                               1.0                               1.0   \n",
       "8444                               1.0                               1.0   \n",
       "8445                               1.0                               1.0   \n",
       "\n",
       "      6M Goutallier (TM) Missing flag  \n",
       "0                                 1.0  \n",
       "1                                 1.0  \n",
       "2                                 1.0  \n",
       "3                                 1.0  \n",
       "4                                 1.0  \n",
       "...                               ...  \n",
       "8441                              1.0  \n",
       "8442                              1.0  \n",
       "8443                              1.0  \n",
       "8444                              1.0  \n",
       "8445                              1.0  \n",
       "\n",
       "[8446 rows x 91 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[input_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2525c5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POD 6M retear</th>\n",
       "      <th>6M ASES</th>\n",
       "      <th>6M CSS</th>\n",
       "      <th>6M KSS</th>\n",
       "      <th>6M VAS(activity)</th>\n",
       "      <th>6M VAS(resting)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.511552</td>\n",
       "      <td>-0.729534</td>\n",
       "      <td>-0.111492</td>\n",
       "      <td>0.184973</td>\n",
       "      <td>0.195548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.358745</td>\n",
       "      <td>1.458271</td>\n",
       "      <td>-0.058845</td>\n",
       "      <td>0.184973</td>\n",
       "      <td>0.195548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.358204</td>\n",
       "      <td>-0.323929</td>\n",
       "      <td>-0.608714</td>\n",
       "      <td>0.184973</td>\n",
       "      <td>0.195548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.328331</td>\n",
       "      <td>-0.732607</td>\n",
       "      <td>-0.614563</td>\n",
       "      <td>0.184973</td>\n",
       "      <td>0.195548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.324348</td>\n",
       "      <td>-0.628133</td>\n",
       "      <td>-0.202746</td>\n",
       "      <td>0.184973</td>\n",
       "      <td>0.195548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8441</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.860095</td>\n",
       "      <td>-2.156255</td>\n",
       "      <td>0.763181</td>\n",
       "      <td>1.654141</td>\n",
       "      <td>1.660600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8442</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.555922</td>\n",
       "      <td>0.420936</td>\n",
       "      <td>-0.739752</td>\n",
       "      <td>2.078198</td>\n",
       "      <td>2.083469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8443</th>\n",
       "      <td>1</td>\n",
       "      <td>0.093389</td>\n",
       "      <td>0.519937</td>\n",
       "      <td>-0.697858</td>\n",
       "      <td>0.485109</td>\n",
       "      <td>0.494844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8444</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.978093</td>\n",
       "      <td>-0.573777</td>\n",
       "      <td>-0.302896</td>\n",
       "      <td>1.882890</td>\n",
       "      <td>1.888709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8445</th>\n",
       "      <td>1</td>\n",
       "      <td>0.679789</td>\n",
       "      <td>0.450485</td>\n",
       "      <td>0.989927</td>\n",
       "      <td>-0.208925</td>\n",
       "      <td>-0.197246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8446 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      POD 6M retear   6M ASES    6M CSS    6M KSS  6M VAS(activity)  \\\n",
       "0                 0 -0.511552 -0.729534 -0.111492          0.184973   \n",
       "1                 0  0.358745  1.458271 -0.058845          0.184973   \n",
       "2                 0 -0.358204 -0.323929 -0.608714          0.184973   \n",
       "3                 0 -0.328331 -0.732607 -0.614563          0.184973   \n",
       "4                 0 -0.324348 -0.628133 -0.202746          0.184973   \n",
       "...             ...       ...       ...       ...               ...   \n",
       "8441              1 -1.860095 -2.156255  0.763181          1.654141   \n",
       "8442              1 -0.555922  0.420936 -0.739752          2.078198   \n",
       "8443              1  0.093389  0.519937 -0.697858          0.485109   \n",
       "8444              1 -0.978093 -0.573777 -0.302896          1.882890   \n",
       "8445              1  0.679789  0.450485  0.989927         -0.208925   \n",
       "\n",
       "      6M VAS(resting)  \n",
       "0            0.195548  \n",
       "1            0.195548  \n",
       "2            0.195548  \n",
       "3            0.195548  \n",
       "4            0.195548  \n",
       "...               ...  \n",
       "8441         1.660600  \n",
       "8442         2.083469  \n",
       "8443         0.494844  \n",
       "8444         1.888709  \n",
       "8445        -0.197246  \n",
       "\n",
       "[8446 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([y_train, X_train[output_columns]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4260e764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(split):\n",
    "  assert split in [\"train\", \"test\"]\n",
    "  \n",
    "  X_file_name = f\"{DATA_PATH}/X_{split}.csv\"\n",
    "  y_file_name = f\"{DATA_PATH}/y_{split}.csv\"\n",
    "\n",
    "  X = pd.read_csv(X_file_name)\n",
    "  y = pd.read_csv(y_file_name)\n",
    "  \n",
    "  # static 데이터\n",
    "  X_static_tensor = torch.tensor(X[static_columns].to_numpy(), dtype=torch.float32)\n",
    "\n",
    "  # 시기별 sequential 데이터\n",
    "  X_seq_tensor_0M = torch.tensor(X[seq_columns_0M].to_numpy(), dtype=torch.float32)\n",
    "  X_seq_tensor_2M = torch.tensor(X[seq_columns_2M].to_numpy(), dtype=torch.float32)\n",
    "  X_seq_tensor_3M = torch.tensor(X[seq_columns_3M].to_numpy(), dtype=torch.float32)\n",
    "  X_seq_tensor_4M = torch.tensor(X[seq_columns_4M].to_numpy(), dtype=torch.float32)\n",
    "  X_seq_tensor_6M = torch.tensor(X[seq_columns_6M].to_numpy(), dtype=torch.float32)\n",
    "  \n",
    "  #0M, 6M goutalier 데이터\n",
    "  X_goutalier_tensor_0M = torch.tensor(X[goutallier_columns_0M + goutallier_columns_0M_missing].to_numpy(), dtype=torch.float32)\n",
    "  X_goutalier_tensor_6M = torch.tensor(X[goutallier_columns_6M + goutallier_columns_6M_missing].to_numpy(), dtype=torch.float32)\n",
    "  \n",
    "  # 전체 인풋 데이터\n",
    "  X_tensor = torch.tensor(X[input_columns].to_numpy(), dtype=torch.float32)\n",
    "  \n",
    "  # 6M 예측 데이터\n",
    "  y_tensor = torch.tensor(pd.concat([y, X[output_columns]], axis=1).to_numpy(), dtype=torch.float32)\n",
    "\n",
    "  return TensorDataset(X_tensor, X_static_tensor, X_seq_tensor_0M, X_seq_tensor_2M, X_seq_tensor_3M, X_seq_tensor_4M, X_seq_tensor_6M, X_goutalier_tensor_0M, X_goutalier_tensor_6M, y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4f36ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 데이터셋 (참고용)\n",
    "trainset = get_dataset(\"train\")\n",
    "testset = get_dataset(\"test\")\n",
    "\n",
    "print(\"기존 데이터셋 구조 확인\")\n",
    "print(f\"Trainset size: {len(trainset)}\")\n",
    "print(f\"Testset size: {len(testset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5cc6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특징 크기 확인\n",
    "static_features = len(static_columns)\n",
    "seq_features_0M = len(seq_columns_0M)\n",
    "seq_features_2M = len(seq_columns_2M)\n",
    "seq_features_3M = len(seq_columns_3M)\n",
    "seq_features_4M = len(seq_columns_4M)\n",
    "seq_features_6M = len(seq_columns_6M)\n",
    "goutallier_features_0M = len(goutallier_columns_0M) + len(goutallier_columns_0M_missing)\n",
    "goutallier_features_6M = len(goutallier_columns_6M) + len(goutallier_columns_6M_missing)\n",
    "\n",
    "print(f\"Static features: {static_features}\")\n",
    "print(f\"0M features: {seq_features_0M}, 2M features: {seq_features_2M}, 3M features: {seq_features_3M}\")\n",
    "print(f\"4M features: {seq_features_4M}, 6M features: {seq_features_6M}\")\n",
    "print(f\"0M Goutallier features: {goutallier_features_0M}, 6M Goutallier features: {goutallier_features_6M}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04a3f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 모델별 데이터셋 생성 함수\n",
    "\n",
    "def get_dataset_model1(split):\n",
    "    \"\"\"Model 1: static + 0M + 0M_goutallier → 2M\"\"\"\n",
    "    assert split in [\"train\", \"test\"]\n",
    "    \n",
    "    X_file_name = f\"{DATA_PATH}/X_{split}.csv\"\n",
    "    y_file_name = f\"{DATA_PATH}/y_{split}.csv\"\n",
    "    \n",
    "    X = pd.read_csv(X_file_name)\n",
    "    y = pd.read_csv(y_file_name)\n",
    "    \n",
    "    # 입력: static + 0M + 0M_goutallier\n",
    "    X_static = torch.tensor(X[static_columns].to_numpy(), dtype=torch.float32)\n",
    "    X_0M = torch.tensor(X[seq_columns_0M].to_numpy(), dtype=torch.float32)\n",
    "    X_0M_goutallier = torch.tensor(X[goutallier_columns_0M + goutallier_columns_0M_missing].to_numpy(), dtype=torch.float32)\n",
    "    \n",
    "    # 출력: 2M\n",
    "    y_2M = torch.tensor(X[seq_columns_2M].to_numpy(), dtype=torch.float32)\n",
    "    \n",
    "    return TensorDataset(X_static, X_0M, X_0M_goutallier, y_2M)\n",
    "\n",
    "def get_dataset_model2(split):\n",
    "    \"\"\"Model 2: static + 0M + 2M + 0M_goutallier → 3M\"\"\"\n",
    "    assert split in [\"train\", \"test\"]\n",
    "    \n",
    "    X_file_name = f\"{DATA_PATH}/X_{split}.csv\"\n",
    "    y_file_name = f\"{DATA_PATH}/y_{split}.csv\"\n",
    "    \n",
    "    X = pd.read_csv(X_file_name)\n",
    "    y = pd.read_csv(y_file_name)\n",
    "    \n",
    "    # 입력: static + 0M + 2M + 0M_goutallier\n",
    "    X_static = torch.tensor(X[static_columns].to_numpy(), dtype=torch.float32)\n",
    "    X_0M = torch.tensor(X[seq_columns_0M].to_numpy(), dtype=torch.float32)\n",
    "    X_2M = torch.tensor(X[seq_columns_2M].to_numpy(), dtype=torch.float32)\n",
    "    X_0M_goutallier = torch.tensor(X[goutallier_columns_0M + goutallier_columns_0M_missing].to_numpy(), dtype=torch.float32)\n",
    "    \n",
    "    # 출력: 3M\n",
    "    y_3M = torch.tensor(X[seq_columns_3M].to_numpy(), dtype=torch.float32)\n",
    "    \n",
    "    return TensorDataset(X_static, X_0M, X_2M, X_0M_goutallier, y_3M)\n",
    "\n",
    "def get_dataset_model3(split):\n",
    "    \"\"\"Model 3: static + 0M + 2M + 3M + 0M_goutallier → 4M\"\"\"\n",
    "    assert split in [\"train\", \"test\"]\n",
    "    \n",
    "    X_file_name = f\"{DATA_PATH}/X_{split}.csv\"\n",
    "    y_file_name = f\"{DATA_PATH}/y_{split}.csv\"\n",
    "    \n",
    "    X = pd.read_csv(X_file_name)\n",
    "    y = pd.read_csv(y_file_name)\n",
    "    \n",
    "    # 입력: static + 0M + 2M + 3M + 0M_goutallier\n",
    "    X_static = torch.tensor(X[static_columns].to_numpy(), dtype=torch.float32)\n",
    "    X_0M = torch.tensor(X[seq_columns_0M].to_numpy(), dtype=torch.float32)\n",
    "    X_2M = torch.tensor(X[seq_columns_2M].to_numpy(), dtype=torch.float32)\n",
    "    X_3M = torch.tensor(X[seq_columns_3M].to_numpy(), dtype=torch.float32)\n",
    "    X_0M_goutallier = torch.tensor(X[goutallier_columns_0M + goutallier_columns_0M_missing].to_numpy(), dtype=torch.float32)\n",
    "    \n",
    "    # 출력: 4M\n",
    "    y_4M = torch.tensor(X[seq_columns_4M].to_numpy(), dtype=torch.float32)\n",
    "    \n",
    "    return TensorDataset(X_static, X_0M, X_2M, X_3M, X_0M_goutallier, y_4M)\n",
    "\n",
    "def get_dataset_model4(split):\n",
    "    \"\"\"Model 4: static + 0M + 2M + 3M + 4M + 0M_goutallier → 6M + y + 6M_goutallier\"\"\"\n",
    "    assert split in [\"train\", \"test\"]\n",
    "    \n",
    "    X_file_name = f\"{DATA_PATH}/X_{split}.csv\"\n",
    "    y_file_name = f\"{DATA_PATH}/y_{split}.csv\"\n",
    "    \n",
    "    X = pd.read_csv(X_file_name)\n",
    "    y = pd.read_csv(y_file_name)\n",
    "    \n",
    "    # 입력: static + 0M + 2M + 3M + 4M + 0M_goutallier\n",
    "    X_static = torch.tensor(X[static_columns].to_numpy(), dtype=torch.float32)\n",
    "    X_0M = torch.tensor(X[seq_columns_0M].to_numpy(), dtype=torch.float32)\n",
    "    X_2M = torch.tensor(X[seq_columns_2M].to_numpy(), dtype=torch.float32)\n",
    "    X_3M = torch.tensor(X[seq_columns_3M].to_numpy(), dtype=torch.float32)\n",
    "    X_4M = torch.tensor(X[seq_columns_4M].to_numpy(), dtype=torch.float32)\n",
    "    X_0M_goutallier = torch.tensor(X[goutallier_columns_0M + goutallier_columns_0M_missing].to_numpy(), dtype=torch.float32)\n",
    "    \n",
    "    # 출력: 6M + y + 6M_goutallier\n",
    "    y_6M = torch.tensor(X[seq_columns_6M].to_numpy(), dtype=torch.float32)\n",
    "    y_label = torch.tensor(y[label_column].to_numpy(), dtype=torch.float32).unsqueeze(1)\n",
    "    y_6M_goutallier = torch.tensor(X[goutallier_columns_6M + goutallier_columns_6M_missing].to_numpy(), dtype=torch.float32)\n",
    "    \n",
    "    # 결합: [6M features (12) + y (1) + 6M_goutallier (8)] = 21\n",
    "    y_combined = torch.cat([y_6M, y_label, y_6M_goutallier], dim=1)\n",
    "    \n",
    "    return TensorDataset(X_static, X_0M, X_2M, X_3M, X_4M, X_0M_goutallier, y_combined)\n",
    "\n",
    "# 데이터셋 생성\n",
    "trainset_model1 = get_dataset_model1(\"train\")\n",
    "testset_model1 = get_dataset_model1(\"test\")\n",
    "trainset_model2 = get_dataset_model2(\"train\")\n",
    "testset_model2 = get_dataset_model2(\"test\")\n",
    "trainset_model3 = get_dataset_model3(\"train\")\n",
    "testset_model3 = get_dataset_model3(\"test\")\n",
    "trainset_model4 = get_dataset_model4(\"train\")\n",
    "testset_model4 = get_dataset_model4(\"test\")\n",
    "\n",
    "print(f\"Model 1 - Train: {len(trainset_model1)}, Test: {len(testset_model1)}\")\n",
    "print(f\"Model 2 - Train: {len(trainset_model2)}, Test: {len(testset_model2)}\")\n",
    "print(f\"Model 3 - Train: {len(trainset_model3)}, Test: {len(testset_model3)}\")\n",
    "print(f\"Model 4 - Train: {len(trainset_model4)}, Test: {len(testset_model4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7afc3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: static + 0M + 0M_goutallier → 2M\n",
    "class SequentialMLP1(L.LightningModule):\n",
    "    def __init__(self, static_features, seq_0M_features, goutallier_0M_features, out_features_2M):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 입력 인코더\n",
    "        self.static_encoder = nn.Sequential(\n",
    "            nn.Linear(static_features, 64),\n",
    "            nn.LayerNorm(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        \n",
    "        self.seq_0M_encoder = nn.Sequential(\n",
    "            nn.Linear(seq_0M_features, 64),\n",
    "            nn.LayerNorm(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        \n",
    "        self.goutallier_0M_encoder = nn.Sequential(\n",
    "            nn.Linear(goutallier_0M_features, 32),\n",
    "            nn.LayerNorm(32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        \n",
    "        # 특징 결합 후 출력\n",
    "        feat_dim = 64 + 64 + 32\n",
    "        self.output_head = nn.Sequential(\n",
    "            nn.Linear(feat_dim, 128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, out_features_2M)\n",
    "        )\n",
    "        \n",
    "        self.train_mse = MeanSquaredError()\n",
    "        self.val_mse = MeanSquaredError()\n",
    "        \n",
    "    def forward(self, x_static, x_0M, x_0M_goutallier):\n",
    "        static_feat = self.static_encoder(x_static)\n",
    "        seq_0M_feat = self.seq_0M_encoder(x_0M)\n",
    "        goutallier_0M_feat = self.goutallier_0M_encoder(x_0M_goutallier)\n",
    "        \n",
    "        combined = torch.cat([static_feat, seq_0M_feat, goutallier_0M_feat], dim=1)\n",
    "        output = self.output_head(combined)\n",
    "        return output\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_static, x_0M, x_0M_goutallier, y_2M = batch\n",
    "        pred_2M = self.forward(x_static, x_0M, x_0M_goutallier)\n",
    "        loss = F.mse_loss(pred_2M, y_2M)\n",
    "        \n",
    "        self.log(\"train/loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.train_mse.update(pred_2M, y_2M)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_static, x_0M, x_0M_goutallier, y_2M = batch\n",
    "        pred_2M = self.forward(x_static, x_0M, x_0M_goutallier)\n",
    "        loss = F.mse_loss(pred_2M, y_2M)\n",
    "        \n",
    "        self.log(\"val/loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.val_mse.update(pred_2M, y_2M)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        self.log(\"train/mse\", self.train_mse.compute())\n",
    "        self.train_mse.reset()\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        self.log(\"val/mse\", self.val_mse.compute())\n",
    "        self.val_mse.reset()\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=5e-6, weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd7f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: static + 0M + 2M + 0M_goutallier → 3M\n",
    "class SequentialMLP2(L.LightningModule):\n",
    "    def __init__(self, static_features, seq_0M_features, seq_2M_features, goutallier_0M_features, out_features_3M):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 입력 인코더\n",
    "        self.static_encoder = nn.Sequential(\n",
    "            nn.Linear(static_features, 64),\n",
    "            nn.LayerNorm(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        \n",
    "        self.seq_0M_encoder = nn.Sequential(\n",
    "            nn.Linear(seq_0M_features, 64),\n",
    "            nn.LayerNorm(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        \n",
    "        self.seq_2M_encoder = nn.Sequential(\n",
    "            nn.Linear(seq_2M_features, 32),\n",
    "            nn.LayerNorm(32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        \n",
    "        self.goutallier_0M_encoder = nn.Sequential(\n",
    "            nn.Linear(goutallier_0M_features, 32),\n",
    "            nn.LayerNorm(32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        \n",
    "        # 특징 결합 후 출력\n",
    "        feat_dim = 64 + 64 + 32 + 32\n",
    "        self.output_head = nn.Sequential(\n",
    "            nn.Linear(feat_dim, 128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, out_features_3M)\n",
    "        )\n",
    "        \n",
    "        self.train_mse = MeanSquaredError()\n",
    "        self.val_mse = MeanSquaredError()\n",
    "        \n",
    "    def forward(self, x_static, x_0M, x_2M, x_0M_goutallier):\n",
    "        static_feat = self.static_encoder(x_static)\n",
    "        seq_0M_feat = self.seq_0M_encoder(x_0M)\n",
    "        seq_2M_feat = self.seq_2M_encoder(x_2M)\n",
    "        goutallier_0M_feat = self.goutallier_0M_encoder(x_0M_goutallier)\n",
    "        \n",
    "        combined = torch.cat([static_feat, seq_0M_feat, seq_2M_feat, goutallier_0M_feat], dim=1)\n",
    "        output = self.output_head(combined)\n",
    "        return output\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_static, x_0M, x_2M, x_0M_goutallier, y_3M = batch\n",
    "        pred_3M = self.forward(x_static, x_0M, x_2M, x_0M_goutallier)\n",
    "        loss = F.mse_loss(pred_3M, y_3M)\n",
    "        \n",
    "        self.log(\"train/loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.train_mse.update(pred_3M, y_3M)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_static, x_0M, x_2M, x_0M_goutallier, y_3M = batch\n",
    "        pred_3M = self.forward(x_static, x_0M, x_2M, x_0M_goutallier)\n",
    "        loss = F.mse_loss(pred_3M, y_3M)\n",
    "        \n",
    "        self.log(\"val/loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.val_mse.update(pred_3M, y_3M)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        self.log(\"train/mse\", self.train_mse.compute())\n",
    "        self.train_mse.reset()\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        self.log(\"val/mse\", self.val_mse.compute())\n",
    "        self.val_mse.reset()\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=5e-6, weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8664e224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: static + 0M + 2M + 3M + 0M_goutallier → 4M\n",
    "class SequentialMLP3(L.LightningModule):\n",
    "    def __init__(self, static_features, seq_0M_features, seq_2M_features, seq_3M_features, goutallier_0M_features, out_features_4M):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 입력 인코더\n",
    "        self.static_encoder = nn.Sequential(\n",
    "            nn.Linear(static_features, 64),\n",
    "            nn.LayerNorm(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        \n",
    "        self.seq_0M_encoder = nn.Sequential(\n",
    "            nn.Linear(seq_0M_features, 64),\n",
    "            nn.LayerNorm(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        \n",
    "        self.seq_2M_encoder = nn.Sequential(\n",
    "            nn.Linear(seq_2M_features, 32),\n",
    "            nn.LayerNorm(32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        \n",
    "        self.seq_3M_encoder = nn.Sequential(\n",
    "            nn.Linear(seq_3M_features, 64),\n",
    "            nn.LayerNorm(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        \n",
    "        self.goutallier_0M_encoder = nn.Sequential(\n",
    "            nn.Linear(goutallier_0M_features, 32),\n",
    "            nn.LayerNorm(32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        \n",
    "        # 특징 결합 후 출력\n",
    "        feat_dim = 64 + 64 + 32 + 64 + 32\n",
    "        self.output_head = nn.Sequential(\n",
    "            nn.Linear(feat_dim, 128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, out_features_4M)\n",
    "        )\n",
    "        \n",
    "        self.train_mse = MeanSquaredError()\n",
    "        self.val_mse = MeanSquaredError()\n",
    "        \n",
    "    def forward(self, x_static, x_0M, x_2M, x_3M, x_0M_goutallier):\n",
    "        static_feat = self.static_encoder(x_static)\n",
    "        seq_0M_feat = self.seq_0M_encoder(x_0M)\n",
    "        seq_2M_feat = self.seq_2M_encoder(x_2M)\n",
    "        seq_3M_feat = self.seq_3M_encoder(x_3M)\n",
    "        goutallier_0M_feat = self.goutallier_0M_encoder(x_0M_goutallier)\n",
    "        \n",
    "        combined = torch.cat([static_feat, seq_0M_feat, seq_2M_feat, seq_3M_feat, goutallier_0M_feat], dim=1)\n",
    "        output = self.output_head(combined)\n",
    "        return output\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_static, x_0M, x_2M, x_3M, x_0M_goutallier, y_4M = batch\n",
    "        pred_4M = self.forward(x_static, x_0M, x_2M, x_3M, x_0M_goutallier)\n",
    "        loss = F.mse_loss(pred_4M, y_4M)\n",
    "        \n",
    "        self.log(\"train/loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.train_mse.update(pred_4M, y_4M)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_static, x_0M, x_2M, x_3M, x_0M_goutallier, y_4M = batch\n",
    "        pred_4M = self.forward(x_static, x_0M, x_2M, x_3M, x_0M_goutallier)\n",
    "        loss = F.mse_loss(pred_4M, y_4M)\n",
    "        \n",
    "        self.log(\"val/loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.val_mse.update(pred_4M, y_4M)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        self.log(\"train/mse\", self.train_mse.compute())\n",
    "        self.train_mse.reset()\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        self.log(\"val/mse\", self.val_mse.compute())\n",
    "        self.val_mse.reset()\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=5e-6, weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b0622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4: static + 0M + 2M + 3M + 4M + 0M_goutallier → 6M + y + 6M_goutallier\n",
    "class SequentialMLP4(L.LightningModule):\n",
    "    def __init__(self, static_features, seq_0M_features, seq_2M_features, seq_3M_features, seq_4M_features, goutallier_0M_features, out_features_total):\n",
    "        super().__init__()\n",
    "        self.register_buffer('pos_weight', torch.tensor([1.0]))\n",
    "        \n",
    "        # 입력 인코더\n",
    "        self.static_encoder = nn.Sequential(\n",
    "            nn.Linear(static_features, 64),\n",
    "            nn.LayerNorm(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        \n",
    "        self.seq_0M_encoder = nn.Sequential(\n",
    "            nn.Linear(seq_0M_features, 64),\n",
    "            nn.LayerNorm(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        \n",
    "        self.seq_2M_encoder = nn.Sequential(\n",
    "            nn.Linear(seq_2M_features, 32),\n",
    "            nn.LayerNorm(32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        \n",
    "        self.seq_3M_encoder = nn.Sequential(\n",
    "            nn.Linear(seq_3M_features, 64),\n",
    "            nn.LayerNorm(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        \n",
    "        self.seq_4M_encoder = nn.Sequential(\n",
    "            nn.Linear(seq_4M_features, 64),\n",
    "            nn.LayerNorm(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        \n",
    "        self.goutallier_0M_encoder = nn.Sequential(\n",
    "            nn.Linear(goutallier_0M_features, 32),\n",
    "            nn.LayerNorm(32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        \n",
    "        # 특징 결합\n",
    "        feat_dim = 64 + 64 + 32 + 64 + 64 + 32\n",
    "        \n",
    "        # 분류 헤드 (y 예측)\n",
    "        self.clshead = nn.Sequential(\n",
    "            nn.Linear(feat_dim, 128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "        # 회귀 헤드 (6M + 6M_goutallier 예측)\n",
    "        self.reghead = nn.Sequential(\n",
    "            nn.Linear(feat_dim, 256),\n",
    "            nn.LayerNorm(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, out_features_total - 1)  # y 제외한 나머지\n",
    "        )\n",
    "        \n",
    "        self.train_roc = BinaryAUROC()\n",
    "        self.val_roc = BinaryAUROC()\n",
    "        self.val_ap = BinaryAveragePrecision()\n",
    "        self.train_mse = MeanSquaredError()\n",
    "        self.val_mse = MeanSquaredError()\n",
    "        \n",
    "    def forward(self, x_static, x_0M, x_2M, x_3M, x_4M, x_0M_goutallier):\n",
    "        static_feat = self.static_encoder(x_static)\n",
    "        seq_0M_feat = self.seq_0M_encoder(x_0M)\n",
    "        seq_2M_feat = self.seq_2M_encoder(x_2M)\n",
    "        seq_3M_feat = self.seq_3M_encoder(x_3M)\n",
    "        seq_4M_feat = self.seq_4M_encoder(x_4M)\n",
    "        goutallier_0M_feat = self.goutallier_0M_encoder(x_0M_goutallier)\n",
    "        \n",
    "        combined = torch.cat([static_feat, seq_0M_feat, seq_2M_feat, seq_3M_feat, seq_4M_feat, goutallier_0M_feat], dim=1)\n",
    "        \n",
    "        logits = self.clshead(combined)\n",
    "        regs = self.reghead(combined)\n",
    "        \n",
    "        # 결합: [logits (1) + regs (20)] = 21\n",
    "        output = torch.cat([logits, regs], dim=1)\n",
    "        return logits, regs, output\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_static, x_0M, x_2M, x_3M, x_4M, x_0M_goutallier, y_combined = batch\n",
    "        y_label = y_combined[:, :1]\n",
    "        y_reg = y_combined[:, 1:]\n",
    "        \n",
    "        logits, regs, _ = self.forward(x_static, x_0M, x_2M, x_3M, x_4M, x_0M_goutallier)\n",
    "        \n",
    "        clf_loss = F.binary_cross_entropy_with_logits(logits, y_label, pos_weight=self.pos_weight)\n",
    "        reg_loss = F.smooth_l1_loss(regs, y_reg)\n",
    "        loss = clf_loss + reg_loss\n",
    "        \n",
    "        self.log(\"train/loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train/clf_loss\", clf_loss)\n",
    "        self.log(\"train/reg_loss\", reg_loss)\n",
    "        \n",
    "        probs = logits.sigmoid().flatten()\n",
    "        targets = y_label.flatten().to(torch.int)\n",
    "        self.train_roc.update(probs, targets)\n",
    "        self.train_mse.update(regs, y_reg)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_static, x_0M, x_2M, x_3M, x_4M, x_0M_goutallier, y_combined = batch\n",
    "        y_label = y_combined[:, :1]\n",
    "        y_reg = y_combined[:, 1:]\n",
    "        \n",
    "        logits, regs, _ = self.forward(x_static, x_0M, x_2M, x_3M, x_4M, x_0M_goutallier)\n",
    "        \n",
    "        clf_loss = F.binary_cross_entropy_with_logits(logits, y_label, pos_weight=self.pos_weight)\n",
    "        reg_loss = F.smooth_l1_loss(regs, y_reg)\n",
    "        loss = clf_loss + reg_loss\n",
    "        \n",
    "        self.log(\"val/loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val/clf_loss\", clf_loss)\n",
    "        self.log(\"val/reg_loss\", reg_loss)\n",
    "        \n",
    "        probs = logits.sigmoid().flatten()\n",
    "        targets = y_label.flatten().to(torch.int)\n",
    "        self.val_roc.update(probs, targets)\n",
    "        self.val_ap.update(probs, targets)\n",
    "        self.val_mse.update(regs, y_reg)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        self.log(\"train/roc\", self.train_roc.compute())\n",
    "        self.log(\"train/mse\", self.train_mse.compute())\n",
    "        self.train_roc.reset()\n",
    "        self.train_mse.reset()\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        self.log(\"val/roc\", self.val_roc.compute())\n",
    "        self.log(\"val/ap\", self.val_ap.compute())\n",
    "        self.log(\"val/mse\", self.val_mse.compute())\n",
    "        self.val_roc.reset()\n",
    "        self.val_ap.reset()\n",
    "        self.val_mse.reset()\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=5e-6, weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58740df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 모델 학습\n",
    "batch_size = 64\n",
    "max_epochs = 24\n",
    "\n",
    "# Model 1 학습\n",
    "print(\"=\" * 80)\n",
    "print(\"Model 1 학습 시작: static + 0M + 0M_goutallier → 2M\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "model1 = SequentialMLP1(\n",
    "    static_features=static_features,\n",
    "    seq_0M_features=seq_features_0M,\n",
    "    goutallier_0M_features=goutallier_features_0M,\n",
    "    out_features_2M=seq_features_2M\n",
    ")\n",
    "\n",
    "trainloader1 = DataLoader(trainset_model1, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "valloader1 = DataLoader(testset_model1, batch_size=batch_size)\n",
    "\n",
    "trainer1 = L.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    callbacks=[ModelCheckpoint(monitor='val/loss', mode='min', save_top_k=1, filename='model1-best')]\n",
    ")\n",
    "\n",
    "trainer1.fit(model1, trainloader1, valloader1)\n",
    "print(\"Model 1 학습 완료\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c8f3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2 학습\n",
    "print(\"=\" * 80)\n",
    "print(\"Model 2 학습 시작: static + 0M + 2M + 0M_goutallier → 3M\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "model2 = SequentialMLP2(\n",
    "    static_features=static_features,\n",
    "    seq_0M_features=seq_features_0M,\n",
    "    seq_2M_features=seq_features_2M,\n",
    "    goutallier_0M_features=goutallier_features_0M,\n",
    "    out_features_3M=seq_features_3M\n",
    ")\n",
    "\n",
    "trainloader2 = DataLoader(trainset_model2, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "valloader2 = DataLoader(testset_model2, batch_size=batch_size)\n",
    "\n",
    "trainer2 = L.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    callbacks=[ModelCheckpoint(monitor='val/loss', mode='min', save_top_k=1, filename='model2-best')]\n",
    ")\n",
    "\n",
    "trainer2.fit(model2, trainloader2, valloader2)\n",
    "print(\"Model 2 학습 완료\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b992a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3 학습\n",
    "print(\"=\" * 80)\n",
    "print(\"Model 3 학습 시작: static + 0M + 2M + 3M + 0M_goutallier → 4M\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "model3 = SequentialMLP3(\n",
    "    static_features=static_features,\n",
    "    seq_0M_features=seq_features_0M,\n",
    "    seq_2M_features=seq_features_2M,\n",
    "    seq_3M_features=seq_features_3M,\n",
    "    goutallier_0M_features=goutallier_features_0M,\n",
    "    out_features_4M=seq_features_4M\n",
    ")\n",
    "\n",
    "trainloader3 = DataLoader(trainset_model3, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "valloader3 = DataLoader(testset_model3, batch_size=batch_size)\n",
    "\n",
    "trainer3 = L.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    callbacks=[ModelCheckpoint(monitor='val/loss', mode='min', save_top_k=1, filename='model3-best')]\n",
    ")\n",
    "\n",
    "trainer3.fit(model3, trainloader3, valloader3)\n",
    "print(\"Model 3 학습 완료\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff8c22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4 학습\n",
    "print(\"=\" * 80)\n",
    "print(\"Model 4 학습 시작: static + 0M + 2M + 3M + 4M + 0M_goutallier → 6M + y + 6M_goutallier\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "model4 = SequentialMLP4(\n",
    "    static_features=static_features,\n",
    "    seq_0M_features=seq_features_0M,\n",
    "    seq_2M_features=seq_features_2M,\n",
    "    seq_3M_features=seq_features_3M,\n",
    "    seq_4M_features=seq_features_4M,\n",
    "    goutallier_0M_features=goutallier_features_0M,\n",
    "    out_features_total=seq_features_6M + 1 + goutallier_features_6M  # 12 + 1 + 8 = 21\n",
    ")\n",
    "\n",
    "trainloader4 = DataLoader(trainset_model4, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "valloader4 = DataLoader(testset_model4, batch_size=batch_size)\n",
    "\n",
    "trainer4 = L.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    callbacks=[ModelCheckpoint(monitor='val/roc', mode='max', save_top_k=1, filename='model4-best')]\n",
    ")\n",
    "\n",
    "trainer4.fit(model4, trainloader4, valloader4)\n",
    "print(\"Model 4 학습 완료\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df475c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연결된 시계열 모델 클래스 (4개 모델을 순차적으로 실행)\n",
    "class SequentialModel(nn.Module):\n",
    "    \"\"\"0M 입력만으로 6M 예측하는 연결된 시계열 모델\"\"\"\n",
    "    def __init__(self, model1, model2, model3, model4):\n",
    "        super().__init__()\n",
    "        self.model1 = model1\n",
    "        self.model2 = model2\n",
    "        self.model3 = model3\n",
    "        self.model4 = model4\n",
    "        \n",
    "        # 평가 모드로 설정\n",
    "        self.model1.eval()\n",
    "        self.model2.eval()\n",
    "        self.model3.eval()\n",
    "        self.model4.eval()\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def forward(self, x_static, x_0M, x_0M_goutallier):\n",
    "        \"\"\"\n",
    "        입력: static, 0M, 0M_goutallier\n",
    "        출력: 6M features, y (logits), 6M_goutallier\n",
    "        \"\"\"\n",
    "        # Model 1: static + 0M + 0M_goutallier → 2M\n",
    "        pred_2M = self.model1(x_static, x_0M, x_0M_goutallier)\n",
    "        \n",
    "        # Model 2: static + 0M + 2M + 0M_goutallier → 3M\n",
    "        pred_3M = self.model2(x_static, x_0M, pred_2M, x_0M_goutallier)\n",
    "        \n",
    "        # Model 3: static + 0M + 2M + 3M + 0M_goutallier → 4M\n",
    "        pred_4M = self.model3(x_static, x_0M, pred_2M, pred_3M, x_0M_goutallier)\n",
    "        \n",
    "        # Model 4: static + 0M + 2M + 3M + 4M + 0M_goutallier → 6M + y + 6M_goutallier\n",
    "        logits, regs, output = self.model4(x_static, x_0M, pred_2M, pred_3M, pred_4M, x_0M_goutallier)\n",
    "        \n",
    "        # 출력 분리: [6M (12) + y (1) + 6M_goutallier (8)]\n",
    "        pred_6M = regs[:, :seq_features_6M]\n",
    "        pred_y_logits = logits\n",
    "        pred_6M_goutallier = regs[:, seq_features_6M:]\n",
    "        \n",
    "        return {\n",
    "            'pred_2M': pred_2M,\n",
    "            'pred_3M': pred_3M,\n",
    "            'pred_4M': pred_4M,\n",
    "            'pred_6M': pred_6M,\n",
    "            'pred_y_logits': pred_y_logits,\n",
    "            'pred_6M_goutallier': pred_6M_goutallier,\n",
    "            'output': output\n",
    "        }\n",
    "\n",
    "# 연결된 모델 생성\n",
    "sequential_model = SequentialModel(model1, model2, model3, model4)\n",
    "print(\"연결된 시계열 모델 생성 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097d69bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연결된 모델 평가 함수\n",
    "@torch.no_grad()\n",
    "def evaluate_sequential_model(sequential_model, testset_model1):\n",
    "    \"\"\"0M 입력만으로 전체 시계열 예측 평가\"\"\"\n",
    "    sequential_model.eval()\n",
    "    \n",
    "    # Model 1 데이터셋에서 static, 0M, 0M_goutallier 추출\n",
    "    all_pred_2M = []\n",
    "    all_pred_3M = []\n",
    "    all_pred_4M = []\n",
    "    all_pred_6M = []\n",
    "    all_pred_y_logits = []\n",
    "    all_pred_6M_goutallier = []\n",
    "    \n",
    "    # 실제 값들 (참고용)\n",
    "    all_true_2M = []\n",
    "    all_true_3M = []\n",
    "    all_true_4M = []\n",
    "    all_true_6M = []\n",
    "    all_true_y = []\n",
    "    all_true_6M_goutallier = []\n",
    "    \n",
    "    for i in range(len(testset_model1)):\n",
    "        x_static, x_0M, x_0M_goutallier, y_2M = testset_model1[i]\n",
    "        x_static = x_static.unsqueeze(0)\n",
    "        x_0M = x_0M.unsqueeze(0)\n",
    "        x_0M_goutallier = x_0M_goutallier.unsqueeze(0)\n",
    "        \n",
    "        # 예측\n",
    "        predictions = sequential_model(x_static, x_0M, x_0M_goutallier)\n",
    "        \n",
    "        all_pred_2M.append(predictions['pred_2M'])\n",
    "        all_pred_3M.append(predictions['pred_3M'])\n",
    "        all_pred_4M.append(predictions['pred_4M'])\n",
    "        all_pred_6M.append(predictions['pred_6M'])\n",
    "        all_pred_y_logits.append(predictions['pred_y_logits'])\n",
    "        all_pred_6M_goutallier.append(predictions['pred_6M_goutallier'])\n",
    "        \n",
    "        # 실제 값 (다른 데이터셋에서 가져오기)\n",
    "        _, _, _, _, _, _, y_combined = testset_model4[i]\n",
    "        all_true_2M.append(y_2M)\n",
    "        # 실제 값은 testset_model4에서 가져옴\n",
    "        y_6M = y_combined[:seq_features_6M]\n",
    "        y_label = y_combined[seq_features_6M:seq_features_6M+1]\n",
    "        y_6M_goutallier = y_combined[seq_features_6M+1:]\n",
    "        \n",
    "        # 3M, 4M 실제 값\n",
    "        _, _, _, _, y_3M = testset_model2[i]\n",
    "        _, _, _, _, _, y_4M = testset_model3[i]\n",
    "        \n",
    "        all_true_3M.append(y_3M)\n",
    "        all_true_4M.append(y_4M)\n",
    "        all_true_6M.append(y_6M)\n",
    "        all_true_y.append(y_label)\n",
    "        all_true_6M_goutallier.append(y_6M_goutallier)\n",
    "    \n",
    "    # 텐서로 변환\n",
    "    pred_2M = torch.cat(all_pred_2M, dim=0)\n",
    "    pred_3M = torch.cat(all_pred_3M, dim=0)\n",
    "    pred_4M = torch.cat(all_pred_4M, dim=0)\n",
    "    pred_6M = torch.cat(all_pred_6M, dim=0)\n",
    "    pred_y_logits = torch.cat(all_pred_y_logits, dim=0)\n",
    "    pred_6M_goutallier = torch.cat(all_pred_6M_goutallier, dim=0)\n",
    "    \n",
    "    true_2M = torch.stack(all_true_2M)\n",
    "    true_3M = torch.stack(all_true_3M)\n",
    "    true_4M = torch.stack(all_true_4M)\n",
    "    true_6M = torch.stack(all_true_6M)\n",
    "    true_y = torch.stack(all_true_y)\n",
    "    true_6M_goutallier = torch.stack(all_true_6M_goutallier)\n",
    "    \n",
    "    # 성능 계산\n",
    "    mse_2M = F.mse_loss(pred_2M, true_2M).item()\n",
    "    mse_3M = F.mse_loss(pred_3M, true_3M).item()\n",
    "    mse_4M = F.mse_loss(pred_4M, true_4M).item()\n",
    "    mse_6M = F.mse_loss(pred_6M, true_6M).item()\n",
    "    mse_6M_goutallier = F.mse_loss(pred_6M_goutallier, true_6M_goutallier).item()\n",
    "    \n",
    "    # 분류 성능\n",
    "    pred_y_probs = pred_y_logits.sigmoid().flatten()\n",
    "    true_y_int = true_y.flatten().to(torch.int)\n",
    "    \n",
    "    roc_auc = roc_auc_score(true_y_int.cpu().numpy(), pred_y_probs.cpu().numpy())\n",
    "    ap = average_precision_score(true_y_int.cpu().numpy(), pred_y_probs.cpu().numpy())\n",
    "    \n",
    "    results = {\n",
    "        'mse_2M': mse_2M,\n",
    "        'mse_3M': mse_3M,\n",
    "        'mse_4M': mse_4M,\n",
    "        'mse_6M': mse_6M,\n",
    "        'mse_6M_goutallier': mse_6M_goutallier,\n",
    "        'roc_auc': roc_auc,\n",
    "        'ap': ap,\n",
    "        'predictions': {\n",
    "            'pred_2M': pred_2M,\n",
    "            'pred_3M': pred_3M,\n",
    "            'pred_4M': pred_4M,\n",
    "            'pred_6M': pred_6M,\n",
    "            'pred_y_logits': pred_y_logits,\n",
    "            'pred_y_probs': pred_y_probs,\n",
    "            'pred_6M_goutallier': pred_6M_goutallier\n",
    "        },\n",
    "        'targets': {\n",
    "            'true_2M': true_2M,\n",
    "            'true_3M': true_3M,\n",
    "            'true_4M': true_4M,\n",
    "            'true_6M': true_6M,\n",
    "            'true_y': true_y_int,\n",
    "            'true_6M_goutallier': true_6M_goutallier\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 평가 실행\n",
    "print(\"=\" * 80)\n",
    "print(\"연결된 시계열 모델 평가 시작\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "eval_results = evaluate_sequential_model(sequential_model, testset_model1)\n",
    "\n",
    "print(\"\\n=== 시계열 모델 평가 결과 ===\")\n",
    "print(f\"2M 예측 MSE: {eval_results['mse_2M']:.4f}\")\n",
    "print(f\"3M 예측 MSE: {eval_results['mse_3M']:.4f}\")\n",
    "print(f\"4M 예측 MSE: {eval_results['mse_4M']:.4f}\")\n",
    "print(f\"6M 예측 MSE: {eval_results['mse_6M']:.4f}\")\n",
    "print(f\"6M Goutallier 예측 MSE: {eval_results['mse_6M_goutallier']:.4f}\")\n",
    "print(f\"\\n분류 성능:\")\n",
    "print(f\"ROC AUC: {eval_results['roc_auc']:.4f}\")\n",
    "print(f\"AP (Average Precision): {eval_results['ap']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0c1332",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(L.LightningModule):\n",
    "  def __init__(self, in_features, static_features, seq_features, goutallier_features, out_features):\n",
    "    super().__init__()\n",
    "    self.register_buffer('pos_weight', torch.tensor([1.0]))\n",
    "\n",
    "    dropout = 0.3\n",
    "    self.static_encoder = nn.Sequential(\n",
    "      nn.Linear(static_features, 64), \n",
    "      nn.LayerNorm(64), \n",
    "      nn.LeakyReLU(), \n",
    "      nn.Dropout(0.2),\n",
    "    )\n",
    "\n",
    "    self.seq_encoder = nn.Sequential(\n",
    "      nn.Linear(seq_features, 128), \n",
    "      nn.LayerNorm(128), \n",
    "      nn.LeakyReLU(), \n",
    "      nn.Dropout(0.2),\n",
    "    )\n",
    "\n",
    "    self.goutallier = nn.Sequential(\n",
    "      nn.Linear(goutallier_features, 64), \n",
    "      nn.LayerNorm(64), \n",
    "      nn.LeakyReLU(), \n",
    "      nn.Dropout(0.2),\n",
    "    )\n",
    "\n",
    "    feat_dim = 64 + 128 + 64\n",
    "    \n",
    "    self.clshead = nn.Sequential(\n",
    "      nn.Linear(feat_dim, 128),\n",
    "      nn.LayerNorm(128),\n",
    "      nn.ReLU(),\n",
    "\n",
    "      nn.Linear(128, 1)\n",
    "    )\n",
    "    \n",
    "    self.reghead = nn.Sequential(\n",
    "      nn.Linear(feat_dim, 256),\n",
    "      nn.LayerNorm(256),\n",
    "      nn.LeakyReLU(),\n",
    "\n",
    "      nn.Linear(256, 5)\n",
    "    )\n",
    "\n",
    "    self.train_roc = BinaryAUROC()\n",
    "    self.test_roc = BinaryAUROC()\n",
    "    self.test_ap = BinaryAveragePrecision()\n",
    "    self.val_roc = BinaryAUROC()\n",
    "    self.val_ap = BinaryAveragePrecision()\n",
    "\n",
    "    self.train_mse = MeanSquaredError()\n",
    "    self.test_mse  = MeanSquaredError()\n",
    "    self.train_mae = MeanAbsoluteError()\n",
    "    self.test_mae  = MeanAbsoluteError()\n",
    "\n",
    "  def forward(self, xb, xb_static, xb_seq, xb_goutallier):\n",
    "    static_features = self.static_encoder(xb_static)\n",
    "    seq_features = self.seq_encoder(xb_seq)\n",
    "    goutallier_features = self.goutallier(xb_goutallier)\n",
    "\n",
    "    combined_features = torch.cat([static_features, seq_features, goutallier_features], dim=1)\n",
    "    \n",
    "    logits = self.clshead(combined_features)\n",
    "    regs = self.reghead(combined_features)\n",
    "\n",
    "    return logits, regs\n",
    "\n",
    "  def _shared_step(self, batch, metric=True):\n",
    "    xb, xb_static, xb_seq, xb_goutallier, yb = batch\n",
    "    clf_targets = yb[:, :1]\n",
    "    reg_targets = yb[:, 1:]\n",
    "\n",
    "    logits, regs = self.forward(xb, xb_static, xb_seq, xb_goutallier)\n",
    "\n",
    "    clf_loss = F.binary_cross_entropy_with_logits(logits, clf_targets, pos_weight=self.pos_weight)\n",
    "    reg_loss = F.smooth_l1_loss(regs, reg_targets)\n",
    "    loss = clf_loss + reg_loss\n",
    "\n",
    "    return {\n",
    "      \"loss\": loss,\n",
    "      \"clf_loss\": clf_loss,\n",
    "      \"reg_loss\": reg_loss,\n",
    "      \"clf_logits\": logits.detach(),\n",
    "      \"clf_targets\": clf_targets.detach(),\n",
    "    }\n",
    "  \n",
    "  def training_step(self, batch, batch_idx):\n",
    "    out = self._shared_step(batch)\n",
    "\n",
    "    self.log(\"train/loss\", out[\"loss\"], on_epoch=True, prog_bar=True)\n",
    "    self.log(\"train/clf_loss\", out[\"clf_loss\"])\n",
    "    self.log(\"train/reg_loss\", out[\"reg_loss\"])\n",
    "\n",
    "    probs = out[\"clf_logits\"].sigmoid().flatten()\n",
    "    targets = out[\"clf_targets\"].flatten().to(torch.int)\n",
    "    self.train_roc.update(probs, targets)\n",
    "\n",
    "    return out[\"loss\"]\n",
    "\n",
    "  def test_step(self, batch, batch_idx):\n",
    "    out = self._shared_step(batch)\n",
    "\n",
    "    self.log(\"test/loss\", out[\"loss\"], prog_bar=True)\n",
    "    self.log(\"test/clf_loss\", out[\"clf_loss\"])\n",
    "    self.log(\"test/reg_loss\", out[\"reg_loss\"])\n",
    "\n",
    "    probs = out[\"clf_logits\"].sigmoid().flatten()\n",
    "    targets = out[\"clf_targets\"].flatten().to(torch.int)\n",
    "    self.test_roc.update(probs, targets)\n",
    "    self.test_ap.update(probs, targets)\n",
    "    \n",
    "    return out[\"loss\"]\n",
    "  \n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    out = self._shared_step(batch)\n",
    "\n",
    "    self.log(\"val/loss\", out[\"loss\"], prog_bar=True, on_epoch=True)\n",
    "    self.log(\"val/clf_loss\", out[\"clf_loss\"], on_epoch=True)\n",
    "    self.log(\"val/reg_loss\", out[\"reg_loss\"], on_epoch=True)\n",
    "\n",
    "    probs = out[\"clf_logits\"].sigmoid().flatten()\n",
    "    targets = out[\"clf_targets\"].flatten().to(torch.int)\n",
    "    self.val_roc.update(probs, targets)\n",
    "    self.val_ap.update(probs, targets)\n",
    "    \n",
    "    return out[\"loss\"]\n",
    "  \n",
    "  def on_train_epoch_end(self):\n",
    "    self.log(\"train/roc\", self.train_roc.compute())\n",
    "    self.train_roc.reset()\n",
    "\n",
    "  def on_test_epoch_end(self):\n",
    "    self.log(\"test/roc\", self.test_roc.compute())\n",
    "    self.log(\"test/ap\", self.test_ap.compute())\n",
    "    self.test_roc.reset()\n",
    "\n",
    "  def on_validation_epoch_end(self):\n",
    "    self.log(\"val/roc\", self.val_roc.compute())\n",
    "    self.log(\"val/ap\", self.val_ap.compute())\n",
    "    self.val_roc.reset()\n",
    "    self.val_ap.reset()\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "      optimizer = torch.optim.AdamW(self.parameters(), lr=5*1e-6, weight_decay=1e-4)\n",
    "\n",
    "      return {\n",
    "          \"optimizer\": optimizer,\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5239a5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistoryCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.train_losses = []\n",
    "        self.test_losses = []\n",
    "    \n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        if len(self.train_losses) == 0:\n",
    "            print(f\"[Train] Available metrics: {list(trainer.callback_metrics.keys())}\")\n",
    "        \n",
    "        train_loss = trainer.callback_metrics.get('train/loss_epoch')\n",
    "        if train_loss is not None:\n",
    "            self.train_losses.append(train_loss.item())\n",
    "        else:\n",
    "            print(f\"Warning: train/loss_epoch not found!\")\n",
    "    \n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        if len(self.test_losses) == 0:\n",
    "            print(f\"[Val] Available metrics: {list(trainer.callback_metrics.keys())}\")\n",
    "        \n",
    "        val_loss = trainer.callback_metrics.get('val/loss')\n",
    "        if val_loss is not None:\n",
    "            self.test_losses.append(val_loss.item())\n",
    "        else:\n",
    "            print(f\"Warning: val/loss not found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logs = []\n",
    "batch_size = 64\n",
    "num_experiments = 1\n",
    "\n",
    "test_logs = []\n",
    "models = []\n",
    "loss_histories = []\n",
    "\n",
    "for i in range(num_experiments):\n",
    "    mlp = MLP(in_features, static_features, seq_features, goutallier_features, out_features)\n",
    "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    testloader  = DataLoader(testset,  batch_size=batch_size)\n",
    "\n",
    "    loss_history_callback = LossHistoryCallback()\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=24,\n",
    "        callbacks=[\n",
    "            ModelCheckpoint(monitor='train/roc', mode='max', save_top_k=1),\n",
    "            loss_history_callback\n",
    "        ]\n",
    "    )\n",
    "    trainer.fit(mlp, trainloader, testloader)\n",
    "    test_result = trainer.test(mlp, testloader)\n",
    "    test_logs.append(test_result)\n",
    "    models.append(mlp)\n",
    "    loss_histories.append(loss_history_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee425a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_rocs = []\n",
    "individual_aps = []\n",
    "\n",
    "print(\"===== 개별 모델 성능 확인 =====\")\n",
    "for i, test_log in enumerate(test_logs):\n",
    "    roc = test_log[0][\"test/roc\"]\n",
    "    ap = test_log[0][\"test/ap\"]\n",
    "    individual_rocs.append(roc)\n",
    "    individual_aps.append(ap)\n",
    "    print(f\"모델 {i+1}: ROC AUC = {roc:.4f}, AP = {ap:.4f}\")\n",
    "\n",
    "individual_rocs = np.array(individual_rocs)\n",
    "individual_aps = np.array(individual_aps)\n",
    "\n",
    "print(f\"\\n개별 모델 ROC AUC: {individual_rocs.mean():.4f} ± {individual_rocs.std():.4f}\")\n",
    "print(f\"개별 모델 AP: {individual_aps.mean():.4f} ± {individual_aps.std():.4f}\")\n",
    "\n",
    "best_model_idx = np.argmax(individual_rocs)\n",
    "best_model = models[best_model_idx]\n",
    "\n",
    "print(f\"\\n===== 최고 성능 모델 선택 =====\")\n",
    "print(f\"최고 성능 모델: 모델 {best_model_idx + 1}\")\n",
    "print(f\"ROC AUC: {individual_rocs[best_model_idx]:.4f}\")\n",
    "print(f\"AP: {individual_aps[best_model_idx]:.4f}\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_best_model(model, dataloader):\n",
    "    model.eval()\n",
    "    all_logits = []\n",
    "    all_regs = []\n",
    "    clf_targets = []\n",
    "    reg_targets = []\n",
    "    \n",
    "    for xb, x_static, x_seq, x_goutallier, yb in dataloader:\n",
    "        logits, regs = model(xb, x_static, x_seq, x_goutallier)\n",
    "        all_logits.append(logits)\n",
    "        all_regs.append(regs)\n",
    "        clf_targets.append(yb[:, :1])\n",
    "        reg_targets.append(yb[:, 1:])\n",
    "    \n",
    "    logits = torch.cat(all_logits)\n",
    "    regs = torch.cat(all_regs)\n",
    "    clf_targets = torch.cat(clf_targets).to(torch.int).flatten()\n",
    "    reg_targets = torch.cat(reg_targets)\n",
    "    \n",
    "    return logits, regs, clf_targets, reg_targets\n",
    "\n",
    "best_logits, best_regs, clf_targets, reg_targets = predict_with_best_model(best_model, testloader)\n",
    "probs = best_logits.sigmoid()\n",
    "\n",
    "if probs.dim() > 1:\n",
    "    probs_flat = probs.flatten()\n",
    "else:\n",
    "    probs_flat = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0afac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_roc = roc_auc_score(clf_targets, probs_flat)\n",
    "best_ap = average_precision_score(clf_targets, probs_flat)\n",
    "    \n",
    "print(f\"\\n=== 최고 성능 모델 최종 성능 ===\")\n",
    "print(f\"ROC AUC: {best_roc:.4f}\")\n",
    "print(f\"AP: {best_ap:.4f}\")\n",
    "    \n",
    "threshold = 0.3\n",
    "predicted_labels = (probs_flat > threshold).int()\n",
    "print(f\"\\n=== 분류 성능 ===\")\n",
    "print(classification_report(clf_targets, predicted_labels, target_names=['Negative', 'Positive']))\n",
    "    \n",
    "mse = torch.nn.functional.mse_loss(best_regs, reg_targets).item()\n",
    "mae = torch.nn.functional.l1_loss(best_regs, reg_targets).item()\n",
    "    \n",
    "print(f\"\\n=== 회귀 성능 ===\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72215148",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_aps = np.array([test_log[0][\"test/ap\"] for test_log in test_logs])\n",
    "test_rocs = np.array([test_log[0][\"test/roc\"] for test_log in test_logs])\n",
    "pd.DataFrame({\"ROC AUC\": test_rocs, \"PR AUC\": test_aps}).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f25d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_set_stat(dataset):\n",
    "  _, _, _, _, y = dataset[:]\n",
    "  negative, positive = torch.bincount(y[:, 0].to(torch.int)).tolist()\n",
    "  samples = len(dataset)\n",
    "\n",
    "  print(f\"tatal   : {samples}\")\n",
    "  print(f\"negative: {negative:3} ({negative/samples*100:5.2f}%)\")\n",
    "  print(f\"positive: {positive:3} ({positive/samples*100:5.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee2341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"trainset (SMOTE)\")\n",
    "show_set_stat(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183d1b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"testset\")\n",
    "show_set_stat(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4763ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def forward_loader(model, dataloader):\n",
    "  all_logits = []\n",
    "  all_regs = []\n",
    "  all_clf_targets = []\n",
    "  all_reg_targets = []\n",
    "  \n",
    "  model.eval()\n",
    "  for xb, x_static, x_seq, x_goutallier, yb in dataloader:\n",
    "    logits, regs = model(xb, x_static, x_seq, x_goutallier)\n",
    "    all_logits.append(logits)\n",
    "    all_regs.append(regs)\n",
    "    all_clf_targets.append(yb[:, :1])\n",
    "    all_reg_targets.append(yb[:, 1:])\n",
    "\n",
    "  logits = torch.cat(all_logits).flatten()\n",
    "  regs = torch.cat(all_regs)\n",
    "  clf_targets = torch.cat(all_clf_targets).to(torch.int).flatten()\n",
    "  reg_targets = torch.cat(all_reg_targets)\n",
    "\n",
    "  return logits, regs, clf_targets, reg_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ae957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, regs, clf_targets, reg_targets = forward_loader(mlp, testloader)\n",
    "probs = logits.sigmoid()\n",
    "\n",
    "print(f\"logits.shape:      {logits.shape}\")\n",
    "print(f\"probs.shape:      {probs.shape}\")\n",
    "print(f\"regs.shape:        {regs.shape}\")\n",
    "print()\n",
    "print(f\"clf_targets.shape: {clf_targets.shape}\")\n",
    "print(f\"reg_targets.shape: {reg_targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad6143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions, recalls, thresholds = precision_recall_curve(clf_targets, probs)\n",
    "thresholds = np.append(thresholds, 1.0)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(thresholds, precisions, label='Precision', marker='o', markersize=3)\n",
    "plt.plot(thresholds, recalls, label='Recall', marker='x', markersize=3)\n",
    "\n",
    "plt.title(\"Precision & Recall vs Threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06428065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_score_distributions(\n",
    "  y_score, y_true, *,\n",
    "  bins=40,\n",
    "  title=None,\n",
    "  density=False,\n",
    "  th_lines=(0.5,),\n",
    "):\n",
    "  y_true = np.asarray(y_true).astype(int)\n",
    "  y_score = np.asarray(y_score)\n",
    "\n",
    "  x_main = y_score\n",
    "  x_label = \"Predicted probability\"\n",
    "\n",
    "  pos = x_main[y_true == 1]\n",
    "  neg = x_main[y_true == 0]\n",
    "\n",
    "  xmin = np.min(x_main)\n",
    "  xmax = np.max(x_main)\n",
    "  bins_edges = np.linspace(xmin, xmax, bins+1)\n",
    "\n",
    "  plt.figure(figsize=(9, 5.5))\n",
    "  plt.hist(neg, bins=bins_edges, alpha=0.55, density=density,\n",
    "           label=f\"Negative (n={len(neg)})\", edgecolor=\"white\", linewidth=0.5)\n",
    "  plt.hist(pos, bins=bins_edges, alpha=0.55, density=density,\n",
    "           label=f\"Positive (n={len(pos)})\", edgecolor=\"white\", linewidth=0.5)\n",
    "\n",
    "  if th_lines:\n",
    "    for th in th_lines:\n",
    "      plt.axvline(th, linestyle=\"--\", linewidth=1.5)\n",
    "\n",
    "  plt.xlabel(x_label)\n",
    "  plt.ylabel(\"Density\" if density else \"Count\")\n",
    "  plt.title(title or \"Score distributions by class\")\n",
    "  plt.legend(loc=\"best\")\n",
    "  plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590cb0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_thresholds = np.linspace(0, 1, 11)[1:-1].tolist() # [0.1, 0.2, ... , 0.9]\n",
    "\n",
    "def test_thresholds(y_score, y_true, thresholds=default_thresholds, verbose=True):\n",
    "  accuracies = []\n",
    "  precisions = []\n",
    "  recalls = []\n",
    "  f1s = []\n",
    "  for threshold in thresholds:\n",
    "    bin_acc = BinaryAccuracy(threshold)\n",
    "    bin_precison = BinaryPrecision(threshold)\n",
    "    bin_recall = BinaryRecall(threshold)\n",
    "    bin_f1 = BinaryF1Score(threshold)\n",
    "\n",
    "    bin_acc.update(y_score, y_true)\n",
    "    bin_precison.update(y_score, y_true)\n",
    "    bin_recall.update(y_score, y_true)\n",
    "    bin_f1.update(y_score, y_true)\n",
    "\n",
    "    accuracies.append(bin_acc.compute().item())\n",
    "    precisions.append(bin_precison.compute().item())\n",
    "    recalls.append(bin_recall.compute().item())\n",
    "    f1s.append(bin_f1.compute().item())\n",
    "\n",
    "  result = pd.DataFrame({\n",
    "    \"threshold\": thresholds,\n",
    "    \"accuracy\": accuracies,\n",
    "    \"precison\": precisions,\n",
    "    \"recall\": recalls,\n",
    "    \"f1\": f1s\n",
    "  }).set_index(\"threshold\")\n",
    "\n",
    "  if verbose:\n",
    "    print(result)\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fa07c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_range = np.arange(0.0, 1.01, 0.01)\n",
    "\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "specificities = []\n",
    "youden_indices = []\n",
    "\n",
    "y_true_np = clf_targets.cpu().numpy()\n",
    "probs_np = probs.cpu().numpy()\n",
    "\n",
    "for th in thresholds_range:\n",
    "    y_pred = (probs_np >= th).astype(int)\n",
    "    \n",
    "    tn = np.sum((y_pred == 0) & (y_true_np == 0))\n",
    "    fp = np.sum((y_pred == 1) & (y_true_np == 0))\n",
    "    fn = np.sum((y_pred == 0) & (y_true_np == 1))\n",
    "    tp = np.sum((y_pred == 1) & (y_true_np == 1))\n",
    "    \n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    youden = recall + specificity - 1\n",
    "    \n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    specificities.append(specificity)\n",
    "    youden_indices.append(youden)\n",
    "\n",
    "best_accuracy_th = thresholds_range[np.argmax(accuracies)]\n",
    "best_f1_th = thresholds_range[np.argmax(f1_scores)]\n",
    "best_youden_th = thresholds_range[np.argmax(youden_indices)]\n",
    "balanced_th = thresholds_range[np.argmin(np.abs(np.array(precisions) - np.array(recalls)))]\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(\" 최적 Threshold 결과\")\n",
    "print(f\"{'='*100}\\n\")\n",
    "\n",
    "print(f\"Accuracy 최대화:        Threshold = {best_accuracy_th:.3f}  (Accuracy = {max(accuracies):.4f})\")\n",
    "print(f\"F1 Score 최대화:        Threshold = {best_f1_th:.3f}  (F1 = {max(f1_scores):.4f})\")\n",
    "print(f\"Precision-Recall 균형:  Threshold = {balanced_th:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ccf794",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [best_accuracy_th]\n",
    "test_thresholds(probs, clf_targets, thresholds)\n",
    "plot_score_distributions(probs, clf_targets, bins=40, density=True, th_lines=thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0120c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_regression_summary(regs, reg_targets, output_columns):\n",
    "    \n",
    "    results = []\n",
    "    for i, col_name in enumerate(output_columns):\n",
    "        pred = regs[:, i]\n",
    "        true = reg_targets[:, i]\n",
    "        \n",
    "        mse = torch.mean((pred - true) ** 2).item()\n",
    "        mae = torch.mean(torch.abs(pred - true)).item()\n",
    "        rmse = torch.sqrt(torch.mean((pred - true) ** 2)).item()\n",
    "        \n",
    "        ss_res = torch.sum((true - pred) ** 2)\n",
    "        ss_tot = torch.sum((true - torch.mean(true)) ** 2)\n",
    "        r2 = 1 - (ss_res / ss_tot).item()\n",
    "        \n",
    "        results.append({\n",
    "            'Column': col_name,\n",
    "            'MSE': mse,\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'R²': r2\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    print(df.round(4))\n",
    "    \n",
    "    return df\n",
    "\n",
    "logits, regs, clf_targets, reg_targets = forward_loader(models[0], testloader)\n",
    "regression_summary = print_regression_summary(regs, reg_targets, output_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6d1ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(testset)\n",
    "# show_set_stat(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd512ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testloader = DataLoader(testset, batch_size=batch_size)\n",
    "# test_logs = trainer.test(mlp, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fef2459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_logits, test_regs, test_clf_targets, test_reg_targets = forward_loader(mlp, testloader)\n",
    "# test_probs = test_logits.sigmoid()\n",
    "# test_thresholds(test_probs, test_clf_targets, thresholds)\n",
    "# plot_score_distributions(test_probs, test_clf_targets, bins=40, density=True, th_lines=thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2e0404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae20aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_columns = seq_columns[:12] + goutallier_columns[:4] + goutallier_columns[8:12]\n",
    "# pre_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c980f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_columns = [column for column in columns if column not in static_columns + pre_columns + output_columns]\n",
    "# mean_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8db9a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_table = pd.read_csv(\"X_train.csv\")\n",
    "# mean_table[\"age_group\"] = mean_table[\"나이\"] // 10 * 10\n",
    "\n",
    "# group_columns = [\"성별 (M:1,F:2)\", \"age_group\"]\n",
    "# mean_table = mean_table.groupby(group_columns)[mean_columns].mean().reset_index()\n",
    "# mean_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eec593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_pre_with_mean_dataset(split):\n",
    "#   assert split in [\"val\", \"test\"]\n",
    "#   X = pd.read_csv(f\"X_{split}.csv\")\n",
    "#   y = pd.read_csv(f\"y_{split}.csv\")\n",
    "\n",
    "#   indices = pd.concat([X[\"성별 (M:1,F:2)\"], X[\"나이\"] // 10 * 10], axis=1)\n",
    "#   indices.columns = group_columns\n",
    "#   mean_values = indices.merge(mean_table, on=group_columns, how=\"left\")\n",
    "\n",
    "#   X[mean_columns] = mean_values[mean_columns]\n",
    "#   X_np = X[input_columns].to_numpy()\n",
    "#   y_np = pd.concat([y, X[output_columns]], axis=1).to_numpy()\n",
    "\n",
    "#   X_tensor = torch.tensor(X_np, dtype=torch.float32)\n",
    "#   y_tensor = torch.tensor(y_np, dtype=torch.float32)\n",
    "\n",
    "#   return TensorDataset(X_tensor, y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7049e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_pre_with_mean_set = get_pre_with_mean_dataset(\"val\")\n",
    "# val_pre_with_mean_loader = DataLoader(val_pre_with_mean_set, batch_size=batch_size)\n",
    "# val_pre_with_mean_logs = trainer.test(mlp, val_pre_with_mean_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041bc402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits, regs, clf_targets, reg_targets = forward_loader(mlp, val_pre_with_mean_loader)\n",
    "# probs = logits.sigmoid()\n",
    "# test_thresholds(probs, clf_targets, thresholds)\n",
    "# plot_score_distributions(probs, clf_targets, bins=40, density=False, th_lines=thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea548a47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87529f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fgsm_attack(data, data_grad, epsilon):\n",
    "#   sign_data_grad = data_grad.sign()\n",
    "#   perturbed_data = data + epsilon*sign_data_grad\n",
    "#   return perturbed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0709c5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_static_columns = len(static_columns)\n",
    "# num_goutallier_columns= len(goutallier_columns)\n",
    "# num_static_columns, num_goutallier_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e41405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fgsm_target_start = num_static_columns+12\n",
    "# fgsm_target_end = -num_goutallier_columns\n",
    "# fgsm_target_columns = input_columns[fgsm_target_start:fgsm_target_end]\n",
    "# fgsm_target_columns, len(fgsm_target_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f536bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 0: '6M ASES'          -> maximize\n",
    "# # 1: '6M CSS'           -> maximize\n",
    "# # 2: '6M KSS'           -> maximize\n",
    "# # 3: '6M VAS(activity)' -> minimize\n",
    "# # 4: '6M VAS(resting)'  -> minimize\n",
    "# maximize_indices = [0, 1, 2]\n",
    "# minimize_indices = [3, 4]\n",
    "\n",
    "# lambda_logits = 1.0\n",
    "# lambda_reg = 0.3\n",
    "# epsilon = 0.5\n",
    "\n",
    "# all_logits = []\n",
    "# all_regs = []\n",
    "# all_perturbed_xb = []\n",
    "# all_perturbed_logits = []\n",
    "# all_perturbed_regs = []\n",
    "\n",
    "# mlp.eval()\n",
    "# for xb, yb in val_pre_with_mean_loader:\n",
    "#   clf_targets = yb[:, :1]\n",
    "#   reg_targets = yb[:, 1:]\n",
    "\n",
    "#   xb.requires_grad = True\n",
    "#   logits, regs = mlp(xb)\n",
    "#   all_logits.append(logits.detach())\n",
    "#   all_regs.append(regs.detach())\n",
    "\n",
    "#   clf_loss = F.binary_cross_entropy_with_logits(logits, clf_targets)\n",
    "#   logits_dir_loss = -logits.mean()\n",
    "\n",
    "#   reg_inc_term = -regs[:, maximize_indices].mean()\n",
    "#   reg_dec_term = regs[:, minimize_indices].mean()\n",
    "#   reg_dir_loss = reg_inc_term + reg_dec_term\n",
    "\n",
    "#   loss = clf_loss + lambda_logits * logits_dir_loss + lambda_reg * reg_dir_loss\n",
    "\n",
    "#   mlp.zero_grad()\n",
    "#   loss.backward()\n",
    "\n",
    "#   xb_grad = xb.grad.data\n",
    "#   perturbed_xb = fgsm_attack(xb, xb_grad, epsilon)\n",
    "#   all_perturbed_xb.append(perturbed_xb.detach())\n",
    "\n",
    "#   perturbed_logits, perturbed_regs = mlp(perturbed_xb)\n",
    "#   all_perturbed_logits.append(perturbed_logits.detach())\n",
    "#   all_perturbed_regs.append(perturbed_regs.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b761ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits = torch.cat(all_logits).flatten()\n",
    "# regs = torch.cat(all_regs)\n",
    "# logits.shape, regs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce007506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perturbed_logits = torch.cat(all_perturbed_logits).flatten()\n",
    "# perturbed_regs = torch.cat(all_perturbed_regs)\n",
    "# perturbed_logits.shape, perturbed_regs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a136de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# probs = logits.sigmoid()\n",
    "# perturbed_probs = perturbed_logits.sigmoid()\n",
    "# probs.shape, perturbed_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe51f921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(label_column)\n",
    "# prob_results = pd.DataFrame({\n",
    "#   \"probability\": probs.flatten(),\n",
    "#   \"after probability\": perturbed_probs.flatten()\n",
    "# })\n",
    "# prob_results[\"delta\"] = prob_results[\"after probability\"] - prob_results[\"probability\"]\n",
    "# prob_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7476b9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e27a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_feature_results = []\n",
    "# for feature_idx in range(regs.size(1)):\n",
    "#   feature_column = output_columns[feature_idx]\n",
    "#   after_column = f\"after {feature_column}\"\n",
    "\n",
    "#   feature_results = pd.DataFrame({\n",
    "#     feature_column: regs[:, feature_idx],\n",
    "#     after_column: perturbed_regs[:, feature_idx]\n",
    "#   })\n",
    "#   feature_results[\"delta\"] = feature_results[after_column] - feature_results[feature_column]\n",
    "#   all_feature_results.append(feature_results)\n",
    "\n",
    "#   direction = \"maximize\" if feature_idx in maximize_indices else \"minimize\"\n",
    "#   print(f\"{feature_column} ({direction})\")\n",
    "#   print(feature_results)\n",
    "#   print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2d6218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feature_column, feature_results in zip(output_columns, all_feature_results):\n",
    "#   direction = \"maximize\" if feature_idx in maximize_indices else \"minimize\"\n",
    "#   print(f\"{feature_column} ({direction})\")\n",
    "#   print(feature_results.describe())\n",
    "#   print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hospital",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
