{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b43411b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda\\envs\\hospital\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, classification_report, accuracy_score\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchmetrics.regression import MeanSquaredError, MeanAbsoluteError\n",
    "from torchmetrics.classification import BinaryAUROC, BinaryAveragePrecision\n",
    "from torchmetrics.classification import BinaryAccuracy, BinaryPrecision, BinaryRecall, BinaryF1Score\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.callbacks import Callback\n",
    "\n",
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568bd53b",
   "metadata": {},
   "source": [
    "### 데이터셋 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a431bcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_MAKER = \"jiseock\"\n",
    "if DATA_MAKER == \"jiseock\":\n",
    "    DATA_PATH = \"../dataset/jiseock\"\n",
    "else:\n",
    "    DATA_PATH = \"../dataset/yeonseo\"\n",
    "\n",
    "X_train = pd.read_csv(f\"{DATA_PATH}/X_train.csv\")\n",
    "y_train = pd.read_csv(f\"{DATA_PATH}/y_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87c42fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>나이</th>\n",
       "      <th>성별 (M:1,F:2)</th>\n",
       "      <th>Rt:1,Lt:2</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Tearsize (AP,cm)</th>\n",
       "      <th>Tearsize (ML)</th>\n",
       "      <th>Tearsize (retraction)</th>\n",
       "      <th>흡연여부 (비흡연:1,흡연:2)</th>\n",
       "      <th>흡연여부 (비흡연:1,흡연:2) Missing flag</th>\n",
       "      <th>...</th>\n",
       "      <th>6M Goutallier (ISP)</th>\n",
       "      <th>6M Goutallier (TM)</th>\n",
       "      <th>Pre Goutallier (SSP) Missing flag</th>\n",
       "      <th>Pre Goutallier (SSC) Missing flag</th>\n",
       "      <th>Pre Goutallier (ISP) Missing flag</th>\n",
       "      <th>Pre Goutallier (TM) Missing flag</th>\n",
       "      <th>6M Goutallier (SSP) Missing flag</th>\n",
       "      <th>6M Goutallier (SSC) Missing flag</th>\n",
       "      <th>6M Goutallier (ISP) Missing flag</th>\n",
       "      <th>6M Goutallier (TM) Missing flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.112260</td>\n",
       "      <td>-0.239010</td>\n",
       "      <td>0.529347</td>\n",
       "      <td>1.299314</td>\n",
       "      <td>1.236586</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229042</td>\n",
       "      <td>-0.201304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429514</td>\n",
       "      <td>-0.072467</td>\n",
       "      <td>-0.673177</td>\n",
       "      <td>-0.693529</td>\n",
       "      <td>-0.671659</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229042</td>\n",
       "      <td>-0.201304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.344449</td>\n",
       "      <td>-0.488825</td>\n",
       "      <td>-0.913682</td>\n",
       "      <td>-0.927981</td>\n",
       "      <td>-0.896158</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229042</td>\n",
       "      <td>-0.201304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.584307</td>\n",
       "      <td>0.268947</td>\n",
       "      <td>-0.071915</td>\n",
       "      <td>-0.693529</td>\n",
       "      <td>-0.671659</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229042</td>\n",
       "      <td>-0.201304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.050343</td>\n",
       "      <td>-0.209865</td>\n",
       "      <td>0.529347</td>\n",
       "      <td>0.478732</td>\n",
       "      <td>0.450838</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229042</td>\n",
       "      <td>-0.201304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7173</th>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.371571</td>\n",
       "      <td>-1.414487</td>\n",
       "      <td>0.014274</td>\n",
       "      <td>-0.777214</td>\n",
       "      <td>-0.751792</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229042</td>\n",
       "      <td>-0.201304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7174</th>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.038328</td>\n",
       "      <td>0.032052</td>\n",
       "      <td>0.070864</td>\n",
       "      <td>-0.498668</td>\n",
       "      <td>-0.485071</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229042</td>\n",
       "      <td>-0.201304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7175</th>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.778539</td>\n",
       "      <td>0.094077</td>\n",
       "      <td>-0.174047</td>\n",
       "      <td>-0.206960</td>\n",
       "      <td>-0.205745</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229042</td>\n",
       "      <td>-0.201304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7176</th>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.048063</td>\n",
       "      <td>-0.588316</td>\n",
       "      <td>-1.114365</td>\n",
       "      <td>-1.123613</td>\n",
       "      <td>-1.083486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229042</td>\n",
       "      <td>-0.201304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7177</th>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.030424</td>\n",
       "      <td>-0.341497</td>\n",
       "      <td>-0.673177</td>\n",
       "      <td>-0.466425</td>\n",
       "      <td>-0.454196</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229042</td>\n",
       "      <td>-0.201304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7178 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      나이  성별 (M:1,F:2)  Rt:1,Lt:2    Height    Weight  Tearsize (AP,cm)  \\\n",
       "0     70             2          1 -0.112260 -0.239010          0.529347   \n",
       "1     61             1          1  0.429514 -0.072467         -0.673177   \n",
       "2     73             2          1 -0.344449 -0.488825         -0.913682   \n",
       "3     60             1          2  0.584307  0.268947         -0.071915   \n",
       "4     75             2          2 -0.050343 -0.209865          0.529347   \n",
       "...   ..           ...        ...       ...       ...               ...   \n",
       "7173  72             2          2 -0.371571 -1.414487          0.014274   \n",
       "7174  80             1          2  0.038328  0.032052          0.070864   \n",
       "7175  83             2          1  0.778539  0.094077         -0.174047   \n",
       "7176  65             2          1  0.048063 -0.588316         -1.114365   \n",
       "7177  89             2          1 -1.030424 -0.341497         -0.673177   \n",
       "\n",
       "      Tearsize (ML)  Tearsize (retraction)  흡연여부 (비흡연:1,흡연:2)  \\\n",
       "0          1.299314               1.236586                1.0   \n",
       "1         -0.693529              -0.671659                1.0   \n",
       "2         -0.927981              -0.896158                1.0   \n",
       "3         -0.693529              -0.671659                1.0   \n",
       "4          0.478732               0.450838                1.0   \n",
       "...             ...                    ...                ...   \n",
       "7173      -0.777214              -0.751792                1.0   \n",
       "7174      -0.498668              -0.485071                1.0   \n",
       "7175      -0.206960              -0.205745                1.0   \n",
       "7176      -1.123613              -1.083486                1.0   \n",
       "7177      -0.466425              -0.454196                1.0   \n",
       "\n",
       "      흡연여부 (비흡연:1,흡연:2) Missing flag  ...  6M Goutallier (ISP)  \\\n",
       "0                                1.0  ...            -0.229042   \n",
       "1                                1.0  ...            -0.229042   \n",
       "2                                0.0  ...            -0.229042   \n",
       "3                                1.0  ...            -0.229042   \n",
       "4                                1.0  ...            -0.229042   \n",
       "...                              ...  ...                  ...   \n",
       "7173                             1.0  ...            -0.229042   \n",
       "7174                             1.0  ...            -0.229042   \n",
       "7175                             1.0  ...            -0.229042   \n",
       "7176                             1.0  ...            -0.229042   \n",
       "7177                             1.0  ...            -0.229042   \n",
       "\n",
       "      6M Goutallier (TM)  Pre Goutallier (SSP) Missing flag  \\\n",
       "0              -0.201304                                1.0   \n",
       "1              -0.201304                                1.0   \n",
       "2              -0.201304                                0.0   \n",
       "3              -0.201304                                0.0   \n",
       "4              -0.201304                                1.0   \n",
       "...                  ...                                ...   \n",
       "7173           -0.201304                                0.0   \n",
       "7174           -0.201304                                1.0   \n",
       "7175           -0.201304                                1.0   \n",
       "7176           -0.201304                                1.0   \n",
       "7177           -0.201304                                1.0   \n",
       "\n",
       "      Pre Goutallier (SSC) Missing flag  Pre Goutallier (ISP) Missing flag  \\\n",
       "0                                   1.0                                1.0   \n",
       "1                                   1.0                                1.0   \n",
       "2                                   0.0                                0.0   \n",
       "3                                   0.0                                0.0   \n",
       "4                                   1.0                                1.0   \n",
       "...                                 ...                                ...   \n",
       "7173                                0.0                                0.0   \n",
       "7174                                1.0                                1.0   \n",
       "7175                                1.0                                1.0   \n",
       "7176                                1.0                                1.0   \n",
       "7177                                1.0                                1.0   \n",
       "\n",
       "      Pre Goutallier (TM) Missing flag  6M Goutallier (SSP) Missing flag  \\\n",
       "0                                  1.0                               1.0   \n",
       "1                                  1.0                               1.0   \n",
       "2                                  0.0                               0.0   \n",
       "3                                  0.0                               0.0   \n",
       "4                                  1.0                               1.0   \n",
       "...                                ...                               ...   \n",
       "7173                               0.0                               1.0   \n",
       "7174                               1.0                               1.0   \n",
       "7175                               1.0                               1.0   \n",
       "7176                               1.0                               1.0   \n",
       "7177                               1.0                               1.0   \n",
       "\n",
       "      6M Goutallier (SSC) Missing flag  6M Goutallier (ISP) Missing flag  \\\n",
       "0                                  1.0                               1.0   \n",
       "1                                  1.0                               1.0   \n",
       "2                                  0.0                               0.0   \n",
       "3                                  0.0                               0.0   \n",
       "4                                  1.0                               1.0   \n",
       "...                                ...                               ...   \n",
       "7173                               1.0                               1.0   \n",
       "7174                               1.0                               1.0   \n",
       "7175                               1.0                               1.0   \n",
       "7176                               1.0                               1.0   \n",
       "7177                               1.0                               1.0   \n",
       "\n",
       "      6M Goutallier (TM) Missing flag  \n",
       "0                                 1.0  \n",
       "1                                 1.0  \n",
       "2                                 0.0  \n",
       "3                                 0.0  \n",
       "4                                 1.0  \n",
       "...                               ...  \n",
       "7173                              1.0  \n",
       "7174                              1.0  \n",
       "7175                              1.0  \n",
       "7176                              1.0  \n",
       "7177                              1.0  \n",
       "\n",
       "[7178 rows x 96 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa0fd065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POD 6M retear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7173</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7174</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7175</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7176</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7177</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7178 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      POD 6M retear\n",
       "0                 0\n",
       "1                 0\n",
       "2                 0\n",
       "3                 0\n",
       "4                 0\n",
       "...             ...\n",
       "7173              1\n",
       "7174              1\n",
       "7175              1\n",
       "7176              1\n",
       "7177              1\n",
       "\n",
       "[7178 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfb8c992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['나이',\n",
       " '성별 (M:1,F:2)',\n",
       " 'Rt:1,Lt:2',\n",
       " 'Height',\n",
       " 'Weight',\n",
       " 'Tearsize (AP,cm)',\n",
       " 'Tearsize (ML)',\n",
       " 'Tearsize (retraction)',\n",
       " '흡연여부 (비흡연:1,흡연:2)',\n",
       " '흡연여부 (비흡연:1,흡연:2) Missing flag',\n",
       " 'Hospital 0',\n",
       " 'Hospital 1',\n",
       " 'Hospital 2',\n",
       " 'Hospital 3',\n",
       " 'Hospital 4',\n",
       " 'Hospital 5',\n",
       " 'Hospital 6',\n",
       " 'Disease 0',\n",
       " 'Disease 1',\n",
       " 'Disease 2',\n",
       " 'Disease 3',\n",
       " 'Disease 4',\n",
       " 'Disease 5',\n",
       " 'Disease 6',\n",
       " 'Disease 7',\n",
       " '0M ASES',\n",
       " '0M CSS',\n",
       " '0M ERabd',\n",
       " '0M ERside',\n",
       " '0M FF',\n",
       " '0M IR',\n",
       " '0M KSS',\n",
       " '0M MMTgrade',\n",
       " '0M MMTsec',\n",
       " '0M VAS(activity)',\n",
       " '0M VAS(resting)',\n",
       " '0M add',\n",
       " '2M ERabd',\n",
       " '2M ERside',\n",
       " '2M FF',\n",
       " '2M IR',\n",
       " '2M MMTgrade',\n",
       " '2M MMTsec',\n",
       " '2M add',\n",
       " '3M ASES',\n",
       " '3M CSS',\n",
       " '3M ERabd',\n",
       " '3M ERside',\n",
       " '3M FF',\n",
       " '3M IR',\n",
       " '3M KSS',\n",
       " '3M MMTgrade',\n",
       " '3M MMTsec',\n",
       " '3M VAS(activity)',\n",
       " '3M VAS(resting)',\n",
       " '3M add',\n",
       " '4M ASES',\n",
       " '4M CSS',\n",
       " '4M ERabd',\n",
       " '4M ERside',\n",
       " '4M FF',\n",
       " '4M IR',\n",
       " '4M KSS',\n",
       " '4M MMTgrade',\n",
       " '4M MMTsec',\n",
       " '4M VAS(activity)',\n",
       " '4M VAS(resting)',\n",
       " '4M add',\n",
       " '6M ASES',\n",
       " '6M CSS',\n",
       " '6M ERabd',\n",
       " '6M ERside',\n",
       " '6M FF',\n",
       " '6M IR',\n",
       " '6M KSS',\n",
       " '6M MMTgrade',\n",
       " '6M MMTsec',\n",
       " '6M VAS(activity)',\n",
       " '6M VAS(resting)',\n",
       " '6M add',\n",
       " 'Pre Goutallier (SSP)',\n",
       " 'Pre Goutallier (SSC)',\n",
       " 'Pre Goutallier (ISP)',\n",
       " 'Pre Goutallier (TM)',\n",
       " '6M Goutallier (SSP)',\n",
       " '6M Goutallier (SSC)',\n",
       " '6M Goutallier (ISP)',\n",
       " '6M Goutallier (TM)',\n",
       " 'Pre Goutallier (SSP) Missing flag',\n",
       " 'Pre Goutallier (SSC) Missing flag',\n",
       " 'Pre Goutallier (ISP) Missing flag',\n",
       " 'Pre Goutallier (TM) Missing flag',\n",
       " '6M Goutallier (SSP) Missing flag',\n",
       " '6M Goutallier (SSC) Missing flag',\n",
       " '6M Goutallier (ISP) Missing flag',\n",
       " '6M Goutallier (TM) Missing flag']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = list(X_train.columns)\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44e04aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['나이',\n",
       " '성별 (M:1,F:2)',\n",
       " 'Rt:1,Lt:2',\n",
       " 'Height',\n",
       " 'Weight',\n",
       " 'Tearsize (AP,cm)',\n",
       " 'Tearsize (ML)',\n",
       " 'Tearsize (retraction)',\n",
       " '흡연여부 (비흡연:1,흡연:2)',\n",
       " '흡연여부 (비흡연:1,흡연:2) Missing flag',\n",
       " 'Hospital 0',\n",
       " 'Hospital 1',\n",
       " 'Hospital 2',\n",
       " 'Hospital 3',\n",
       " 'Hospital 4',\n",
       " 'Hospital 5',\n",
       " 'Hospital 6',\n",
       " 'Disease 0',\n",
       " 'Disease 1',\n",
       " 'Disease 2',\n",
       " 'Disease 3',\n",
       " 'Disease 4',\n",
       " 'Disease 5',\n",
       " 'Disease 6',\n",
       " 'Disease 7']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_columns = columns[:25]\n",
    "\n",
    "# static 데이터 칼럼\n",
    "static_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7862c6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0M ASES', '0M CSS', '0M ERabd', '0M ERside', '0M FF', '0M IR', '0M KSS', '0M MMTgrade', '0M MMTsec', '0M VAS(activity)', '0M VAS(resting)', '0M add']\n",
      "['2M ERabd', '2M ERside', '2M FF', '2M IR', '2M MMTgrade', '2M MMTsec', '2M add']\n",
      "['3M ASES', '3M CSS', '3M ERabd', '3M ERside', '3M FF', '3M IR', '3M KSS', '3M MMTgrade', '3M MMTsec', '3M VAS(activity)', '3M VAS(resting)', '3M add']\n",
      "['4M ASES', '4M CSS', '4M ERabd', '4M ERside', '4M FF', '4M IR', '4M KSS', '4M MMTgrade', '4M MMTsec', '4M VAS(activity)', '4M VAS(resting)', '4M add']\n",
      "['6M ASES', '6M CSS', '6M ERabd', '6M ERside', '6M FF', '6M IR', '6M KSS', '6M MMTgrade', '6M MMTsec', '6M VAS(activity)', '6M VAS(resting)', '6M add']\n"
     ]
    }
   ],
   "source": [
    "seq_columns = columns[25:-16]\n",
    "\n",
    "# 시퀀셜 데이터 관련 칼럼들\n",
    "seq_columns_0M = seq_columns[:12]\n",
    "seq_columns_2M = seq_columns[12:19]\n",
    "seq_columns_3M = seq_columns[19:31]\n",
    "seq_columns_4M = seq_columns[31:43]\n",
    "seq_columns_6M = seq_columns[43:]\n",
    "\n",
    "seq_columns_all = [seq_columns_0M, seq_columns_2M, seq_columns_3M, seq_columns_4M, seq_columns_6M]\n",
    "\n",
    "for seq_col in seq_columns_all:\n",
    "    print(seq_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86ed4d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pre Goutallier (SSP)', 'Pre Goutallier (SSC)', 'Pre Goutallier (ISP)', 'Pre Goutallier (TM)']\n",
      "['6M Goutallier (SSP)', '6M Goutallier (SSC)', '6M Goutallier (ISP)', '6M Goutallier (TM)']\n",
      "['Pre Goutallier (SSP) Missing flag', 'Pre Goutallier (SSC) Missing flag', 'Pre Goutallier (ISP) Missing flag', 'Pre Goutallier (TM) Missing flag']\n",
      "['6M Goutallier (SSP) Missing flag', '6M Goutallier (SSC) Missing flag', '6M Goutallier (ISP) Missing flag', '6M Goutallier (TM) Missing flag']\n"
     ]
    }
   ],
   "source": [
    "goutallier_columns = columns[-16:]\n",
    "\n",
    "# goutaliar 관련 칼럼들\n",
    "goutallier_columns_0M = goutallier_columns [:4]\n",
    "goutallier_columns_6M = goutallier_columns [4:8]\n",
    "goutallier_columns_0M_missing = goutallier_columns [8:12]\n",
    "goutallier_columns_6M_missing = goutallier_columns [12:]\n",
    "\n",
    "print(goutallier_columns_0M)\n",
    "print(goutallier_columns_6M)\n",
    "print(goutallier_columns_0M_missing)\n",
    "print(goutallier_columns_6M_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a663ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns) == len(static_columns) + len(seq_columns) + len(goutallier_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cb95606",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column = \"POD 6M retear\"\n",
    "output_columns = [\"6M ASES\", \"6M CSS\", \"6M KSS\", \"6M VAS(activity)\", \"6M VAS(resting)\"]\n",
    "input_columns = static_columns + [column for column in seq_columns if column not in output_columns] + goutallier_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "690b23f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6M ASES', '6M CSS', '6M KSS', '6M VAS(activity)', '6M VAS(resting)']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23baa483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['나이',\n",
       " '성별 (M:1,F:2)',\n",
       " 'Rt:1,Lt:2',\n",
       " 'Height',\n",
       " 'Weight',\n",
       " 'Tearsize (AP,cm)',\n",
       " 'Tearsize (ML)',\n",
       " 'Tearsize (retraction)',\n",
       " '흡연여부 (비흡연:1,흡연:2)',\n",
       " '흡연여부 (비흡연:1,흡연:2) Missing flag',\n",
       " 'Hospital 0',\n",
       " 'Hospital 1',\n",
       " 'Hospital 2',\n",
       " 'Hospital 3',\n",
       " 'Hospital 4',\n",
       " 'Hospital 5',\n",
       " 'Hospital 6',\n",
       " 'Disease 0',\n",
       " 'Disease 1',\n",
       " 'Disease 2',\n",
       " 'Disease 3',\n",
       " 'Disease 4',\n",
       " 'Disease 5',\n",
       " 'Disease 6',\n",
       " 'Disease 7',\n",
       " '0M ASES',\n",
       " '0M CSS',\n",
       " '0M ERabd',\n",
       " '0M ERside',\n",
       " '0M FF',\n",
       " '0M IR',\n",
       " '0M KSS',\n",
       " '0M MMTgrade',\n",
       " '0M MMTsec',\n",
       " '0M VAS(activity)',\n",
       " '0M VAS(resting)',\n",
       " '0M add',\n",
       " '2M ERabd',\n",
       " '2M ERside',\n",
       " '2M FF',\n",
       " '2M IR',\n",
       " '2M MMTgrade',\n",
       " '2M MMTsec',\n",
       " '2M add',\n",
       " '3M ASES',\n",
       " '3M CSS',\n",
       " '3M ERabd',\n",
       " '3M ERside',\n",
       " '3M FF',\n",
       " '3M IR',\n",
       " '3M KSS',\n",
       " '3M MMTgrade',\n",
       " '3M MMTsec',\n",
       " '3M VAS(activity)',\n",
       " '3M VAS(resting)',\n",
       " '3M add',\n",
       " '4M ASES',\n",
       " '4M CSS',\n",
       " '4M ERabd',\n",
       " '4M ERside',\n",
       " '4M FF',\n",
       " '4M IR',\n",
       " '4M KSS',\n",
       " '4M MMTgrade',\n",
       " '4M MMTsec',\n",
       " '4M VAS(activity)',\n",
       " '4M VAS(resting)',\n",
       " '4M add',\n",
       " '6M ERabd',\n",
       " '6M ERside',\n",
       " '6M FF',\n",
       " '6M IR',\n",
       " '6M MMTgrade',\n",
       " '6M MMTsec',\n",
       " '6M add',\n",
       " 'Pre Goutallier (SSP)',\n",
       " 'Pre Goutallier (SSC)',\n",
       " 'Pre Goutallier (ISP)',\n",
       " 'Pre Goutallier (TM)',\n",
       " '6M Goutallier (SSP)',\n",
       " '6M Goutallier (SSC)',\n",
       " '6M Goutallier (ISP)',\n",
       " '6M Goutallier (TM)',\n",
       " 'Pre Goutallier (SSP) Missing flag',\n",
       " 'Pre Goutallier (SSC) Missing flag',\n",
       " 'Pre Goutallier (ISP) Missing flag',\n",
       " 'Pre Goutallier (TM) Missing flag',\n",
       " '6M Goutallier (SSP) Missing flag',\n",
       " '6M Goutallier (SSC) Missing flag',\n",
       " '6M Goutallier (ISP) Missing flag',\n",
       " '6M Goutallier (TM) Missing flag']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80ba6ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>나이</th>\n",
       "      <th>성별 (M:1,F:2)</th>\n",
       "      <th>Rt:1,Lt:2</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Tearsize (AP,cm)</th>\n",
       "      <th>Tearsize (ML)</th>\n",
       "      <th>Tearsize (retraction)</th>\n",
       "      <th>흡연여부 (비흡연:1,흡연:2)</th>\n",
       "      <th>흡연여부 (비흡연:1,흡연:2) Missing flag</th>\n",
       "      <th>...</th>\n",
       "      <th>6M Goutallier (ISP)</th>\n",
       "      <th>6M Goutallier (TM)</th>\n",
       "      <th>Pre Goutallier (SSP) Missing flag</th>\n",
       "      <th>Pre Goutallier (SSC) Missing flag</th>\n",
       "      <th>Pre Goutallier (ISP) Missing flag</th>\n",
       "      <th>Pre Goutallier (TM) Missing flag</th>\n",
       "      <th>6M Goutallier (SSP) Missing flag</th>\n",
       "      <th>6M Goutallier (SSC) Missing flag</th>\n",
       "      <th>6M Goutallier (ISP) Missing flag</th>\n",
       "      <th>6M Goutallier (TM) Missing flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.112260</td>\n",
       "      <td>-0.239010</td>\n",
       "      <td>0.529347</td>\n",
       "      <td>1.299314</td>\n",
       "      <td>1.236586</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229042</td>\n",
       "      <td>-0.201304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429514</td>\n",
       "      <td>-0.072467</td>\n",
       "      <td>-0.673177</td>\n",
       "      <td>-0.693529</td>\n",
       "      <td>-0.671659</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229042</td>\n",
       "      <td>-0.201304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.344449</td>\n",
       "      <td>-0.488825</td>\n",
       "      <td>-0.913682</td>\n",
       "      <td>-0.927981</td>\n",
       "      <td>-0.896158</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229042</td>\n",
       "      <td>-0.201304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.584307</td>\n",
       "      <td>0.268947</td>\n",
       "      <td>-0.071915</td>\n",
       "      <td>-0.693529</td>\n",
       "      <td>-0.671659</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229042</td>\n",
       "      <td>-0.201304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.050343</td>\n",
       "      <td>-0.209865</td>\n",
       "      <td>0.529347</td>\n",
       "      <td>0.478732</td>\n",
       "      <td>0.450838</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229042</td>\n",
       "      <td>-0.201304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7173</th>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.371571</td>\n",
       "      <td>-1.414487</td>\n",
       "      <td>0.014274</td>\n",
       "      <td>-0.777214</td>\n",
       "      <td>-0.751792</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229042</td>\n",
       "      <td>-0.201304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7174</th>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.038328</td>\n",
       "      <td>0.032052</td>\n",
       "      <td>0.070864</td>\n",
       "      <td>-0.498668</td>\n",
       "      <td>-0.485071</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229042</td>\n",
       "      <td>-0.201304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7175</th>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.778539</td>\n",
       "      <td>0.094077</td>\n",
       "      <td>-0.174047</td>\n",
       "      <td>-0.206960</td>\n",
       "      <td>-0.205745</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229042</td>\n",
       "      <td>-0.201304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7176</th>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.048063</td>\n",
       "      <td>-0.588316</td>\n",
       "      <td>-1.114365</td>\n",
       "      <td>-1.123613</td>\n",
       "      <td>-1.083486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229042</td>\n",
       "      <td>-0.201304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7177</th>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.030424</td>\n",
       "      <td>-0.341497</td>\n",
       "      <td>-0.673177</td>\n",
       "      <td>-0.466425</td>\n",
       "      <td>-0.454196</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229042</td>\n",
       "      <td>-0.201304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7178 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      나이  성별 (M:1,F:2)  Rt:1,Lt:2    Height    Weight  Tearsize (AP,cm)  \\\n",
       "0     70             2          1 -0.112260 -0.239010          0.529347   \n",
       "1     61             1          1  0.429514 -0.072467         -0.673177   \n",
       "2     73             2          1 -0.344449 -0.488825         -0.913682   \n",
       "3     60             1          2  0.584307  0.268947         -0.071915   \n",
       "4     75             2          2 -0.050343 -0.209865          0.529347   \n",
       "...   ..           ...        ...       ...       ...               ...   \n",
       "7173  72             2          2 -0.371571 -1.414487          0.014274   \n",
       "7174  80             1          2  0.038328  0.032052          0.070864   \n",
       "7175  83             2          1  0.778539  0.094077         -0.174047   \n",
       "7176  65             2          1  0.048063 -0.588316         -1.114365   \n",
       "7177  89             2          1 -1.030424 -0.341497         -0.673177   \n",
       "\n",
       "      Tearsize (ML)  Tearsize (retraction)  흡연여부 (비흡연:1,흡연:2)  \\\n",
       "0          1.299314               1.236586                1.0   \n",
       "1         -0.693529              -0.671659                1.0   \n",
       "2         -0.927981              -0.896158                1.0   \n",
       "3         -0.693529              -0.671659                1.0   \n",
       "4          0.478732               0.450838                1.0   \n",
       "...             ...                    ...                ...   \n",
       "7173      -0.777214              -0.751792                1.0   \n",
       "7174      -0.498668              -0.485071                1.0   \n",
       "7175      -0.206960              -0.205745                1.0   \n",
       "7176      -1.123613              -1.083486                1.0   \n",
       "7177      -0.466425              -0.454196                1.0   \n",
       "\n",
       "      흡연여부 (비흡연:1,흡연:2) Missing flag  ...  6M Goutallier (ISP)  \\\n",
       "0                                1.0  ...            -0.229042   \n",
       "1                                1.0  ...            -0.229042   \n",
       "2                                0.0  ...            -0.229042   \n",
       "3                                1.0  ...            -0.229042   \n",
       "4                                1.0  ...            -0.229042   \n",
       "...                              ...  ...                  ...   \n",
       "7173                             1.0  ...            -0.229042   \n",
       "7174                             1.0  ...            -0.229042   \n",
       "7175                             1.0  ...            -0.229042   \n",
       "7176                             1.0  ...            -0.229042   \n",
       "7177                             1.0  ...            -0.229042   \n",
       "\n",
       "      6M Goutallier (TM)  Pre Goutallier (SSP) Missing flag  \\\n",
       "0              -0.201304                                1.0   \n",
       "1              -0.201304                                1.0   \n",
       "2              -0.201304                                0.0   \n",
       "3              -0.201304                                0.0   \n",
       "4              -0.201304                                1.0   \n",
       "...                  ...                                ...   \n",
       "7173           -0.201304                                0.0   \n",
       "7174           -0.201304                                1.0   \n",
       "7175           -0.201304                                1.0   \n",
       "7176           -0.201304                                1.0   \n",
       "7177           -0.201304                                1.0   \n",
       "\n",
       "      Pre Goutallier (SSC) Missing flag  Pre Goutallier (ISP) Missing flag  \\\n",
       "0                                   1.0                                1.0   \n",
       "1                                   1.0                                1.0   \n",
       "2                                   0.0                                0.0   \n",
       "3                                   0.0                                0.0   \n",
       "4                                   1.0                                1.0   \n",
       "...                                 ...                                ...   \n",
       "7173                                0.0                                0.0   \n",
       "7174                                1.0                                1.0   \n",
       "7175                                1.0                                1.0   \n",
       "7176                                1.0                                1.0   \n",
       "7177                                1.0                                1.0   \n",
       "\n",
       "      Pre Goutallier (TM) Missing flag  6M Goutallier (SSP) Missing flag  \\\n",
       "0                                  1.0                               1.0   \n",
       "1                                  1.0                               1.0   \n",
       "2                                  0.0                               0.0   \n",
       "3                                  0.0                               0.0   \n",
       "4                                  1.0                               1.0   \n",
       "...                                ...                               ...   \n",
       "7173                               0.0                               1.0   \n",
       "7174                               1.0                               1.0   \n",
       "7175                               1.0                               1.0   \n",
       "7176                               1.0                               1.0   \n",
       "7177                               1.0                               1.0   \n",
       "\n",
       "      6M Goutallier (SSC) Missing flag  6M Goutallier (ISP) Missing flag  \\\n",
       "0                                  1.0                               1.0   \n",
       "1                                  1.0                               1.0   \n",
       "2                                  0.0                               0.0   \n",
       "3                                  0.0                               0.0   \n",
       "4                                  1.0                               1.0   \n",
       "...                                ...                               ...   \n",
       "7173                               1.0                               1.0   \n",
       "7174                               1.0                               1.0   \n",
       "7175                               1.0                               1.0   \n",
       "7176                               1.0                               1.0   \n",
       "7177                               1.0                               1.0   \n",
       "\n",
       "      6M Goutallier (TM) Missing flag  \n",
       "0                                 1.0  \n",
       "1                                 1.0  \n",
       "2                                 0.0  \n",
       "3                                 0.0  \n",
       "4                                 1.0  \n",
       "...                               ...  \n",
       "7173                              1.0  \n",
       "7174                              1.0  \n",
       "7175                              1.0  \n",
       "7176                              1.0  \n",
       "7177                              1.0  \n",
       "\n",
       "[7178 rows x 91 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[input_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2525c5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POD 6M retear</th>\n",
       "      <th>6M ASES</th>\n",
       "      <th>6M CSS</th>\n",
       "      <th>6M KSS</th>\n",
       "      <th>6M VAS(activity)</th>\n",
       "      <th>6M VAS(resting)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.377047</td>\n",
       "      <td>1.448052</td>\n",
       "      <td>0.201114</td>\n",
       "      <td>1.201822</td>\n",
       "      <td>1.202527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.756417</td>\n",
       "      <td>0.258163</td>\n",
       "      <td>1.336235</td>\n",
       "      <td>-1.788307</td>\n",
       "      <td>-1.761167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.655014</td>\n",
       "      <td>1.087954</td>\n",
       "      <td>-1.004221</td>\n",
       "      <td>1.201822</td>\n",
       "      <td>1.202527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.594953</td>\n",
       "      <td>-0.054966</td>\n",
       "      <td>-0.699962</td>\n",
       "      <td>1.201822</td>\n",
       "      <td>1.202527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.566225</td>\n",
       "      <td>-1.526670</td>\n",
       "      <td>-0.126550</td>\n",
       "      <td>0.205112</td>\n",
       "      <td>0.214629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7173</th>\n",
       "      <td>1</td>\n",
       "      <td>0.576435</td>\n",
       "      <td>-0.284644</td>\n",
       "      <td>0.671297</td>\n",
       "      <td>0.560877</td>\n",
       "      <td>0.567248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7174</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.788472</td>\n",
       "      <td>0.328121</td>\n",
       "      <td>-0.568735</td>\n",
       "      <td>0.205112</td>\n",
       "      <td>0.214629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7175</th>\n",
       "      <td>1</td>\n",
       "      <td>0.678394</td>\n",
       "      <td>-0.617836</td>\n",
       "      <td>-0.355947</td>\n",
       "      <td>2.198532</td>\n",
       "      <td>2.190425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7176</th>\n",
       "      <td>1</td>\n",
       "      <td>0.932377</td>\n",
       "      <td>0.515679</td>\n",
       "      <td>0.898310</td>\n",
       "      <td>0.205112</td>\n",
       "      <td>0.214629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7177</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.787208</td>\n",
       "      <td>-0.546402</td>\n",
       "      <td>-1.884653</td>\n",
       "      <td>0.267591</td>\n",
       "      <td>0.276556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7178 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      POD 6M retear   6M ASES    6M CSS    6M KSS  6M VAS(activity)  \\\n",
       "0                 0  1.377047  1.448052  0.201114          1.201822   \n",
       "1                 0  0.756417  0.258163  1.336235         -1.788307   \n",
       "2                 0 -0.655014  1.087954 -1.004221          1.201822   \n",
       "3                 0 -0.594953 -0.054966 -0.699962          1.201822   \n",
       "4                 0  0.566225 -1.526670 -0.126550          0.205112   \n",
       "...             ...       ...       ...       ...               ...   \n",
       "7173              1  0.576435 -0.284644  0.671297          0.560877   \n",
       "7174              1 -0.788472  0.328121 -0.568735          0.205112   \n",
       "7175              1  0.678394 -0.617836 -0.355947          2.198532   \n",
       "7176              1  0.932377  0.515679  0.898310          0.205112   \n",
       "7177              1 -1.787208 -0.546402 -1.884653          0.267591   \n",
       "\n",
       "      6M VAS(resting)  \n",
       "0            1.202527  \n",
       "1           -1.761167  \n",
       "2            1.202527  \n",
       "3            1.202527  \n",
       "4            0.214629  \n",
       "...               ...  \n",
       "7173         0.567248  \n",
       "7174         0.214629  \n",
       "7175         2.190425  \n",
       "7176         0.214629  \n",
       "7177         0.276556  \n",
       "\n",
       "[7178 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([y_train, X_train[output_columns]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4260e764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(split):\n",
    "  assert split in [\"train\", \"val\", \"test\"]\n",
    "  \n",
    "  X_file_name = f\"{DATA_PATH}/X_{split}.csv\"\n",
    "  y_file_name = f\"{DATA_PATH}/y_{split}.csv\"\n",
    "\n",
    "  X = pd.read_csv(X_file_name)\n",
    "  y = pd.read_csv(y_file_name)\n",
    "  \n",
    "  # static 데이터\n",
    "  X_static_tensor = torch.tensor(X[static_columns].to_numpy(), dtype=torch.float32)\n",
    "\n",
    "  # 시기별 sequential 데이터\n",
    "  X_seq_tensor_0M = torch.tensor(X[seq_columns_0M].to_numpy(), dtype=torch.float32)\n",
    "  X_seq_tensor_2M = torch.tensor(X[seq_columns_2M].to_numpy(), dtype=torch.float32)\n",
    "  X_seq_tensor_3M = torch.tensor(X[seq_columns_3M].to_numpy(), dtype=torch.float32)\n",
    "  X_seq_tensor_4M = torch.tensor(X[seq_columns_4M].to_numpy(), dtype=torch.float32)\n",
    "  X_seq_tensor_6M = torch.tensor(X[seq_columns_6M].to_numpy(), dtype=torch.float32)\n",
    "  \n",
    "  #0M, 6M goutalier 데이터\n",
    "  X_goutalier_tensor_0M = torch.tensor(X[goutallier_columns_0M + goutallier_columns_0M_missing].to_numpy(), dtype=torch.float32)\n",
    "  X_goutalier_tensor_6M = torch.tensor(X[goutallier_columns_6M + goutallier_columns_6M_missing].to_numpy(), dtype=torch.float32)\n",
    "  \n",
    "  # 전체 인풋 데이터\n",
    "  X_tensor = torch.tensor(X[input_columns].to_numpy(), dtype=torch.float32)\n",
    "  \n",
    "  # 6M 예측 데이터\n",
    "  y_tensor = torch.tensor(pd.concat([y, X[output_columns]], axis=1).to_numpy(), dtype=torch.float32)\n",
    "\n",
    "  return TensorDataset(X_tensor, X_static_tensor, X_seq_tensor_0M, X_seq_tensor_2M, X_seq_tensor_3M, X_seq_tensor_4M, X_seq_tensor_6M, X_goutalier_tensor_0M, X_goutalier_tensor_6M, y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a4f36ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존 데이터셋 구조 확인\n",
      "Trainset size: 7178\n",
      "Validset size: 647\n",
      "Testset size: 100\n"
     ]
    }
   ],
   "source": [
    "trainset = get_dataset(\"train\")\n",
    "valset = get_dataset(\"val\")\n",
    "testset = get_dataset(\"test\")\n",
    "\n",
    "print(\"기존 데이터셋 구조 확인\")\n",
    "print(f\"Trainset size: {len(trainset)}\")\n",
    "print(f\"Validset size: {len(valset)}\") # jiseock\n",
    "print(f\"Testset size: {len(testset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e5cc6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static features: 25\n",
      "0M features: 12, 2M features: 7, 3M features: 12\n",
      "4M features: 12, 6M features: 12\n",
      "0M Goutallier features: 8, 6M Goutallier features: 8\n"
     ]
    }
   ],
   "source": [
    "# 특징 크기 확인\n",
    "static_features = len(static_columns)\n",
    "seq_features_0M = len(seq_columns_0M)\n",
    "seq_features_2M = len(seq_columns_2M)\n",
    "seq_features_3M = len(seq_columns_3M)\n",
    "seq_features_4M = len(seq_columns_4M)\n",
    "seq_features_6M = len(seq_columns_6M)\n",
    "goutallier_features_0M = len(goutallier_columns_0M) + len(goutallier_columns_0M_missing)\n",
    "goutallier_features_6M = len(goutallier_columns_6M) + len(goutallier_columns_6M_missing)\n",
    "\n",
    "print(f\"Static features: {static_features}\")\n",
    "print(f\"0M features: {seq_features_0M}, 2M features: {seq_features_2M}, 3M features: {seq_features_3M}\")\n",
    "print(f\"4M features: {seq_features_4M}, 6M features: {seq_features_6M}\")\n",
    "print(f\"0M Goutallier features: {goutallier_features_0M}, 6M Goutallier features: {goutallier_features_6M}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb372e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 - Train: 7178, Test: 100, Valid: 647\n",
      "Model 2 - Train: 7178, Test: 100, Valid: 647\n",
      "Model 3 - Train: 7178, Test: 100, Valid: 647\n",
      "Model 4 - Train: 7178, Test: 100, Valid: 647\n"
     ]
    }
   ],
   "source": [
    "# 각 모델별 데이터셋 생성 함수\n",
    "def get_dataset_model1(split):\n",
    "    \"\"\"Model 1: static + 0M + 0M_goutallier → 2M\"\"\"\n",
    "    assert split in [\"train\", \"val\", \"test\"]\n",
    "    \n",
    "    X_file_name = f\"{DATA_PATH}/X_{split}.csv\"\n",
    "    y_file_name = f\"{DATA_PATH}/y_{split}.csv\"\n",
    "    \n",
    "    X = pd.read_csv(X_file_name)\n",
    "    y = pd.read_csv(y_file_name)\n",
    "    \n",
    "    # 입력: static + 0M + 0M_goutallier\n",
    "    X_static = torch.tensor(X[static_columns].to_numpy(), dtype=torch.float32)\n",
    "    X_0M = torch.tensor(X[seq_columns_0M].to_numpy(), dtype=torch.float32)\n",
    "    X_0M_goutallier = torch.tensor(X[goutallier_columns_0M + goutallier_columns_0M_missing].to_numpy(), dtype=torch.float32)\n",
    "    \n",
    "    # 출력: 2M\n",
    "    y_2M = torch.tensor(X[seq_columns_2M].to_numpy(), dtype=torch.float32)\n",
    "    \n",
    "    return TensorDataset(X_static, X_0M, X_0M_goutallier, y_2M)\n",
    "\n",
    "def get_dataset_model2(split):\n",
    "    \"\"\"Model 2: static + 0M + 2M + 0M_goutallier → 3M\"\"\"\n",
    "    assert split in [\"train\", \"val\", \"test\"]\n",
    "    \n",
    "    X_file_name = f\"{DATA_PATH}/X_{split}.csv\"\n",
    "    y_file_name = f\"{DATA_PATH}/y_{split}.csv\"\n",
    "    \n",
    "    X = pd.read_csv(X_file_name)\n",
    "    y = pd.read_csv(y_file_name)\n",
    "    \n",
    "    # 입력: static + 0M + 2M + 0M_goutallier\n",
    "    X_static = torch.tensor(X[static_columns].to_numpy(), dtype=torch.float32)\n",
    "    X_0M = torch.tensor(X[seq_columns_0M].to_numpy(), dtype=torch.float32)\n",
    "    X_2M = torch.tensor(X[seq_columns_2M].to_numpy(), dtype=torch.float32)\n",
    "    X_0M_goutallier = torch.tensor(X[goutallier_columns_0M + goutallier_columns_0M_missing].to_numpy(), dtype=torch.float32)\n",
    "    \n",
    "    # 출력: 3M\n",
    "    y_3M = torch.tensor(X[seq_columns_3M].to_numpy(), dtype=torch.float32)\n",
    "    \n",
    "    return TensorDataset(X_static, X_0M, X_2M, X_0M_goutallier, y_3M)\n",
    "\n",
    "def get_dataset_model3(split):\n",
    "    \"\"\"Model 3: static + 0M + 2M + 3M + 0M_goutallier → 4M\"\"\"\n",
    "    assert split in [\"train\", \"val\", \"test\"]\n",
    "    \n",
    "    X_file_name = f\"{DATA_PATH}/X_{split}.csv\"\n",
    "    y_file_name = f\"{DATA_PATH}/y_{split}.csv\"\n",
    "    \n",
    "    X = pd.read_csv(X_file_name)\n",
    "    y = pd.read_csv(y_file_name)\n",
    "    \n",
    "    # 입력: static + 0M + 2M + 3M + 0M_goutallier\n",
    "    X_static = torch.tensor(X[static_columns].to_numpy(), dtype=torch.float32)\n",
    "    X_0M = torch.tensor(X[seq_columns_0M].to_numpy(), dtype=torch.float32)\n",
    "    X_2M = torch.tensor(X[seq_columns_2M].to_numpy(), dtype=torch.float32)\n",
    "    X_3M = torch.tensor(X[seq_columns_3M].to_numpy(), dtype=torch.float32)\n",
    "    X_0M_goutallier = torch.tensor(X[goutallier_columns_0M + goutallier_columns_0M_missing].to_numpy(), dtype=torch.float32)\n",
    "    \n",
    "    # 출력: 4M\n",
    "    y_4M = torch.tensor(X[seq_columns_4M].to_numpy(), dtype=torch.float32)\n",
    "    \n",
    "    return TensorDataset(X_static, X_0M, X_2M, X_3M, X_0M_goutallier, y_4M)\n",
    "\n",
    "def get_dataset_model4(split):\n",
    "    \"\"\"Model 4: static + 0M + 2M + 3M + 4M + 0M_goutallier → 6M + y + 6M_goutallier\"\"\"\n",
    "    assert split in [\"train\", \"val\", \"test\"]\n",
    "    \n",
    "    X_file_name = f\"{DATA_PATH}/X_{split}.csv\"\n",
    "    y_file_name = f\"{DATA_PATH}/y_{split}.csv\"\n",
    "    \n",
    "    X = pd.read_csv(X_file_name)\n",
    "    y = pd.read_csv(y_file_name)\n",
    "    \n",
    "    # 입력: static + 0M + 2M + 3M + 4M + 0M_goutallier\n",
    "    X_static = torch.tensor(X[static_columns].to_numpy(), dtype=torch.float32)\n",
    "    X_0M = torch.tensor(X[seq_columns_0M].to_numpy(), dtype=torch.float32)\n",
    "    X_2M = torch.tensor(X[seq_columns_2M].to_numpy(), dtype=torch.float32)\n",
    "    X_3M = torch.tensor(X[seq_columns_3M].to_numpy(), dtype=torch.float32)\n",
    "    X_4M = torch.tensor(X[seq_columns_4M].to_numpy(), dtype=torch.float32)\n",
    "    X_0M_goutallier = torch.tensor(X[goutallier_columns_0M + goutallier_columns_0M_missing].to_numpy(), dtype=torch.float32)\n",
    "    \n",
    "    # 출력: 6M + y + 6M_goutallier\n",
    "    y_6M = torch.tensor(X[seq_columns_6M].to_numpy(), dtype=torch.float32)\n",
    "    y_label = torch.tensor(y[label_column].to_numpy(), dtype=torch.float32).unsqueeze(1)\n",
    "    y_6M_goutallier = torch.tensor(X[goutallier_columns_6M + goutallier_columns_6M_missing].to_numpy(), dtype=torch.float32)\n",
    "    \n",
    "    # 결합: [6M features (12) + y (1) + 6M_goutallier (8)] = 21\n",
    "    y_combined = torch.cat([y_6M, y_label, y_6M_goutallier], dim=1)\n",
    "    \n",
    "    return TensorDataset(X_static, X_0M, X_2M, X_3M, X_4M, X_0M_goutallier, y_combined)\n",
    "\n",
    "# 데이터셋 생성\n",
    "trainset_model1 = get_dataset_model1(\"train\")\n",
    "testset_model1 = get_dataset_model1(\"test\")\n",
    "valset_model1 = get_dataset_model1(\"val\")\n",
    "\n",
    "trainset_model2 = get_dataset_model2(\"train\")\n",
    "testset_model2 = get_dataset_model2(\"test\")\n",
    "valset_model2 = get_dataset_model2(\"val\")\n",
    "\n",
    "trainset_model3 = get_dataset_model3(\"train\")\n",
    "testset_model3 = get_dataset_model3(\"test\")\n",
    "valset_model3 = get_dataset_model3(\"val\")\n",
    "\n",
    "trainset_model4 = get_dataset_model4(\"train\")\n",
    "testset_model4 = get_dataset_model4(\"test\")\n",
    "valset_model4 = get_dataset_model4(\"val\")\n",
    "\n",
    "print(f\"Model 1 - Train: {len(trainset_model1)}, Test: {len(testset_model1)}, Valid: {len(valset_model1)}\")\n",
    "print(f\"Model 2 - Train: {len(trainset_model2)}, Test: {len(testset_model2)}, Valid: {len(valset_model2)}\")\n",
    "print(f\"Model 3 - Train: {len(trainset_model3)}, Test: {len(testset_model3)}, Valid: {len(valset_model3)}\")\n",
    "print(f\"Model 4 - Train: {len(trainset_model4)}, Test: {len(testset_model4)}, Valid: {len(valset_model4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0c77c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistoryCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.train_losses = []\n",
    "        self.test_losses = []\n",
    "    \n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        if len(self.train_losses) == 0:\n",
    "            print(f\"[Train] Available metrics: {list(trainer.callback_metrics.keys())}\")\n",
    "        \n",
    "        train_loss = trainer.callback_metrics.get('train/loss_epoch')\n",
    "        if train_loss is not None:\n",
    "            self.train_losses.append(train_loss.item())\n",
    "        else:\n",
    "            print(f\"Warning: train/loss_epoch not found!\")\n",
    "    \n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        if len(self.test_losses) == 0:\n",
    "            print(f\"[Val] Available metrics: {list(trainer.callback_metrics.keys())}\")\n",
    "        \n",
    "        val_loss = trainer.callback_metrics.get('val/loss')\n",
    "        if val_loss is not None:\n",
    "            self.test_losses.append(val_loss.item())\n",
    "        else:\n",
    "            print(f\"Warning: val/loss not found!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f1208f",
   "metadata": {},
   "source": [
    "### Optuna 모델 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a157bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAS 기반 인코더/헤드 생성 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# NAS 기반 Optuna 하이퍼파라미터 최적화\n",
    "# ============================================================================\n",
    "\n",
    "def create_encoder(trial, input_dim, name_prefix, min_units=32, max_units=256, min_layers=1, max_layers=3):\n",
    "    \"\"\"동적으로 인코더 생성 - NAS 기반\"\"\"\n",
    "    n_layers = trial.suggest_int(f'{name_prefix}_n_layers', min_layers, max_layers)\n",
    "    layers = []\n",
    "    prev_dim = input_dim\n",
    "    \n",
    "    for i in range(n_layers):\n",
    "        units = trial.suggest_int(f'{name_prefix}_units_{i}', min_units, max_units, step=32)\n",
    "        dropout = trial.suggest_float(f'{name_prefix}_dropout_{i}', 0.0, 0.5, step=0.05)\n",
    "        use_batch_norm = trial.suggest_categorical(f'{name_prefix}_batch_norm_{i}', [True, False])\n",
    "        \n",
    "        layers.append(nn.Linear(prev_dim, units))\n",
    "        if use_batch_norm:\n",
    "            layers.append(nn.BatchNorm1d(units))\n",
    "        else:\n",
    "            layers.append(nn.LayerNorm(units))\n",
    "        layers.append(nn.LeakyReLU())\n",
    "        if dropout > 0:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        \n",
    "        prev_dim = units\n",
    "    \n",
    "    return nn.Sequential(*layers), prev_dim\n",
    "\n",
    "def create_output_head(trial, input_dim, output_dim, name_prefix, min_units=64, max_units=512, min_layers=1, max_layers=4):\n",
    "    \"\"\"동적으로 출력 헤드 생성 - NAS 기반\"\"\"\n",
    "    n_layers = trial.suggest_int(f'{name_prefix}_n_layers', min_layers, max_layers)\n",
    "    layers = []\n",
    "    prev_dim = input_dim\n",
    "    \n",
    "    for i in range(n_layers - 1):\n",
    "        units = trial.suggest_int(f'{name_prefix}_units_{i}', min_units, max_units, step=32)\n",
    "        dropout = trial.suggest_float(f'{name_prefix}_dropout_{i}', 0.0, 0.5, step=0.05)\n",
    "        use_batch_norm = trial.suggest_categorical(f'{name_prefix}_batch_norm_{i}', [True, False])\n",
    "        \n",
    "        layers.append(nn.Linear(prev_dim, units))\n",
    "        if use_batch_norm:\n",
    "            layers.append(nn.BatchNorm1d(units))\n",
    "        else:\n",
    "            layers.append(nn.LayerNorm(units))\n",
    "        layers.append(nn.LeakyReLU())\n",
    "        if dropout > 0:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        \n",
    "        prev_dim = units\n",
    "    \n",
    "    # 마지막 레이어 (출력)\n",
    "    layers.append(nn.Linear(prev_dim, output_dim))\n",
    "    \n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "print(\"NAS 기반 인코더/헤드 생성 함수 정의 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "962a3b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적화된 모델 클래스 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# Model 1 최적화 버전\n",
    "class OptimizedSequentialMLP1(L.LightningModule):\n",
    "    def __init__(self, trial, static_features, seq_0M_features, goutallier_0M_features, out_features_2M):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 인코더 생성\n",
    "        self.static_encoder, static_out = create_encoder(\n",
    "            trial, static_features, 'static_encoder', min_units=64, max_units=256\n",
    "        )\n",
    "        \n",
    "        self.seq_0M_encoder, seq_out = create_encoder(\n",
    "            trial, seq_0M_features, 'seq_0M_encoder', min_units=64, max_units=256\n",
    "        )\n",
    "        \n",
    "        self.goutallier_0M_encoder, goutalier_out = create_encoder(\n",
    "            trial, goutallier_0M_features, 'goutallier_0M_encoder', min_units=32, max_units=128\n",
    "        )\n",
    "        \n",
    "        # 특징 결합 후 출력 헤드\n",
    "        feat_dim = static_out + seq_out + goutalier_out\n",
    "        self.output_head = create_output_head(\n",
    "            trial, feat_dim, out_features_2M, 'output_head', min_units=128, max_units=512\n",
    "        )\n",
    "        \n",
    "        # 학습 파라미터\n",
    "        self.lr = trial.suggest_float('lr', 1e-7, 1e-4, log=True)\n",
    "        self.weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-3, log=True)\n",
    "        \n",
    "        self.train_mse = MeanSquaredError()\n",
    "        self.val_mse = MeanSquaredError()\n",
    "        self.test_mse = MeanSquaredError()\n",
    "        \n",
    "    def forward(self, x_static, x_0M, x_0M_goutallier):\n",
    "        static_feat = self.static_encoder(x_static)\n",
    "        seq_0M_feat = self.seq_0M_encoder(x_0M)\n",
    "        goutallier_0M_feat = self.goutallier_0M_encoder(x_0M_goutallier)\n",
    "        \n",
    "        combined = torch.cat([static_feat, seq_0M_feat, goutallier_0M_feat], dim=1)\n",
    "        output = self.output_head(combined)\n",
    "        return output\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_static, x_0M, x_0M_goutallier, y_2M = batch\n",
    "        pred_2M = self.forward(x_static, x_0M, x_0M_goutallier)\n",
    "        loss = F.mse_loss(pred_2M, y_2M)\n",
    "        \n",
    "        self.log(\"train/loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.train_mse.update(pred_2M, y_2M)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_static, x_0M, x_0M_goutallier, y_2M = batch\n",
    "        pred_2M = self.forward(x_static, x_0M, x_0M_goutallier)\n",
    "        loss = F.mse_loss(pred_2M, y_2M)\n",
    "        \n",
    "        self.log(\"val/loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.val_mse.update(pred_2M, y_2M)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        self.log(\"train/mse\", self.train_mse.compute())\n",
    "        self.train_mse.reset()\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        self.log(\"val/mse\", self.val_mse.compute())\n",
    "        self.val_mse.reset()\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x_static, x_0M, x_0M_goutallier, y_2M = batch\n",
    "        pred_2M = self.forward(x_static, x_0M, x_0M_goutallier)\n",
    "        loss = F.mse_loss(pred_2M, y_2M)\n",
    "        \n",
    "        self.log(\"test/loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.test_mse.update(pred_2M, y_2M)\n",
    "        return loss\n",
    "    \n",
    "    def on_test_epoch_end(self):\n",
    "        self.log(\"test/mse\", self.test_mse.compute())\n",
    "        self.test_mse.reset()\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.5, patience=5\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val/loss\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Model 2 최적화 버전\n",
    "class OptimizedSequentialMLP2(L.LightningModule):\n",
    "    def __init__(self, trial, static_features, seq_0M_features, seq_2M_features, goutallier_0M_features, out_features_3M):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.static_encoder, static_out = create_encoder(\n",
    "            trial, static_features, 'static_encoder', min_units=32, max_units=128\n",
    "        )\n",
    "        \n",
    "        self.seq_0M_encoder, seq_0M_out = create_encoder(\n",
    "            trial, seq_0M_features, 'seq_0M_encoder', min_units=64, max_units=256\n",
    "        )\n",
    "        \n",
    "        self.seq_2M_encoder, seq_2M_out = create_encoder(\n",
    "            trial, seq_2M_features, 'seq_2M_encoder', min_units=32, max_units=128\n",
    "        )\n",
    "        \n",
    "        self.goutallier_0M_encoder, goutalier_out = create_encoder(\n",
    "            trial, goutallier_0M_features, 'goutallier_0M_encoder', min_units=32, max_units=128\n",
    "        )\n",
    "        \n",
    "        feat_dim = static_out + seq_0M_out + seq_2M_out + goutalier_out\n",
    "        self.output_head = create_output_head(\n",
    "            trial, feat_dim, out_features_3M, 'output_head', min_units=64, max_units=256\n",
    "        )\n",
    "        \n",
    "        self.lr = trial.suggest_float('lr', 1e-7, 1e-4, log=True)\n",
    "        self.weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-3, log=True)\n",
    "        \n",
    "        self.train_mse = MeanSquaredError()\n",
    "        self.val_mse = MeanSquaredError()\n",
    "        self.test_mse = MeanSquaredError()\n",
    "        \n",
    "    def forward(self, x_static, x_0M, x_2M, x_0M_goutallier):\n",
    "        static_feat = self.static_encoder(x_static)\n",
    "        seq_0M_feat = self.seq_0M_encoder(x_0M)\n",
    "        seq_2M_feat = self.seq_2M_encoder(x_2M)\n",
    "        goutallier_0M_feat = self.goutallier_0M_encoder(x_0M_goutallier)\n",
    "        \n",
    "        combined = torch.cat([static_feat, seq_0M_feat, seq_2M_feat, goutallier_0M_feat], dim=1)\n",
    "        output = self.output_head(combined)\n",
    "        return output\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_static, x_0M, x_2M, x_0M_goutallier, y_3M = batch\n",
    "        pred_3M = self.forward(x_static, x_0M, x_2M, x_0M_goutallier)\n",
    "        loss = F.mse_loss(pred_3M, y_3M)\n",
    "        \n",
    "        self.log(\"train/loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.train_mse.update(pred_3M, y_3M)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_static, x_0M, x_2M, x_0M_goutallier, y_3M = batch\n",
    "        pred_3M = self.forward(x_static, x_0M, x_2M, x_0M_goutallier)\n",
    "        loss = F.mse_loss(pred_3M, y_3M)\n",
    "        \n",
    "        self.log(\"val/loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.val_mse.update(pred_3M, y_3M)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        self.log(\"train/mse\", self.train_mse.compute())\n",
    "        self.train_mse.reset()\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        self.log(\"val/mse\", self.val_mse.compute())\n",
    "        self.val_mse.reset()\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x_static, x_0M, x_2M, x_0M_goutallier, y_3M = batch\n",
    "        pred_3M = self.forward(x_static, x_0M, x_2M, x_0M_goutallier)\n",
    "        loss = F.mse_loss(pred_3M, y_3M)\n",
    "        \n",
    "        self.log(\"test/loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.test_mse.update(pred_3M, y_3M)\n",
    "        return loss\n",
    "    \n",
    "    def on_test_epoch_end(self):\n",
    "        self.log(\"test/mse\", self.test_mse.compute())\n",
    "        self.test_mse.reset()\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.5, patience=5\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val/loss\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Model 3 최적화 버전\n",
    "class OptimizedSequentialMLP3(L.LightningModule):\n",
    "    def __init__(self, trial, static_features, seq_0M_features, seq_2M_features, seq_3M_features, goutallier_0M_features, out_features_4M):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.static_encoder, static_out = create_encoder(\n",
    "            trial, static_features, 'static_encoder', min_units=32, max_units=128\n",
    "        )\n",
    "        \n",
    "        self.seq_0M_encoder, seq_0M_out = create_encoder(\n",
    "            trial, seq_0M_features, 'seq_0M_encoder', min_units=64, max_units=256\n",
    "        )\n",
    "        \n",
    "        self.seq_2M_encoder, seq_2M_out = create_encoder(\n",
    "            trial, seq_2M_features, 'seq_2M_encoder', min_units=32, max_units=128\n",
    "        )\n",
    "        \n",
    "        self.seq_3M_encoder, seq_3M_out = create_encoder(\n",
    "            trial, seq_3M_features, 'seq_3M_encoder', min_units=64, max_units=256\n",
    "        )\n",
    "        \n",
    "        self.goutallier_0M_encoder, goutalier_out = create_encoder(\n",
    "            trial, goutallier_0M_features, 'goutallier_0M_encoder', min_units=32, max_units=128\n",
    "        )\n",
    "        \n",
    "        feat_dim = static_out + seq_0M_out + seq_2M_out + seq_3M_out + goutalier_out\n",
    "        self.output_head = create_output_head(\n",
    "            trial, feat_dim, out_features_4M, 'output_head', min_units=64, max_units=256\n",
    "        )\n",
    "        \n",
    "        self.lr = trial.suggest_float('lr', 1e-7, 1e-4, log=True)\n",
    "        self.weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-3, log=True)\n",
    "        \n",
    "        self.train_mse = MeanSquaredError()\n",
    "        self.val_mse = MeanSquaredError()\n",
    "        self.test_mse = MeanSquaredError()\n",
    "        \n",
    "    def forward(self, x_static, x_0M, x_2M, x_3M, x_0M_goutallier):\n",
    "        static_feat = self.static_encoder(x_static)\n",
    "        seq_0M_feat = self.seq_0M_encoder(x_0M)\n",
    "        seq_2M_feat = self.seq_2M_encoder(x_2M)\n",
    "        seq_3M_feat = self.seq_3M_encoder(x_3M)\n",
    "        goutallier_0M_feat = self.goutallier_0M_encoder(x_0M_goutallier)\n",
    "        \n",
    "        combined = torch.cat([static_feat, seq_0M_feat, seq_2M_feat, seq_3M_feat, goutallier_0M_feat], dim=1)\n",
    "        output = self.output_head(combined)\n",
    "        return output\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_static, x_0M, x_2M, x_3M, x_0M_goutallier, y_4M = batch\n",
    "        pred_4M = self.forward(x_static, x_0M, x_2M, x_3M, x_0M_goutallier)\n",
    "        loss = F.mse_loss(pred_4M, y_4M)\n",
    "        \n",
    "        self.log(\"train/loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.train_mse.update(pred_4M, y_4M)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_static, x_0M, x_2M, x_3M, x_0M_goutallier, y_4M = batch\n",
    "        pred_4M = self.forward(x_static, x_0M, x_2M, x_3M, x_0M_goutallier)\n",
    "        loss = F.mse_loss(pred_4M, y_4M)\n",
    "        \n",
    "        self.log(\"val/loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.val_mse.update(pred_4M, y_4M)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        self.log(\"train/mse\", self.train_mse.compute())\n",
    "        self.train_mse.reset()\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        self.log(\"val/mse\", self.val_mse.compute())\n",
    "        self.val_mse.reset()\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x_static, x_0M, x_2M, x_3M, x_0M_goutallier, y_4M = batch\n",
    "        pred_4M = self.forward(x_static, x_0M, x_2M, x_3M, x_0M_goutallier)\n",
    "        loss = F.mse_loss(pred_4M, y_4M)\n",
    "        \n",
    "        self.log(\"test/loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.test_mse.update(pred_4M, y_4M)\n",
    "        return loss\n",
    "    \n",
    "    def on_test_epoch_end(self):\n",
    "        self.log(\"test/mse\", self.test_mse.compute())\n",
    "        self.test_mse.reset()\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.5, patience=5\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val/loss\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Model 4 최적화 버전 (분류 + 회귀)\n",
    "class OptimizedSequentialMLP4(L.LightningModule):\n",
    "    def __init__(self, trial, static_features, seq_0M_features, seq_2M_features, seq_3M_features, seq_4M_features, goutallier_0M_features, out_features_total):\n",
    "        super().__init__()\n",
    "        self.register_buffer('pos_weight', torch.tensor([1.0]))\n",
    "        \n",
    "        # 회귀 손실 가중치 최적화\n",
    "        self.reg_loss_weight = trial.suggest_float('reg_loss_weight', 0.1, 0.5, step=0.05)\n",
    "        \n",
    "        self.static_encoder, static_out = create_encoder(\n",
    "            trial, static_features, 'static_encoder', min_units=32, max_units=128\n",
    "        )\n",
    "        \n",
    "        self.seq_0M_encoder, seq_0M_out = create_encoder(\n",
    "            trial, seq_0M_features, 'seq_0M_encoder', min_units=64, max_units=256\n",
    "        )\n",
    "        \n",
    "        self.seq_2M_encoder, seq_2M_out = create_encoder(\n",
    "            trial, seq_2M_features, 'seq_2M_encoder', min_units=32, max_units=128\n",
    "        )\n",
    "        \n",
    "        self.seq_3M_encoder, seq_3M_out = create_encoder(\n",
    "            trial, seq_3M_features, 'seq_3M_encoder', min_units=64, max_units=256\n",
    "        )\n",
    "        \n",
    "        self.seq_4M_encoder, seq_4M_out = create_encoder(\n",
    "            trial, seq_4M_features, 'seq_4M_encoder', min_units=64, max_units=256\n",
    "        )\n",
    "        \n",
    "        self.goutallier_0M_encoder, goutalier_out = create_encoder(\n",
    "            trial, goutallier_0M_features, 'goutallier_0M_encoder', min_units=32, max_units=128\n",
    "        )\n",
    "        \n",
    "        feat_dim = static_out + seq_0M_out + seq_2M_out + seq_3M_out + seq_4M_out + goutalier_out\n",
    "        \n",
    "        # 분류 헤드\n",
    "        self.clshead = create_output_head(\n",
    "            trial, feat_dim, 1, 'clshead', min_units=64, max_units=256\n",
    "        )\n",
    "        \n",
    "        # 회귀 헤드\n",
    "        self.reghead = create_output_head(\n",
    "            trial, feat_dim, out_features_total - 1, 'reghead', min_units=128, max_units=512\n",
    "        )\n",
    "        \n",
    "        self.lr = trial.suggest_float('lr', 1e-7, 1e-4, log=True)\n",
    "        self.weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-3, log=True)\n",
    "        \n",
    "        self.train_roc = BinaryAUROC()\n",
    "        self.val_roc = BinaryAUROC()\n",
    "        self.test_roc = BinaryAUROC()\n",
    "        self.val_ap = BinaryAveragePrecision()\n",
    "        self.test_ap = BinaryAveragePrecision()\n",
    "        self.train_mse = MeanSquaredError()\n",
    "        self.val_mse = MeanSquaredError()\n",
    "        self.test_mse = MeanSquaredError()\n",
    "        \n",
    "    def forward(self, x_static, x_0M, x_2M, x_3M, x_4M, x_0M_goutallier):\n",
    "        static_feat = self.static_encoder(x_static)\n",
    "        seq_0M_feat = self.seq_0M_encoder(x_0M)\n",
    "        seq_2M_feat = self.seq_2M_encoder(x_2M)\n",
    "        seq_3M_feat = self.seq_3M_encoder(x_3M)\n",
    "        seq_4M_feat = self.seq_4M_encoder(x_4M)\n",
    "        goutallier_0M_feat = self.goutallier_0M_encoder(x_0M_goutallier)\n",
    "        \n",
    "        combined = torch.cat([static_feat, seq_0M_feat, seq_2M_feat, seq_3M_feat, seq_4M_feat, goutallier_0M_feat], dim=1)\n",
    "        \n",
    "        logits = self.clshead(combined)\n",
    "        regs = self.reghead(combined)\n",
    "        \n",
    "        output = torch.cat([logits, regs], dim=1)\n",
    "        return logits, regs, output\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_static, x_0M, x_2M, x_3M, x_4M, x_0M_goutallier, y_combined = batch\n",
    "        y_label = y_combined[:, seq_features_6M:seq_features_6M+1]\n",
    "        y_reg = torch.cat([y_combined[:, :seq_features_6M], y_combined[:, seq_features_6M+1:]], dim=1)\n",
    "        \n",
    "        logits, regs, _ = self.forward(x_static, x_0M, x_2M, x_3M, x_4M, x_0M_goutallier)\n",
    "        \n",
    "        clf_loss = F.binary_cross_entropy_with_logits(logits, y_label, pos_weight=self.pos_weight)\n",
    "        reg_loss = F.smooth_l1_loss(regs, y_reg)\n",
    "        loss = clf_loss + self.reg_loss_weight * reg_loss\n",
    "        \n",
    "        self.log(\"train/loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train/clf_loss\", clf_loss)\n",
    "        self.log(\"train/reg_loss\", reg_loss)\n",
    "        \n",
    "        probs = logits.sigmoid().flatten()\n",
    "        targets = torch.clamp(y_label.flatten().to(torch.int), 0, 1)\n",
    "        self.train_roc.update(probs, targets)\n",
    "        self.train_mse.update(regs, y_reg)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_static, x_0M, x_2M, x_3M, x_4M, x_0M_goutallier, y_combined = batch\n",
    "        y_label = y_combined[:, seq_features_6M:seq_features_6M+1]\n",
    "        y_reg = torch.cat([y_combined[:, :seq_features_6M], y_combined[:, seq_features_6M+1:]], dim=1)\n",
    "        \n",
    "        logits, regs, _ = self.forward(x_static, x_0M, x_2M, x_3M, x_4M, x_0M_goutallier)\n",
    "        \n",
    "        clf_loss = F.binary_cross_entropy_with_logits(logits, y_label, pos_weight=self.pos_weight)\n",
    "        reg_loss = F.smooth_l1_loss(regs, y_reg)\n",
    "        loss = clf_loss + self.reg_loss_weight * reg_loss\n",
    "        \n",
    "        self.log(\"val/loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val/clf_loss\", clf_loss)\n",
    "        self.log(\"val/reg_loss\", reg_loss)\n",
    "        \n",
    "        probs = logits.sigmoid().flatten()\n",
    "        targets = torch.clamp(y_label.flatten().to(torch.int), 0, 1)\n",
    "        self.val_roc.update(probs, targets)\n",
    "        self.val_ap.update(probs, targets)\n",
    "        self.val_mse.update(regs, y_reg)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        self.log(\"train/roc\", self.train_roc.compute())\n",
    "        self.log(\"train/mse\", self.train_mse.compute())\n",
    "        self.train_roc.reset()\n",
    "        self.train_mse.reset()\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        self.log(\"val/roc\", self.val_roc.compute())\n",
    "        self.log(\"val/ap\", self.val_ap.compute())\n",
    "        self.log(\"val/mse\", self.val_mse.compute())\n",
    "        self.val_roc.reset()\n",
    "        self.val_ap.reset()\n",
    "        self.val_mse.reset()\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x_static, x_0M, x_2M, x_3M, x_4M, x_0M_goutallier, y_combined = batch\n",
    "        y_label = y_combined[:, seq_features_6M:seq_features_6M+1]\n",
    "        y_reg = torch.cat([y_combined[:, :seq_features_6M], y_combined[:, seq_features_6M+1:]], dim=1)\n",
    "        \n",
    "        logits, regs, _ = self.forward(x_static, x_0M, x_2M, x_3M, x_4M, x_0M_goutallier)\n",
    "        \n",
    "        clf_loss = F.binary_cross_entropy_with_logits(logits, y_label, pos_weight=self.pos_weight)\n",
    "        reg_loss = F.smooth_l1_loss(regs, y_reg)\n",
    "        loss = clf_loss + self.reg_loss_weight * reg_loss\n",
    "        \n",
    "        self.log(\"test/loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"test/clf_loss\", clf_loss)\n",
    "        self.log(\"test/reg_loss\", reg_loss)\n",
    "        \n",
    "        probs = logits.sigmoid().flatten()\n",
    "        targets = torch.clamp(y_label.flatten().to(torch.int), 0, 1)\n",
    "        self.test_roc.update(probs, targets)\n",
    "        self.test_ap.update(probs, targets)\n",
    "        self.test_mse.update(regs, y_reg)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def on_test_epoch_end(self):\n",
    "        self.log(\"test/roc\", self.test_roc.compute())\n",
    "        self.log(\"test/ap\", self.test_ap.compute())\n",
    "        self.log(\"test/mse\", self.test_mse.compute())\n",
    "        self.test_roc.reset()\n",
    "        self.test_ap.reset()\n",
    "        self.test_mse.reset()\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='max', factor=0.5, patience=5\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val/roc\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "print(\"최적화된 모델 클래스 정의 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8618290c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "연결된 시계열 모델 생성 완료\n"
     ]
    }
   ],
   "source": [
    "# 연결된 시계열 모델 클래스 (4개 모델을 순차적으로 실행)\n",
    "class SequentialModel(nn.Module):\n",
    "    \"\"\"0M 입력만으로 6M 예측하는 연결된 시계열 모델\"\"\"\n",
    "    def __init__(self, model1, model2, model3, model4):\n",
    "        super().__init__()\n",
    "        self.model1 = model1\n",
    "        self.model2 = model2\n",
    "        self.model3 = model3\n",
    "        self.model4 = model4\n",
    "        \n",
    "        # 평가 모드로 설정\n",
    "        self.model1.eval()\n",
    "        self.model2.eval()\n",
    "        self.model3.eval()\n",
    "        self.model4.eval()\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def forward(self, x_static, x_0M, x_0M_goutallier):\n",
    "        \"\"\"\n",
    "        입력: static, 0M, 0M_goutallier\n",
    "        출력: 6M features, y (logits), 6M_goutallier\n",
    "        \"\"\"\n",
    "        # Model 1: static + 0M + 0M_goutallier → 2M\n",
    "        pred_2M = self.model1(x_static, x_0M, x_0M_goutallier)\n",
    "        \n",
    "        # Model 2: static + 0M + 2M + 0M_goutallier → 3M\n",
    "        pred_3M = self.model2(x_static, x_0M, pred_2M, x_0M_goutallier)\n",
    "        \n",
    "        # Model 3: static + 0M + 2M + 3M + 0M_goutallier → 4M\n",
    "        pred_4M = self.model3(x_static, x_0M, pred_2M, pred_3M, x_0M_goutallier)\n",
    "        \n",
    "        # Model 4: static + 0M + 2M + 3M + 4M + 0M_goutallier → 6M + y + 6M_goutallier\n",
    "        logits, regs, output = self.model4(x_static, x_0M, pred_2M, pred_3M, pred_4M, x_0M_goutallier)\n",
    "        \n",
    "        # 출력 분리: [6M (12) + y (1) + 6M_goutallier (8)]\n",
    "        pred_6M = regs[:, :seq_features_6M]\n",
    "        pred_y_logits = logits\n",
    "        pred_6M_goutallier = regs[:, seq_features_6M:]\n",
    "        \n",
    "        return {\n",
    "            'pred_2M': pred_2M,\n",
    "            'pred_3M': pred_3M,\n",
    "            'pred_4M': pred_4M,\n",
    "            'pred_6M': pred_6M,\n",
    "            'pred_y_logits': pred_y_logits,\n",
    "            'pred_6M_goutallier': pred_6M_goutallier,\n",
    "            'output': output\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb777567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna 최적화 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Optuna 최적화 함수들\n",
    "# ============================================================================\n",
    "\n",
    "def optimize_model1(trial):\n",
    "    \"\"\"Model 1 최적화\"\"\"\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    \n",
    "    model = OptimizedSequentialMLP1(\n",
    "        trial=trial,\n",
    "        static_features=static_features,\n",
    "        seq_0M_features=seq_features_0M,\n",
    "        goutallier_0M_features=goutallier_features_0M,\n",
    "        out_features_2M=seq_features_2M\n",
    "    )\n",
    "    \n",
    "    trainloader = DataLoader(trainset_model1, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    valloader = DataLoader(valset_model1, batch_size=batch_size)\n",
    "    \n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=50,\n",
    "        gradient_clip_val=1.0,\n",
    "        callbacks=[\n",
    "            PyTorchLightningPruningCallback(trial, monitor=\"val/loss\"),\n",
    "            ModelCheckpoint(monitor='val/loss', mode='min', save_top_k=1, filename='optuna-model1-best'),\n",
    "            EarlyStopping(monitor='val/loss', mode='min', patience=10)\n",
    "        ],\n",
    "        enable_progress_bar=False,\n",
    "        logger=False\n",
    "    )\n",
    "    \n",
    "    trainer.fit(model, trainloader, valloader)\n",
    "    return trainer.callback_metrics[\"val/loss\"].item()\n",
    "\n",
    "def optimize_model2(trial):\n",
    "    \"\"\"Model 2 최적화\"\"\"\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    \n",
    "    model = OptimizedSequentialMLP2(\n",
    "        trial=trial,\n",
    "        static_features=static_features,\n",
    "        seq_0M_features=seq_features_0M,\n",
    "        seq_2M_features=seq_features_2M,\n",
    "        goutallier_0M_features=goutallier_features_0M,\n",
    "        out_features_3M=seq_features_3M\n",
    "    )\n",
    "    \n",
    "    trainloader = DataLoader(trainset_model2, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    valloader = DataLoader(valset_model2, batch_size=batch_size)\n",
    "    \n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=50,\n",
    "        gradient_clip_val=1.0,\n",
    "        callbacks=[\n",
    "            PyTorchLightningPruningCallback(trial, monitor=\"val/loss\"),\n",
    "            ModelCheckpoint(monitor='val/loss', mode='min', save_top_k=1, filename='optuna-model2-best'),\n",
    "            EarlyStopping(monitor='val/loss', mode='min', patience=10)\n",
    "        ],\n",
    "        enable_progress_bar=False,\n",
    "        logger=False\n",
    "    )\n",
    "    \n",
    "    trainer.fit(model, trainloader, valloader)\n",
    "    return trainer.callback_metrics[\"val/loss\"].item()\n",
    "\n",
    "def optimize_model3(trial):\n",
    "    \"\"\"Model 3 최적화\"\"\"\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    \n",
    "    model = OptimizedSequentialMLP3(\n",
    "        trial=trial,\n",
    "        static_features=static_features,\n",
    "        seq_0M_features=seq_features_0M,\n",
    "        seq_2M_features=seq_features_2M,\n",
    "        seq_3M_features=seq_features_3M,\n",
    "        goutallier_0M_features=goutallier_features_0M,\n",
    "        out_features_4M=seq_features_4M\n",
    "    )\n",
    "    \n",
    "    trainloader = DataLoader(trainset_model3, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    valloader = DataLoader(valset_model3, batch_size=batch_size)\n",
    "    \n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=50,\n",
    "        gradient_clip_val=1.0,\n",
    "        callbacks=[\n",
    "            PyTorchLightningPruningCallback(trial, monitor=\"val/loss\"),\n",
    "            ModelCheckpoint(monitor='val/loss', mode='min', save_top_k=1, filename='optuna-model3-best'),\n",
    "            EarlyStopping(monitor='val/loss', mode='min', patience=10)\n",
    "        ],\n",
    "        enable_progress_bar=False,\n",
    "        logger=False\n",
    "    )\n",
    "    \n",
    "    trainer.fit(model, trainloader, valloader)\n",
    "    return trainer.callback_metrics[\"val/loss\"].item()\n",
    "\n",
    "def optimize_model4(trial):\n",
    "    \"\"\"Model 4 최적화 (ROC AUC 최대화)\"\"\"\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    \n",
    "    model = OptimizedSequentialMLP4(\n",
    "        trial=trial,\n",
    "        static_features=static_features,\n",
    "        seq_0M_features=seq_features_0M,\n",
    "        seq_2M_features=seq_features_2M,\n",
    "        seq_3M_features=seq_features_3M,\n",
    "        seq_4M_features=seq_features_4M,\n",
    "        goutallier_0M_features=goutallier_features_0M,\n",
    "        out_features_total=seq_features_6M + 1 + goutallier_features_6M\n",
    "    )\n",
    "    \n",
    "    trainloader = DataLoader(trainset_model4, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    valloader = DataLoader(valset_model4, batch_size=batch_size)\n",
    "    \n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=50,\n",
    "        gradient_clip_val=1.0,\n",
    "        callbacks=[\n",
    "            PyTorchLightningPruningCallback(trial, monitor=\"val/roc\"),\n",
    "            ModelCheckpoint(monitor='val/roc', mode='max', save_top_k=1, filename='optuna-model4-best'),\n",
    "            EarlyStopping(monitor='val/roc', mode='max', patience=10)\n",
    "        ],\n",
    "        enable_progress_bar=False,\n",
    "        logger=False\n",
    "    )\n",
    "    \n",
    "    trainer.fit(model, trainloader, valloader)\n",
    "    # ROC AUC를 최대화 (음수로 반환하여 최소화 문제로 변환)\n",
    "    return -trainer.callback_metrics[\"val/roc\"].item()\n",
    "\n",
    "print(\"Optuna 최적화 함수 정의 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5093f440",
   "metadata": {},
   "source": [
    "### Optuna 실행 및 파라미터 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33df9f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-08 23:19:41,410] A new study created in memory with name: sequential_mlp1_optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "NAS 기반 Optuna 하이퍼파라미터 최적화 시작\n",
      "================================================================================\n",
      "\n",
      "[Model 1] 최적화 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type             | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | static_encoder        | Sequential       | 81.9 K | train\n",
      "1 | seq_0M_encoder        | Sequential       | 1.4 K  | train\n",
      "2 | goutallier_0M_encoder | Sequential       | 1.4 K  | train\n",
      "3 | output_head           | Sequential       | 81.1 K | train\n",
      "4 | train_mse             | MeanSquaredError | 0      | train\n",
      "5 | val_mse               | MeanSquaredError | 0      | train\n",
      "6 | test_mse              | MeanSquaredError | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "165 K     Trainable params\n",
      "0         Non-trainable params\n",
      "165 K     Total params\n",
      "0.663     Total estimated model params size (MB)\n",
      "32        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "d:\\miniconda\\envs\\hospital\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "d:\\miniconda\\envs\\hospital\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "Best trial: 0. Best value: 1.04249:  20%|██        | 1/5 [00:29<01:59, 29.85s/it]GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "d:\\miniconda\\envs\\hospital\\lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:751: Checkpoint directory d:\\GitHub\\ARCR-Feedback\\model\\checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type             | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | static_encoder        | Sequential       | 17.7 K | train\n",
      "1 | seq_0M_encoder        | Sequential       | 45.0 K | train\n",
      "2 | goutallier_0M_encoder | Sequential       | 1.4 K  | train\n",
      "3 | output_head           | Sequential       | 386 K  | train\n",
      "4 | train_mse             | MeanSquaredError | 0      | train\n",
      "5 | val_mse               | MeanSquaredError | 0      | train\n",
      "6 | test_mse              | MeanSquaredError | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "450 K     Trainable params\n",
      "0         Non-trainable params\n",
      "450 K     Total params\n",
      "1.804     Total estimated model params size (MB)\n",
      "46        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-08 23:20:11,262] Trial 0 finished with value: 1.042488694190979 and parameters: {'batch_size': 32, 'static_encoder_n_layers': 3, 'static_encoder_units_0': 256, 'static_encoder_dropout_0': 0.05, 'static_encoder_batch_norm_0': False, 'static_encoder_units_1': 192, 'static_encoder_dropout_1': 0.05, 'static_encoder_batch_norm_1': True, 'static_encoder_units_2': 128, 'static_encoder_dropout_2': 0.15000000000000002, 'static_encoder_batch_norm_2': False, 'seq_0M_encoder_n_layers': 1, 'seq_0M_encoder_units_0': 96, 'seq_0M_encoder_dropout_0': 0.25, 'seq_0M_encoder_batch_norm_0': False, 'goutallier_0M_encoder_n_layers': 1, 'goutallier_0M_encoder_units_0': 128, 'goutallier_0M_encoder_dropout_0': 0.5, 'goutallier_0M_encoder_batch_norm_0': True, 'output_head_n_layers': 2, 'output_head_units_0': 224, 'output_head_dropout_0': 0.30000000000000004, 'output_head_batch_norm_0': False, 'lr': 4.1290339178647116e-05, 'weight_decay': 1.3670054101326959e-05}. Best is trial 0 with value: 1.042488694190979.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Best trial: 0. Best value: 1.04249:  40%|████      | 2/5 [01:36<02:34, 51.55s/it]GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type             | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | static_encoder        | Sequential       | 1.8 K  | train\n",
      "1 | seq_0M_encoder        | Sequential       | 71.9 K | train\n",
      "2 | goutallier_0M_encoder | Sequential       | 10.0 K | train\n",
      "3 | output_head           | Sequential       | 208 K  | train\n",
      "4 | train_mse             | MeanSquaredError | 0      | train\n",
      "5 | val_mse               | MeanSquaredError | 0      | train\n",
      "6 | test_mse              | MeanSquaredError | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "291 K     Trainable params\n",
      "0         Non-trainable params\n",
      "291 K     Total params\n",
      "1.167     Total estimated model params size (MB)\n",
      "43        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-08 23:21:18,000] Trial 1 finished with value: 1.0873445272445679 and parameters: {'batch_size': 64, 'static_encoder_n_layers': 3, 'static_encoder_units_0': 64, 'static_encoder_dropout_0': 0.35000000000000003, 'static_encoder_batch_norm_0': True, 'static_encoder_units_1': 96, 'static_encoder_dropout_1': 0.0, 'static_encoder_batch_norm_1': False, 'static_encoder_units_2': 96, 'static_encoder_dropout_2': 0.0, 'static_encoder_batch_norm_2': True, 'seq_0M_encoder_n_layers': 3, 'seq_0M_encoder_units_0': 224, 'seq_0M_encoder_dropout_0': 0.15000000000000002, 'seq_0M_encoder_batch_norm_0': True, 'seq_0M_encoder_units_1': 128, 'seq_0M_encoder_dropout_1': 0.5, 'seq_0M_encoder_batch_norm_1': False, 'seq_0M_encoder_units_2': 96, 'seq_0M_encoder_dropout_2': 0.25, 'seq_0M_encoder_batch_norm_2': True, 'goutallier_0M_encoder_n_layers': 1, 'goutallier_0M_encoder_units_0': 128, 'goutallier_0M_encoder_dropout_0': 0.45, 'goutallier_0M_encoder_batch_norm_0': True, 'output_head_n_layers': 4, 'output_head_units_0': 448, 'output_head_dropout_0': 0.30000000000000004, 'output_head_batch_norm_0': False, 'output_head_units_1': 416, 'output_head_dropout_1': 0.30000000000000004, 'output_head_batch_norm_1': True, 'output_head_units_2': 128, 'output_head_dropout_2': 0.2, 'output_head_batch_norm_2': True, 'lr': 1.147671610763587e-06, 'weight_decay': 0.0005778198075288679}. Best is trial 0 with value: 1.042488694190979.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Best trial: 0. Best value: 1.04249:  60%|██████    | 3/5 [02:37<01:51, 55.86s/it]GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type             | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | static_encoder        | Sequential       | 40.5 K | train\n",
      "1 | seq_0M_encoder        | Sequential       | 18.1 K | train\n",
      "2 | goutallier_0M_encoder | Sequential       | 4.8 K  | train\n",
      "3 | output_head           | Sequential       | 206 K  | train\n",
      "4 | train_mse             | MeanSquaredError | 0      | train\n",
      "5 | val_mse               | MeanSquaredError | 0      | train\n",
      "6 | test_mse              | MeanSquaredError | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "269 K     Trainable params\n",
      "0         Non-trainable params\n",
      "269 K     Total params\n",
      "1.079     Total estimated model params size (MB)\n",
      "40        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-08 23:22:18,986] Trial 2 finished with value: 1.1612049341201782 and parameters: {'batch_size': 64, 'static_encoder_n_layers': 1, 'static_encoder_units_0': 64, 'static_encoder_dropout_0': 0.45, 'static_encoder_batch_norm_0': True, 'seq_0M_encoder_n_layers': 3, 'seq_0M_encoder_units_0': 224, 'seq_0M_encoder_dropout_0': 0.30000000000000004, 'seq_0M_encoder_batch_norm_0': False, 'seq_0M_encoder_units_1': 192, 'seq_0M_encoder_dropout_1': 0.15000000000000002, 'seq_0M_encoder_batch_norm_1': True, 'seq_0M_encoder_units_2': 128, 'seq_0M_encoder_dropout_2': 0.35000000000000003, 'seq_0M_encoder_batch_norm_2': True, 'goutallier_0M_encoder_n_layers': 3, 'goutallier_0M_encoder_units_0': 32, 'goutallier_0M_encoder_dropout_0': 0.5, 'goutallier_0M_encoder_batch_norm_0': False, 'goutallier_0M_encoder_units_1': 96, 'goutallier_0M_encoder_dropout_1': 0.0, 'goutallier_0M_encoder_batch_norm_1': False, 'goutallier_0M_encoder_units_2': 64, 'goutallier_0M_encoder_dropout_2': 0.30000000000000004, 'goutallier_0M_encoder_batch_norm_2': False, 'output_head_n_layers': 3, 'output_head_units_0': 288, 'output_head_dropout_0': 0.45, 'output_head_batch_norm_0': True, 'output_head_units_1': 448, 'output_head_dropout_1': 0.25, 'output_head_batch_norm_1': False, 'lr': 1.1328439878667612e-07, 'weight_decay': 1.1364202595659636e-06}. Best is trial 0 with value: 1.042488694190979.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Best trial: 0. Best value: 1.04249:  80%|████████  | 4/5 [03:11<00:47, 47.09s/it]GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type             | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | static_encoder        | Sequential       | 45.5 K | train\n",
      "1 | seq_0M_encoder        | Sequential       | 71.9 K | train\n",
      "2 | goutallier_0M_encoder | Sequential       | 1.4 K  | train\n",
      "3 | output_head           | Sequential       | 234 K  | train\n",
      "4 | train_mse             | MeanSquaredError | 0      | train\n",
      "5 | val_mse               | MeanSquaredError | 0      | train\n",
      "6 | test_mse              | MeanSquaredError | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "353 K     Trainable params\n",
      "0         Non-trainable params\n",
      "353 K     Total params\n",
      "1.413     Total estimated model params size (MB)\n",
      "40        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-08 23:22:52,634] Trial 3 finished with value: 1.0659668445587158 and parameters: {'batch_size': 128, 'static_encoder_n_layers': 3, 'static_encoder_units_0': 96, 'static_encoder_dropout_0': 0.5, 'static_encoder_batch_norm_0': False, 'static_encoder_units_1': 128, 'static_encoder_dropout_1': 0.5, 'static_encoder_batch_norm_1': True, 'static_encoder_units_2': 192, 'static_encoder_dropout_2': 0.15000000000000002, 'static_encoder_batch_norm_2': True, 'seq_0M_encoder_n_layers': 2, 'seq_0M_encoder_units_0': 64, 'seq_0M_encoder_dropout_0': 0.30000000000000004, 'seq_0M_encoder_batch_norm_0': False, 'seq_0M_encoder_units_1': 256, 'seq_0M_encoder_dropout_1': 0.2, 'seq_0M_encoder_batch_norm_1': True, 'goutallier_0M_encoder_n_layers': 2, 'goutallier_0M_encoder_units_0': 32, 'goutallier_0M_encoder_dropout_0': 0.30000000000000004, 'goutallier_0M_encoder_batch_norm_0': False, 'goutallier_0M_encoder_units_1': 128, 'goutallier_0M_encoder_dropout_1': 0.30000000000000004, 'goutallier_0M_encoder_batch_norm_1': False, 'output_head_n_layers': 2, 'output_head_units_0': 352, 'output_head_dropout_0': 0.45, 'output_head_batch_norm_0': False, 'lr': 1.2779866971421914e-06, 'weight_decay': 5.267100902438421e-06}. Best is trial 0 with value: 1.042488694190979.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Best trial: 0. Best value: 1.04249: 100%|██████████| 5/5 [04:11<00:00, 50.21s/it]\n",
      "[I 2025-11-08 23:23:52,475] A new study created in memory with name: sequential_mlp2_optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-08 23:23:52,466] Trial 4 finished with value: 1.067136287689209 and parameters: {'batch_size': 64, 'static_encoder_n_layers': 3, 'static_encoder_units_0': 128, 'static_encoder_dropout_0': 0.5, 'static_encoder_batch_norm_0': True, 'static_encoder_units_1': 128, 'static_encoder_dropout_1': 0.5, 'static_encoder_batch_norm_1': False, 'static_encoder_units_2': 192, 'static_encoder_dropout_2': 0.30000000000000004, 'static_encoder_batch_norm_2': False, 'seq_0M_encoder_n_layers': 3, 'seq_0M_encoder_units_0': 224, 'seq_0M_encoder_dropout_0': 0.15000000000000002, 'seq_0M_encoder_batch_norm_0': True, 'seq_0M_encoder_units_1': 192, 'seq_0M_encoder_dropout_1': 0.2, 'seq_0M_encoder_batch_norm_1': True, 'seq_0M_encoder_units_2': 128, 'seq_0M_encoder_dropout_2': 0.45, 'seq_0M_encoder_batch_norm_2': False, 'goutallier_0M_encoder_n_layers': 1, 'goutallier_0M_encoder_units_0': 128, 'goutallier_0M_encoder_dropout_0': 0.30000000000000004, 'goutallier_0M_encoder_batch_norm_0': True, 'output_head_n_layers': 2, 'output_head_units_0': 512, 'output_head_dropout_0': 0.30000000000000004, 'output_head_batch_norm_0': True, 'lr': 9.29931116177832e-07, 'weight_decay': 0.0007119633782049011}. Best is trial 0 with value: 1.042488694190979.\n",
      "\n",
      "[Model 1] 최적화 완료!\n",
      "최고 성능: 1.042489\n",
      "최적 파라미터:\n",
      "  batch_size: 32\n",
      "  static_encoder_n_layers: 3\n",
      "  static_encoder_units_0: 256\n",
      "  static_encoder_dropout_0: 0.05\n",
      "  static_encoder_batch_norm_0: False\n",
      "  static_encoder_units_1: 192\n",
      "  static_encoder_dropout_1: 0.05\n",
      "  static_encoder_batch_norm_1: True\n",
      "  static_encoder_units_2: 128\n",
      "  static_encoder_dropout_2: 0.15000000000000002\n",
      "  static_encoder_batch_norm_2: False\n",
      "  seq_0M_encoder_n_layers: 1\n",
      "  seq_0M_encoder_units_0: 96\n",
      "  seq_0M_encoder_dropout_0: 0.25\n",
      "  seq_0M_encoder_batch_norm_0: False\n",
      "  goutallier_0M_encoder_n_layers: 1\n",
      "  goutallier_0M_encoder_units_0: 128\n",
      "  goutallier_0M_encoder_dropout_0: 0.5\n",
      "  goutallier_0M_encoder_batch_norm_0: True\n",
      "  output_head_n_layers: 2\n",
      "  output_head_units_0: 224\n",
      "  output_head_dropout_0: 0.30000000000000004\n",
      "  output_head_batch_norm_0: False\n",
      "  lr: 4.1290339178647116e-05\n",
      "  weight_decay: 1.3670054101326959e-05\n",
      "\n",
      "[Model 2] 최적화 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type             | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | static_encoder        | Sequential       | 3.6 K  | train\n",
      "1 | seq_0M_encoder        | Sequential       | 18.1 K | train\n",
      "2 | seq_2M_encoder        | Sequential       | 640    | train\n",
      "3 | goutallier_0M_encoder | Sequential       | 9.3 K  | train\n",
      "4 | output_head           | Sequential       | 5.4 K  | train\n",
      "5 | train_mse             | MeanSquaredError | 0      | train\n",
      "6 | val_mse               | MeanSquaredError | 0      | train\n",
      "7 | test_mse              | MeanSquaredError | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "37.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "37.0 K    Total params\n",
      "0.148     Total estimated model params size (MB)\n",
      "40        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "Best trial: 0. Best value: 0.862382:  20%|██        | 1/5 [01:35<06:23, 95.83s/it]GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type             | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | static_encoder        | Sequential       | 3.6 K  | train\n",
      "1 | seq_0M_encoder        | Sequential       | 1.4 K  | train\n",
      "2 | seq_2M_encoder        | Sequential       | 26.5 K | train\n",
      "3 | goutallier_0M_encoder | Sequential       | 30.8 K | train\n",
      "4 | output_head           | Sequential       | 131 K  | train\n",
      "5 | train_mse             | MeanSquaredError | 0      | train\n",
      "6 | val_mse               | MeanSquaredError | 0      | train\n",
      "7 | test_mse              | MeanSquaredError | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "193 K     Trainable params\n",
      "0         Non-trainable params\n",
      "193 K     Total params\n",
      "0.776     Total estimated model params size (MB)\n",
      "47        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-08 23:25:28,303] Trial 0 finished with value: 0.8623823523521423 and parameters: {'batch_size': 32, 'static_encoder_n_layers': 1, 'static_encoder_units_0': 128, 'static_encoder_dropout_0': 0.0, 'static_encoder_batch_norm_0': False, 'seq_0M_encoder_n_layers': 3, 'seq_0M_encoder_units_0': 64, 'seq_0M_encoder_dropout_0': 0.35000000000000003, 'seq_0M_encoder_batch_norm_0': False, 'seq_0M_encoder_units_1': 64, 'seq_0M_encoder_dropout_1': 0.15000000000000002, 'seq_0M_encoder_batch_norm_1': True, 'seq_0M_encoder_units_2': 192, 'seq_0M_encoder_dropout_2': 0.45, 'seq_0M_encoder_batch_norm_2': False, 'seq_2M_encoder_n_layers': 1, 'seq_2M_encoder_units_0': 64, 'seq_2M_encoder_dropout_0': 0.15000000000000002, 'seq_2M_encoder_batch_norm_0': True, 'goutallier_0M_encoder_n_layers': 3, 'goutallier_0M_encoder_units_0': 64, 'goutallier_0M_encoder_dropout_0': 0.35000000000000003, 'goutallier_0M_encoder_batch_norm_0': False, 'goutallier_0M_encoder_units_1': 64, 'goutallier_0M_encoder_dropout_1': 0.35000000000000003, 'goutallier_0M_encoder_batch_norm_1': True, 'goutallier_0M_encoder_units_2': 64, 'goutallier_0M_encoder_dropout_2': 0.45, 'goutallier_0M_encoder_batch_norm_2': True, 'output_head_n_layers': 1, 'lr': 6.872477348686306e-06, 'weight_decay': 9.34434736795313e-05}. Best is trial 0 with value: 0.8623823523521423.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Best trial: 1. Best value: 0.84689:  40%|████      | 2/5 [03:32<05:24, 108.20s/it]GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type             | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | static_encoder        | Sequential       | 3.6 K  | train\n",
      "1 | seq_0M_encoder        | Sequential       | 3.4 K  | train\n",
      "2 | seq_2M_encoder        | Sequential       | 4.8 K  | train\n",
      "3 | goutallier_0M_encoder | Sequential       | 5.0 K  | train\n",
      "4 | output_head           | Sequential       | 144 K  | train\n",
      "5 | train_mse             | MeanSquaredError | 0      | train\n",
      "6 | val_mse               | MeanSquaredError | 0      | train\n",
      "7 | test_mse              | MeanSquaredError | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "161 K     Trainable params\n",
      "0         Non-trainable params\n",
      "161 K     Total params\n",
      "0.646     Total estimated model params size (MB)\n",
      "40        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-08 23:27:25,168] Trial 1 finished with value: 0.8468904495239258 and parameters: {'batch_size': 32, 'static_encoder_n_layers': 1, 'static_encoder_units_0': 128, 'static_encoder_dropout_0': 0.15000000000000002, 'static_encoder_batch_norm_0': True, 'seq_0M_encoder_n_layers': 1, 'seq_0M_encoder_units_0': 96, 'seq_0M_encoder_dropout_0': 0.4, 'seq_0M_encoder_batch_norm_0': False, 'seq_2M_encoder_n_layers': 3, 'seq_2M_encoder_units_0': 128, 'seq_2M_encoder_dropout_0': 0.30000000000000004, 'seq_2M_encoder_batch_norm_0': True, 'seq_2M_encoder_units_1': 96, 'seq_2M_encoder_dropout_1': 0.1, 'seq_2M_encoder_batch_norm_1': False, 'seq_2M_encoder_units_2': 128, 'seq_2M_encoder_dropout_2': 0.45, 'seq_2M_encoder_batch_norm_2': True, 'goutallier_0M_encoder_n_layers': 3, 'goutallier_0M_encoder_units_0': 128, 'goutallier_0M_encoder_dropout_0': 0.0, 'goutallier_0M_encoder_batch_norm_0': True, 'goutallier_0M_encoder_units_1': 128, 'goutallier_0M_encoder_dropout_1': 0.25, 'goutallier_0M_encoder_batch_norm_1': False, 'goutallier_0M_encoder_units_2': 96, 'goutallier_0M_encoder_dropout_2': 0.2, 'goutallier_0M_encoder_batch_norm_2': False, 'output_head_n_layers': 3, 'output_head_units_0': 224, 'output_head_dropout_0': 0.15000000000000002, 'output_head_batch_norm_0': False, 'output_head_units_1': 128, 'output_head_dropout_1': 0.0, 'output_head_batch_norm_1': False, 'lr': 3.388190805998407e-05, 'weight_decay': 6.320694554270116e-05}. Best is trial 1 with value: 0.8468904495239258.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Best trial: 1. Best value: 0.84689:  60%|██████    | 3/5 [04:06<02:28, 74.24s/it] GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type             | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | static_encoder        | Sequential       | 5.9 K  | train\n",
      "1 | seq_0M_encoder        | Sequential       | 33.7 K | train\n",
      "2 | seq_2M_encoder        | Sequential       | 17.6 K | train\n",
      "3 | goutallier_0M_encoder | Sequential       | 7.4 K  | train\n",
      "4 | output_head           | Sequential       | 91.3 K | train\n",
      "5 | train_mse             | MeanSquaredError | 0      | train\n",
      "6 | val_mse               | MeanSquaredError | 0      | train\n",
      "7 | test_mse              | MeanSquaredError | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.623     Total estimated model params size (MB)\n",
      "56        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-08 23:27:58,989] Trial 2 finished with value: 1.015425443649292 and parameters: {'batch_size': 128, 'static_encoder_n_layers': 1, 'static_encoder_units_0': 128, 'static_encoder_dropout_0': 0.0, 'static_encoder_batch_norm_0': False, 'seq_0M_encoder_n_layers': 1, 'seq_0M_encoder_units_0': 224, 'seq_0M_encoder_dropout_0': 0.4, 'seq_0M_encoder_batch_norm_0': False, 'seq_2M_encoder_n_layers': 2, 'seq_2M_encoder_units_0': 32, 'seq_2M_encoder_dropout_0': 0.1, 'seq_2M_encoder_batch_norm_0': True, 'seq_2M_encoder_units_1': 128, 'seq_2M_encoder_dropout_1': 0.25, 'seq_2M_encoder_batch_norm_1': False, 'goutallier_0M_encoder_n_layers': 2, 'goutallier_0M_encoder_units_0': 64, 'goutallier_0M_encoder_dropout_0': 0.15000000000000002, 'goutallier_0M_encoder_batch_norm_0': True, 'goutallier_0M_encoder_units_1': 64, 'goutallier_0M_encoder_dropout_1': 0.5, 'goutallier_0M_encoder_batch_norm_1': False, 'output_head_n_layers': 3, 'output_head_units_0': 192, 'output_head_dropout_0': 0.05, 'output_head_batch_norm_0': True, 'output_head_units_1': 192, 'output_head_dropout_1': 0.4, 'output_head_batch_norm_1': False, 'lr': 3.096874777265384e-07, 'weight_decay': 0.00011094606556170264}. Best is trial 1 with value: 0.8468904495239258.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Best trial: 1. Best value: 0.84689:  80%|████████  | 4/5 [04:48<01:01, 61.58s/it]GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type             | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | static_encoder        | Sequential       | 5.9 K  | train\n",
      "1 | seq_0M_encoder        | Sequential       | 1.4 K  | train\n",
      "2 | seq_2M_encoder        | Sequential       | 640    | train\n",
      "3 | goutallier_0M_encoder | Sequential       | 1.1 K  | train\n",
      "4 | output_head           | Sequential       | 3.5 K  | train\n",
      "5 | train_mse             | MeanSquaredError | 0      | train\n",
      "6 | val_mse               | MeanSquaredError | 0      | train\n",
      "7 | test_mse              | MeanSquaredError | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "12.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "12.5 K    Total params\n",
      "0.050     Total estimated model params size (MB)\n",
      "29        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-08 23:28:41,160] Trial 3 finished with value: 0.915486752986908 and parameters: {'batch_size': 128, 'static_encoder_n_layers': 2, 'static_encoder_units_0': 96, 'static_encoder_dropout_0': 0.0, 'static_encoder_batch_norm_0': True, 'static_encoder_units_1': 32, 'static_encoder_dropout_1': 0.4, 'static_encoder_batch_norm_1': True, 'seq_0M_encoder_n_layers': 2, 'seq_0M_encoder_units_0': 160, 'seq_0M_encoder_dropout_0': 0.25, 'seq_0M_encoder_batch_norm_0': True, 'seq_0M_encoder_units_1': 192, 'seq_0M_encoder_dropout_1': 0.05, 'seq_0M_encoder_batch_norm_1': False, 'seq_2M_encoder_n_layers': 3, 'seq_2M_encoder_units_0': 64, 'seq_2M_encoder_dropout_0': 0.1, 'seq_2M_encoder_batch_norm_0': True, 'seq_2M_encoder_units_1': 128, 'seq_2M_encoder_dropout_1': 0.1, 'seq_2M_encoder_batch_norm_1': True, 'seq_2M_encoder_units_2': 64, 'seq_2M_encoder_dropout_2': 0.30000000000000004, 'seq_2M_encoder_batch_norm_2': False, 'goutallier_0M_encoder_n_layers': 2, 'goutallier_0M_encoder_units_0': 96, 'goutallier_0M_encoder_dropout_0': 0.45, 'goutallier_0M_encoder_batch_norm_0': True, 'goutallier_0M_encoder_units_1': 64, 'goutallier_0M_encoder_dropout_1': 0.1, 'goutallier_0M_encoder_batch_norm_1': True, 'output_head_n_layers': 4, 'output_head_units_0': 64, 'output_head_dropout_0': 0.30000000000000004, 'output_head_batch_norm_0': False, 'output_head_units_1': 224, 'output_head_dropout_1': 0.4, 'output_head_batch_norm_1': False, 'output_head_units_2': 224, 'output_head_dropout_2': 0.15000000000000002, 'output_head_batch_norm_2': False, 'lr': 2.8035441839967212e-06, 'weight_decay': 9.43836424437317e-05}. Best is trial 1 with value: 0.8468904495239258.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Best trial: 1. Best value: 0.84689: 100%|██████████| 5/5 [05:16<00:00, 63.38s/it]\n",
      "[I 2025-11-08 23:29:09,406] A new study created in memory with name: sequential_mlp3_optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-08 23:29:09,397] Trial 4 finished with value: 0.9209532737731934 and parameters: {'batch_size': 128, 'static_encoder_n_layers': 2, 'static_encoder_units_0': 96, 'static_encoder_dropout_0': 0.30000000000000004, 'static_encoder_batch_norm_0': False, 'static_encoder_units_1': 32, 'static_encoder_dropout_1': 0.1, 'static_encoder_batch_norm_1': True, 'seq_0M_encoder_n_layers': 1, 'seq_0M_encoder_units_0': 96, 'seq_0M_encoder_dropout_0': 0.4, 'seq_0M_encoder_batch_norm_0': True, 'seq_2M_encoder_n_layers': 1, 'seq_2M_encoder_units_0': 64, 'seq_2M_encoder_dropout_0': 0.35000000000000003, 'seq_2M_encoder_batch_norm_0': False, 'goutallier_0M_encoder_n_layers': 1, 'goutallier_0M_encoder_units_0': 96, 'goutallier_0M_encoder_dropout_0': 0.05, 'goutallier_0M_encoder_batch_norm_0': True, 'output_head_n_layers': 1, 'lr': 6.010700528773055e-06, 'weight_decay': 2.312018427697772e-06}. Best is trial 1 with value: 0.8468904495239258.\n",
      "\n",
      "[Model 2] 최적화 완료!\n",
      "최고 성능: 0.846890\n",
      "최적 파라미터:\n",
      "  batch_size: 32\n",
      "  static_encoder_n_layers: 1\n",
      "  static_encoder_units_0: 128\n",
      "  static_encoder_dropout_0: 0.15000000000000002\n",
      "  static_encoder_batch_norm_0: True\n",
      "  seq_0M_encoder_n_layers: 1\n",
      "  seq_0M_encoder_units_0: 96\n",
      "  seq_0M_encoder_dropout_0: 0.4\n",
      "  seq_0M_encoder_batch_norm_0: False\n",
      "  seq_2M_encoder_n_layers: 3\n",
      "  seq_2M_encoder_units_0: 128\n",
      "  seq_2M_encoder_dropout_0: 0.30000000000000004\n",
      "  seq_2M_encoder_batch_norm_0: True\n",
      "  seq_2M_encoder_units_1: 96\n",
      "  seq_2M_encoder_dropout_1: 0.1\n",
      "  seq_2M_encoder_batch_norm_1: False\n",
      "  seq_2M_encoder_units_2: 128\n",
      "  seq_2M_encoder_dropout_2: 0.45\n",
      "  seq_2M_encoder_batch_norm_2: True\n",
      "  goutallier_0M_encoder_n_layers: 3\n",
      "  goutallier_0M_encoder_units_0: 128\n",
      "  goutallier_0M_encoder_dropout_0: 0.0\n",
      "  goutallier_0M_encoder_batch_norm_0: True\n",
      "  goutallier_0M_encoder_units_1: 128\n",
      "  goutallier_0M_encoder_dropout_1: 0.25\n",
      "  goutallier_0M_encoder_batch_norm_1: False\n",
      "  goutallier_0M_encoder_units_2: 96\n",
      "  goutallier_0M_encoder_dropout_2: 0.2\n",
      "  goutallier_0M_encoder_batch_norm_2: False\n",
      "  output_head_n_layers: 3\n",
      "  output_head_units_0: 224\n",
      "  output_head_dropout_0: 0.15000000000000002\n",
      "  output_head_batch_norm_0: False\n",
      "  output_head_units_1: 128\n",
      "  output_head_dropout_1: 0.0\n",
      "  output_head_batch_norm_1: False\n",
      "  lr: 3.388190805998407e-05\n",
      "  weight_decay: 6.320694554270116e-05\n",
      "\n",
      "[Model 3] 최적화 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type             | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | static_encoder        | Sequential       | 896    | train\n",
      "1 | seq_0M_encoder        | Sequential       | 44.5 K | train\n",
      "2 | seq_2M_encoder        | Sequential       | 13.9 K | train\n",
      "3 | seq_3M_encoder        | Sequential       | 960    | train\n",
      "4 | goutallier_0M_encoder | Sequential       | 8.7 K  | train\n",
      "5 | output_head           | Sequential       | 38.3 K | train\n",
      "6 | train_mse             | MeanSquaredError | 0      | train\n",
      "7 | val_mse               | MeanSquaredError | 0      | train\n",
      "8 | test_mse              | MeanSquaredError | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "107 K     Trainable params\n",
      "0         Non-trainable params\n",
      "107 K     Total params\n",
      "0.429     Total estimated model params size (MB)\n",
      "62        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Best trial: 0. Best value: 1.15364:  20%|██        | 1/5 [00:49<03:16, 49.20s/it]GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type             | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | static_encoder        | Sequential       | 5.4 K  | train\n",
      "1 | seq_0M_encoder        | Sequential       | 32.5 K | train\n",
      "2 | seq_2M_encoder        | Sequential       | 5.2 K  | train\n",
      "3 | seq_3M_encoder        | Sequential       | 960    | train\n",
      "4 | goutallier_0M_encoder | Sequential       | 1.1 K  | train\n",
      "5 | output_head           | Sequential       | 6.5 K  | train\n",
      "6 | train_mse             | MeanSquaredError | 0      | train\n",
      "7 | val_mse               | MeanSquaredError | 0      | train\n",
      "8 | test_mse              | MeanSquaredError | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "51.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "51.7 K    Total params\n",
      "0.207     Total estimated model params size (MB)\n",
      "53        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-08 23:29:58,601] Trial 0 finished with value: 1.1536363363265991 and parameters: {'batch_size': 128, 'static_encoder_n_layers': 1, 'static_encoder_units_0': 32, 'static_encoder_dropout_0': 0.1, 'static_encoder_batch_norm_0': False, 'seq_0M_encoder_n_layers': 3, 'seq_0M_encoder_units_0': 192, 'seq_0M_encoder_dropout_0': 0.4, 'seq_0M_encoder_batch_norm_0': False, 'seq_0M_encoder_units_1': 160, 'seq_0M_encoder_dropout_1': 0.5, 'seq_0M_encoder_batch_norm_1': False, 'seq_0M_encoder_units_2': 64, 'seq_0M_encoder_dropout_2': 0.35000000000000003, 'seq_0M_encoder_batch_norm_2': False, 'seq_2M_encoder_n_layers': 2, 'seq_2M_encoder_units_0': 128, 'seq_2M_encoder_dropout_0': 0.05, 'seq_2M_encoder_batch_norm_0': False, 'seq_2M_encoder_units_1': 96, 'seq_2M_encoder_dropout_1': 0.45, 'seq_2M_encoder_batch_norm_1': False, 'seq_3M_encoder_n_layers': 1, 'seq_3M_encoder_units_0': 64, 'seq_3M_encoder_dropout_0': 0.5, 'seq_3M_encoder_batch_norm_0': True, 'goutallier_0M_encoder_n_layers': 3, 'goutallier_0M_encoder_units_0': 96, 'goutallier_0M_encoder_dropout_0': 0.4, 'goutallier_0M_encoder_batch_norm_0': False, 'goutallier_0M_encoder_units_1': 32, 'goutallier_0M_encoder_dropout_1': 0.4, 'goutallier_0M_encoder_batch_norm_1': False, 'goutallier_0M_encoder_units_2': 128, 'goutallier_0M_encoder_dropout_2': 0.4, 'goutallier_0M_encoder_batch_norm_2': True, 'output_head_n_layers': 4, 'output_head_units_0': 64, 'output_head_dropout_0': 0.35000000000000003, 'output_head_batch_norm_0': False, 'output_head_units_1': 96, 'output_head_dropout_1': 0.25, 'output_head_batch_norm_1': False, 'output_head_units_2': 64, 'output_head_dropout_2': 0.25, 'output_head_batch_norm_2': False, 'lr': 3.2825953901482617e-07, 'weight_decay': 7.641953163184227e-05}. Best is trial 0 with value: 1.1536363363265991.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Best trial: 0. Best value: 1.15364:  40%|████      | 2/5 [01:30<02:13, 44.34s/it]GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type             | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | static_encoder        | Sequential       | 13.3 K | train\n",
      "1 | seq_0M_encoder        | Sequential       | 23.3 K | train\n",
      "2 | seq_2M_encoder        | Sequential       | 320    | train\n",
      "3 | seq_3M_encoder        | Sequential       | 43.8 K | train\n",
      "4 | goutallier_0M_encoder | Sequential       | 14.1 K | train\n",
      "5 | output_head           | Sequential       | 47.5 K | train\n",
      "6 | train_mse             | MeanSquaredError | 0      | train\n",
      "7 | val_mse               | MeanSquaredError | 0      | train\n",
      "8 | test_mse              | MeanSquaredError | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "142 K     Trainable params\n",
      "0         Non-trainable params\n",
      "142 K     Total params\n",
      "0.569     Total estimated model params size (MB)\n",
      "61        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-08 23:30:39,547] Trial 1 finished with value: 1.1801942586898804 and parameters: {'batch_size': 128, 'static_encoder_n_layers': 3, 'static_encoder_units_0': 32, 'static_encoder_dropout_0': 0.1, 'static_encoder_batch_norm_0': True, 'static_encoder_units_1': 32, 'static_encoder_dropout_1': 0.4, 'static_encoder_batch_norm_1': False, 'static_encoder_units_2': 96, 'static_encoder_dropout_2': 0.5, 'static_encoder_batch_norm_2': True, 'seq_0M_encoder_n_layers': 3, 'seq_0M_encoder_units_0': 192, 'seq_0M_encoder_dropout_0': 0.5, 'seq_0M_encoder_batch_norm_0': False, 'seq_0M_encoder_units_1': 64, 'seq_0M_encoder_dropout_1': 0.2, 'seq_0M_encoder_batch_norm_1': True, 'seq_0M_encoder_units_2': 256, 'seq_0M_encoder_dropout_2': 0.0, 'seq_0M_encoder_batch_norm_2': False, 'seq_2M_encoder_n_layers': 3, 'seq_2M_encoder_units_0': 96, 'seq_2M_encoder_dropout_0': 0.1, 'seq_2M_encoder_batch_norm_0': True, 'seq_2M_encoder_units_1': 32, 'seq_2M_encoder_dropout_1': 0.2, 'seq_2M_encoder_batch_norm_1': False, 'seq_2M_encoder_units_2': 32, 'seq_2M_encoder_dropout_2': 0.45, 'seq_2M_encoder_batch_norm_2': False, 'seq_3M_encoder_n_layers': 1, 'seq_3M_encoder_units_0': 64, 'seq_3M_encoder_dropout_0': 0.05, 'seq_3M_encoder_batch_norm_0': False, 'goutallier_0M_encoder_n_layers': 1, 'goutallier_0M_encoder_units_0': 96, 'goutallier_0M_encoder_dropout_0': 0.45, 'goutallier_0M_encoder_batch_norm_0': True, 'output_head_n_layers': 1, 'lr': 2.863593972443282e-07, 'weight_decay': 2.4559238334930872e-05}. Best is trial 0 with value: 1.1536363363265991.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.959004:  60%|██████    | 3/5 [03:08<02:18, 69.12s/it]GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type             | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | static_encoder        | Sequential       | 7.4 K  | train\n",
      "1 | seq_0M_encoder        | Sequential       | 960    | train\n",
      "2 | seq_2M_encoder        | Sequential       | 7.1 K  | train\n",
      "3 | seq_3M_encoder        | Sequential       | 3.4 K  | train\n",
      "4 | goutallier_0M_encoder | Sequential       | 1.1 K  | train\n",
      "5 | output_head           | Sequential       | 84.3 K | train\n",
      "6 | train_mse             | MeanSquaredError | 0      | train\n",
      "7 | val_mse               | MeanSquaredError | 0      | train\n",
      "8 | test_mse              | MeanSquaredError | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "104 K     Trainable params\n",
      "0         Non-trainable params\n",
      "104 K     Total params\n",
      "0.417     Total estimated model params size (MB)\n",
      "45        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-08 23:32:18,146] Trial 2 finished with value: 0.959004282951355 and parameters: {'batch_size': 32, 'static_encoder_n_layers': 3, 'static_encoder_units_0': 96, 'static_encoder_dropout_0': 0.25, 'static_encoder_batch_norm_0': True, 'static_encoder_units_1': 64, 'static_encoder_dropout_1': 0.2, 'static_encoder_batch_norm_1': False, 'static_encoder_units_2': 64, 'static_encoder_dropout_2': 0.4, 'static_encoder_batch_norm_2': True, 'seq_0M_encoder_n_layers': 2, 'seq_0M_encoder_units_0': 160, 'seq_0M_encoder_dropout_0': 0.15000000000000002, 'seq_0M_encoder_batch_norm_0': True, 'seq_0M_encoder_units_1': 128, 'seq_0M_encoder_dropout_1': 0.25, 'seq_0M_encoder_batch_norm_1': False, 'seq_2M_encoder_n_layers': 1, 'seq_2M_encoder_units_0': 32, 'seq_2M_encoder_dropout_0': 0.5, 'seq_2M_encoder_batch_norm_0': False, 'seq_3M_encoder_n_layers': 3, 'seq_3M_encoder_units_0': 128, 'seq_3M_encoder_dropout_0': 0.35000000000000003, 'seq_3M_encoder_batch_norm_0': True, 'seq_3M_encoder_units_1': 128, 'seq_3M_encoder_dropout_1': 0.0, 'seq_3M_encoder_batch_norm_1': False, 'seq_3M_encoder_units_2': 192, 'seq_3M_encoder_dropout_2': 0.15000000000000002, 'seq_3M_encoder_batch_norm_2': False, 'goutallier_0M_encoder_n_layers': 3, 'goutallier_0M_encoder_units_0': 128, 'goutallier_0M_encoder_dropout_0': 0.4, 'goutallier_0M_encoder_batch_norm_0': False, 'goutallier_0M_encoder_units_1': 64, 'goutallier_0M_encoder_dropout_1': 0.4, 'goutallier_0M_encoder_batch_norm_1': False, 'goutallier_0M_encoder_units_2': 64, 'goutallier_0M_encoder_dropout_2': 0.15000000000000002, 'goutallier_0M_encoder_batch_norm_2': True, 'output_head_n_layers': 2, 'output_head_units_0': 96, 'output_head_dropout_0': 0.05, 'output_head_batch_norm_0': True, 'lr': 1.353991669666595e-05, 'weight_decay': 7.921927037578637e-06}. Best is trial 2 with value: 0.959004282951355.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.937405:  80%|████████  | 4/5 [03:59<01:01, 61.76s/it]GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type             | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | static_encoder        | Sequential       | 896    | train\n",
      "1 | seq_0M_encoder        | Sequential       | 1.4 K  | train\n",
      "2 | seq_2M_encoder        | Sequential       | 2.8 K  | train\n",
      "3 | seq_3M_encoder        | Sequential       | 1.4 K  | train\n",
      "4 | goutallier_0M_encoder | Sequential       | 1.4 K  | train\n",
      "5 | output_head           | Sequential       | 90.6 K | train\n",
      "6 | train_mse             | MeanSquaredError | 0      | train\n",
      "7 | val_mse               | MeanSquaredError | 0      | train\n",
      "8 | test_mse              | MeanSquaredError | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "98.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "98.6 K    Total params\n",
      "0.394     Total estimated model params size (MB)\n",
      "46        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-08 23:33:08,630] Trial 3 finished with value: 0.9374052882194519 and parameters: {'batch_size': 64, 'static_encoder_n_layers': 3, 'static_encoder_units_0': 32, 'static_encoder_dropout_0': 0.30000000000000004, 'static_encoder_batch_norm_0': True, 'static_encoder_units_1': 96, 'static_encoder_dropout_1': 0.15000000000000002, 'static_encoder_batch_norm_1': False, 'static_encoder_units_2': 32, 'static_encoder_dropout_2': 0.1, 'static_encoder_batch_norm_2': True, 'seq_0M_encoder_n_layers': 1, 'seq_0M_encoder_units_0': 64, 'seq_0M_encoder_dropout_0': 0.30000000000000004, 'seq_0M_encoder_batch_norm_0': True, 'seq_2M_encoder_n_layers': 2, 'seq_2M_encoder_units_0': 64, 'seq_2M_encoder_dropout_0': 0.25, 'seq_2M_encoder_batch_norm_0': False, 'seq_2M_encoder_units_1': 96, 'seq_2M_encoder_dropout_1': 0.1, 'seq_2M_encoder_batch_norm_1': False, 'seq_3M_encoder_n_layers': 1, 'seq_3M_encoder_units_0': 224, 'seq_3M_encoder_dropout_0': 0.4, 'seq_3M_encoder_batch_norm_0': False, 'goutallier_0M_encoder_n_layers': 1, 'goutallier_0M_encoder_units_0': 96, 'goutallier_0M_encoder_dropout_0': 0.0, 'goutallier_0M_encoder_batch_norm_0': False, 'output_head_n_layers': 2, 'output_head_units_0': 160, 'output_head_dropout_0': 0.1, 'output_head_batch_norm_0': True, 'lr': 1.9962054366834087e-05, 'weight_decay': 8.650574897013576e-05}. Best is trial 3 with value: 0.9374052882194519.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Best trial: 3. Best value: 0.937405: 100%|██████████| 5/5 [05:57<00:00, 71.56s/it]\n",
      "[I 2025-11-08 23:35:07,235] A new study created in memory with name: sequential_mlp4_optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-08 23:35:07,225] Trial 4 finished with value: 1.014063835144043 and parameters: {'batch_size': 32, 'static_encoder_n_layers': 1, 'static_encoder_units_0': 32, 'static_encoder_dropout_0': 0.5, 'static_encoder_batch_norm_0': False, 'seq_0M_encoder_n_layers': 1, 'seq_0M_encoder_units_0': 96, 'seq_0M_encoder_dropout_0': 0.5, 'seq_0M_encoder_batch_norm_0': True, 'seq_2M_encoder_n_layers': 2, 'seq_2M_encoder_units_0': 64, 'seq_2M_encoder_dropout_0': 0.35000000000000003, 'seq_2M_encoder_batch_norm_0': False, 'seq_2M_encoder_units_1': 32, 'seq_2M_encoder_dropout_1': 0.30000000000000004, 'seq_2M_encoder_batch_norm_1': True, 'seq_3M_encoder_n_layers': 1, 'seq_3M_encoder_units_0': 96, 'seq_3M_encoder_dropout_0': 0.15000000000000002, 'seq_3M_encoder_batch_norm_0': True, 'goutallier_0M_encoder_n_layers': 1, 'goutallier_0M_encoder_units_0': 128, 'goutallier_0M_encoder_dropout_0': 0.25, 'goutallier_0M_encoder_batch_norm_0': False, 'output_head_n_layers': 4, 'output_head_units_0': 64, 'output_head_dropout_0': 0.05, 'output_head_batch_norm_0': False, 'output_head_units_1': 192, 'output_head_dropout_1': 0.15000000000000002, 'output_head_batch_norm_1': False, 'output_head_units_2': 256, 'output_head_dropout_2': 0.05, 'output_head_batch_norm_2': False, 'lr': 9.122472897102264e-07, 'weight_decay': 7.314862356262147e-05}. Best is trial 3 with value: 0.9374052882194519.\n",
      "\n",
      "[Model 3] 최적화 완료!\n",
      "최고 성능: 0.937405\n",
      "최적 파라미터:\n",
      "  batch_size: 64\n",
      "  static_encoder_n_layers: 3\n",
      "  static_encoder_units_0: 32\n",
      "  static_encoder_dropout_0: 0.30000000000000004\n",
      "  static_encoder_batch_norm_0: True\n",
      "  static_encoder_units_1: 96\n",
      "  static_encoder_dropout_1: 0.15000000000000002\n",
      "  static_encoder_batch_norm_1: False\n",
      "  static_encoder_units_2: 32\n",
      "  static_encoder_dropout_2: 0.1\n",
      "  static_encoder_batch_norm_2: True\n",
      "  seq_0M_encoder_n_layers: 1\n",
      "  seq_0M_encoder_units_0: 64\n",
      "  seq_0M_encoder_dropout_0: 0.30000000000000004\n",
      "  seq_0M_encoder_batch_norm_0: True\n",
      "  seq_2M_encoder_n_layers: 2\n",
      "  seq_2M_encoder_units_0: 64\n",
      "  seq_2M_encoder_dropout_0: 0.25\n",
      "  seq_2M_encoder_batch_norm_0: False\n",
      "  seq_2M_encoder_units_1: 96\n",
      "  seq_2M_encoder_dropout_1: 0.1\n",
      "  seq_2M_encoder_batch_norm_1: False\n",
      "  seq_3M_encoder_n_layers: 1\n",
      "  seq_3M_encoder_units_0: 224\n",
      "  seq_3M_encoder_dropout_0: 0.4\n",
      "  seq_3M_encoder_batch_norm_0: False\n",
      "  goutallier_0M_encoder_n_layers: 1\n",
      "  goutallier_0M_encoder_units_0: 96\n",
      "  goutallier_0M_encoder_dropout_0: 0.0\n",
      "  goutallier_0M_encoder_batch_norm_0: False\n",
      "  output_head_n_layers: 2\n",
      "  output_head_units_0: 160\n",
      "  output_head_dropout_0: 0.1\n",
      "  output_head_batch_norm_0: True\n",
      "  lr: 1.9962054366834087e-05\n",
      "  weight_decay: 8.650574897013576e-05\n",
      "\n",
      "[Model 4] 최적화 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                  | Type                   | Params | Mode \n",
      "--------------------------------------------------------------------------\n",
      "0  | static_encoder        | Sequential             | 4.3 K  | train\n",
      "1  | seq_0M_encoder        | Sequential             | 23.9 K | train\n",
      "2  | seq_2M_encoder        | Sequential             | 320    | train\n",
      "3  | seq_3M_encoder        | Sequential             | 47.6 K | train\n",
      "4  | seq_4M_encoder        | Sequential             | 960    | train\n",
      "5  | goutallier_0M_encoder | Sequential             | 352    | train\n",
      "6  | clshead               | Sequential             | 117 K  | train\n",
      "7  | reghead               | Sequential             | 638 K  | train\n",
      "8  | train_roc             | BinaryAUROC            | 0      | train\n",
      "9  | val_roc               | BinaryAUROC            | 0      | train\n",
      "10 | test_roc              | BinaryAUROC            | 0      | train\n",
      "11 | val_ap                | BinaryAveragePrecision | 0      | train\n",
      "12 | test_ap               | BinaryAveragePrecision | 0      | train\n",
      "13 | train_mse             | MeanSquaredError       | 0      | train\n",
      "14 | val_mse               | MeanSquaredError       | 0      | train\n",
      "15 | test_mse              | MeanSquaredError       | 0      | train\n",
      "--------------------------------------------------------------------------\n",
      "833 K     Trainable params\n",
      "0         Non-trainable params\n",
      "833 K     Total params\n",
      "3.332     Total estimated model params size (MB)\n",
      "75        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "Best trial: 0. Best value: -0.717544:  20%|██        | 1/5 [01:07<04:30, 67.50s/it]GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                  | Type                   | Params | Mode \n",
      "--------------------------------------------------------------------------\n",
      "0  | static_encoder        | Sequential             | 4.3 K  | train\n",
      "1  | seq_0M_encoder        | Sequential             | 2.9 K  | train\n",
      "2  | seq_2M_encoder        | Sequential             | 9.7 K  | train\n",
      "3  | seq_3M_encoder        | Sequential             | 27.1 K | train\n",
      "4  | seq_4M_encoder        | Sequential             | 1.4 K  | train\n",
      "5  | goutallier_0M_encoder | Sequential             | 20.1 K | train\n",
      "6  | clshead               | Sequential             | 108 K  | train\n",
      "7  | reghead               | Sequential             | 693 K  | train\n",
      "8  | train_roc             | BinaryAUROC            | 0      | train\n",
      "9  | val_roc               | BinaryAUROC            | 0      | train\n",
      "10 | test_roc              | BinaryAUROC            | 0      | train\n",
      "11 | val_ap                | BinaryAveragePrecision | 0      | train\n",
      "12 | test_ap               | BinaryAveragePrecision | 0      | train\n",
      "13 | train_mse             | MeanSquaredError       | 0      | train\n",
      "14 | val_mse               | MeanSquaredError       | 0      | train\n",
      "15 | test_mse              | MeanSquaredError       | 0      | train\n",
      "--------------------------------------------------------------------------\n",
      "867 K     Trainable params\n",
      "0         Non-trainable params\n",
      "867 K     Total params\n",
      "3.470     Total estimated model params size (MB)\n",
      "84        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-08 23:36:14,737] Trial 0 finished with value: -0.7175442576408386 and parameters: {'batch_size': 32, 'reg_loss_weight': 0.25, 'static_encoder_n_layers': 2, 'static_encoder_units_0': 32, 'static_encoder_dropout_0': 0.4, 'static_encoder_batch_norm_0': False, 'static_encoder_units_1': 96, 'static_encoder_dropout_1': 0.30000000000000004, 'static_encoder_batch_norm_1': False, 'seq_0M_encoder_n_layers': 3, 'seq_0M_encoder_units_0': 192, 'seq_0M_encoder_dropout_0': 0.0, 'seq_0M_encoder_batch_norm_0': True, 'seq_0M_encoder_units_1': 64, 'seq_0M_encoder_dropout_1': 0.05, 'seq_0M_encoder_batch_norm_1': True, 'seq_0M_encoder_units_2': 128, 'seq_0M_encoder_dropout_2': 0.4, 'seq_0M_encoder_batch_norm_2': False, 'seq_2M_encoder_n_layers': 1, 'seq_2M_encoder_units_0': 32, 'seq_2M_encoder_dropout_0': 0.1, 'seq_2M_encoder_batch_norm_0': True, 'seq_3M_encoder_n_layers': 3, 'seq_3M_encoder_units_0': 96, 'seq_3M_encoder_dropout_0': 0.30000000000000004, 'seq_3M_encoder_batch_norm_0': True, 'seq_3M_encoder_units_1': 128, 'seq_3M_encoder_dropout_1': 0.0, 'seq_3M_encoder_batch_norm_1': True, 'seq_3M_encoder_units_2': 256, 'seq_3M_encoder_dropout_2': 0.30000000000000004, 'seq_3M_encoder_batch_norm_2': False, 'seq_4M_encoder_n_layers': 1, 'seq_4M_encoder_units_0': 64, 'seq_4M_encoder_dropout_0': 0.5, 'seq_4M_encoder_batch_norm_0': False, 'goutallier_0M_encoder_n_layers': 1, 'goutallier_0M_encoder_units_0': 32, 'goutallier_0M_encoder_dropout_0': 0.45, 'goutallier_0M_encoder_batch_norm_0': False, 'clshead_n_layers': 2, 'clshead_units_0': 192, 'clshead_dropout_0': 0.0, 'clshead_batch_norm_0': False, 'reghead_n_layers': 4, 'reghead_units_0': 512, 'reghead_dropout_0': 0.35000000000000003, 'reghead_batch_norm_0': True, 'reghead_units_1': 352, 'reghead_dropout_1': 0.2, 'reghead_batch_norm_1': True, 'reghead_units_2': 384, 'reghead_dropout_2': 0.05, 'reghead_batch_norm_2': False, 'lr': 7.364761375568211e-06, 'weight_decay': 4.472225152950367e-06}. Best is trial 0 with value: -0.7175442576408386.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Best trial: 1. Best value: -0.723611:  40%|████      | 2/5 [02:59<04:41, 93.69s/it]GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                  | Type                   | Params | Mode \n",
      "--------------------------------------------------------------------------\n",
      "0  | static_encoder        | Sequential             | 3.6 K  | train\n",
      "1  | seq_0M_encoder        | Sequential             | 128 K  | train\n",
      "2  | seq_2M_encoder        | Sequential             | 1.3 K  | train\n",
      "3  | seq_3M_encoder        | Sequential             | 32.5 K | train\n",
      "4  | seq_4M_encoder        | Sequential             | 2.9 K  | train\n",
      "5  | goutallier_0M_encoder | Sequential             | 11.2 K | train\n",
      "6  | clshead               | Sequential             | 127 K  | train\n",
      "7  | reghead               | Sequential             | 557 K  | train\n",
      "8  | train_roc             | BinaryAUROC            | 0      | train\n",
      "9  | val_roc               | BinaryAUROC            | 0      | train\n",
      "10 | test_roc              | BinaryAUROC            | 0      | train\n",
      "11 | val_ap                | BinaryAveragePrecision | 0      | train\n",
      "12 | test_ap               | BinaryAveragePrecision | 0      | train\n",
      "13 | train_mse             | MeanSquaredError       | 0      | train\n",
      "14 | val_mse               | MeanSquaredError       | 0      | train\n",
      "15 | test_mse              | MeanSquaredError       | 0      | train\n",
      "--------------------------------------------------------------------------\n",
      "864 K     Trainable params\n",
      "0         Non-trainable params\n",
      "864 K     Total params\n",
      "3.459     Total estimated model params size (MB)\n",
      "85        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-08 23:38:06,759] Trial 1 finished with value: -0.7236107587814331 and parameters: {'batch_size': 64, 'reg_loss_weight': 0.25, 'static_encoder_n_layers': 2, 'static_encoder_units_0': 32, 'static_encoder_dropout_0': 0.05, 'static_encoder_batch_norm_0': False, 'static_encoder_units_1': 96, 'static_encoder_dropout_1': 0.5, 'static_encoder_batch_norm_1': True, 'seq_0M_encoder_n_layers': 1, 'seq_0M_encoder_units_0': 192, 'seq_0M_encoder_dropout_0': 0.0, 'seq_0M_encoder_batch_norm_0': False, 'seq_2M_encoder_n_layers': 2, 'seq_2M_encoder_units_0': 128, 'seq_2M_encoder_dropout_0': 0.1, 'seq_2M_encoder_batch_norm_0': True, 'seq_2M_encoder_units_1': 64, 'seq_2M_encoder_dropout_1': 0.1, 'seq_2M_encoder_batch_norm_1': True, 'seq_3M_encoder_n_layers': 2, 'seq_3M_encoder_units_0': 128, 'seq_3M_encoder_dropout_0': 0.25, 'seq_3M_encoder_batch_norm_0': False, 'seq_3M_encoder_units_1': 192, 'seq_3M_encoder_dropout_1': 0.35000000000000003, 'seq_3M_encoder_batch_norm_1': False, 'seq_4M_encoder_n_layers': 1, 'seq_4M_encoder_units_0': 96, 'seq_4M_encoder_dropout_0': 0.05, 'seq_4M_encoder_batch_norm_0': True, 'goutallier_0M_encoder_n_layers': 3, 'goutallier_0M_encoder_units_0': 96, 'goutallier_0M_encoder_dropout_0': 0.1, 'goutallier_0M_encoder_batch_norm_0': True, 'goutallier_0M_encoder_units_1': 96, 'goutallier_0M_encoder_dropout_1': 0.45, 'goutallier_0M_encoder_batch_norm_1': False, 'goutallier_0M_encoder_units_2': 96, 'goutallier_0M_encoder_dropout_2': 0.5, 'goutallier_0M_encoder_batch_norm_2': False, 'clshead_n_layers': 4, 'clshead_units_0': 96, 'clshead_dropout_0': 0.35000000000000003, 'clshead_batch_norm_0': False, 'clshead_units_1': 192, 'clshead_dropout_1': 0.5, 'clshead_batch_norm_1': True, 'clshead_units_2': 96, 'clshead_dropout_2': 0.1, 'clshead_batch_norm_2': False, 'reghead_n_layers': 4, 'reghead_units_0': 512, 'reghead_dropout_0': 0.1, 'reghead_batch_norm_0': False, 'reghead_units_1': 384, 'reghead_dropout_1': 0.0, 'reghead_batch_norm_1': False, 'reghead_units_2': 288, 'reghead_dropout_2': 0.35000000000000003, 'reghead_batch_norm_2': True, 'lr': 8.803750572022688e-07, 'weight_decay': 4.188687940648018e-06}. Best is trial 1 with value: -0.7236107587814331.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "Best trial: 1. Best value: -0.723611:  60%|██████    | 3/5 [04:15<02:51, 85.56s/it]GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                  | Type                   | Params | Mode \n",
      "--------------------------------------------------------------------------\n",
      "0  | static_encoder        | Sequential             | 2.7 K  | train\n",
      "1  | seq_0M_encoder        | Sequential             | 3.4 K  | train\n",
      "2  | seq_2M_encoder        | Sequential             | 3.7 K  | train\n",
      "3  | seq_3M_encoder        | Sequential             | 46.9 K | train\n",
      "4  | seq_4M_encoder        | Sequential             | 11.7 K | train\n",
      "5  | goutallier_0M_encoder | Sequential             | 34.9 K | train\n",
      "6  | clshead               | Sequential             | 961    | train\n",
      "7  | reghead               | Sequential             | 19.2 K | train\n",
      "8  | train_roc             | BinaryAUROC            | 0      | train\n",
      "9  | val_roc               | BinaryAUROC            | 0      | train\n",
      "10 | test_roc              | BinaryAUROC            | 0      | train\n",
      "11 | val_ap                | BinaryAveragePrecision | 0      | train\n",
      "12 | test_ap               | BinaryAveragePrecision | 0      | train\n",
      "13 | train_mse             | MeanSquaredError       | 0      | train\n",
      "14 | val_mse               | MeanSquaredError       | 0      | train\n",
      "15 | test_mse              | MeanSquaredError       | 0      | train\n",
      "--------------------------------------------------------------------------\n",
      "123 K     Trainable params\n",
      "0         Non-trainable params\n",
      "123 K     Total params\n",
      "0.494     Total estimated model params size (MB)\n",
      "66        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-08 23:39:22,632] Trial 2 finished with value: -0.7214268445968628 and parameters: {'batch_size': 128, 'reg_loss_weight': 0.2, 'static_encoder_n_layers': 1, 'static_encoder_units_0': 128, 'static_encoder_dropout_0': 0.25, 'static_encoder_batch_norm_0': False, 'seq_0M_encoder_n_layers': 3, 'seq_0M_encoder_units_0': 256, 'seq_0M_encoder_dropout_0': 0.4, 'seq_0M_encoder_batch_norm_0': False, 'seq_0M_encoder_units_1': 256, 'seq_0M_encoder_dropout_1': 0.35000000000000003, 'seq_0M_encoder_batch_norm_1': False, 'seq_0M_encoder_units_2': 224, 'seq_0M_encoder_dropout_2': 0.5, 'seq_0M_encoder_batch_norm_2': True, 'seq_2M_encoder_n_layers': 1, 'seq_2M_encoder_units_0': 128, 'seq_2M_encoder_dropout_0': 0.45, 'seq_2M_encoder_batch_norm_0': True, 'seq_3M_encoder_n_layers': 3, 'seq_3M_encoder_units_0': 64, 'seq_3M_encoder_dropout_0': 0.5, 'seq_3M_encoder_batch_norm_0': False, 'seq_3M_encoder_units_1': 192, 'seq_3M_encoder_dropout_1': 0.1, 'seq_3M_encoder_batch_norm_1': False, 'seq_3M_encoder_units_2': 96, 'seq_3M_encoder_dropout_2': 0.2, 'seq_3M_encoder_batch_norm_2': False, 'seq_4M_encoder_n_layers': 1, 'seq_4M_encoder_units_0': 192, 'seq_4M_encoder_dropout_0': 0.05, 'seq_4M_encoder_batch_norm_0': False, 'goutallier_0M_encoder_n_layers': 3, 'goutallier_0M_encoder_units_0': 32, 'goutallier_0M_encoder_dropout_0': 0.0, 'goutallier_0M_encoder_batch_norm_0': True, 'goutallier_0M_encoder_units_1': 64, 'goutallier_0M_encoder_dropout_1': 0.5, 'goutallier_0M_encoder_batch_norm_1': False, 'goutallier_0M_encoder_units_2': 128, 'goutallier_0M_encoder_dropout_2': 0.05, 'goutallier_0M_encoder_batch_norm_2': True, 'clshead_n_layers': 3, 'clshead_units_0': 128, 'clshead_dropout_0': 0.45, 'clshead_batch_norm_0': True, 'clshead_units_1': 96, 'clshead_dropout_1': 0.4, 'clshead_batch_norm_1': True, 'reghead_n_layers': 4, 'reghead_units_0': 320, 'reghead_dropout_0': 0.4, 'reghead_batch_norm_0': True, 'reghead_units_1': 352, 'reghead_dropout_1': 0.05, 'reghead_batch_norm_1': False, 'reghead_units_2': 416, 'reghead_dropout_2': 0.25, 'reghead_batch_norm_2': True, 'lr': 1.6525474010882326e-06, 'weight_decay': 7.050698707532273e-05}. Best is trial 1 with value: -0.7236107587814331.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: -0.723611:  80%|████████  | 4/5 [07:05<01:58, 118.74s/it]GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                  | Type                   | Params | Mode \n",
      "--------------------------------------------------------------------------\n",
      "0  | static_encoder        | Sequential             | 896    | train\n",
      "1  | seq_0M_encoder        | Sequential             | 2.4 K  | train\n",
      "2  | seq_2M_encoder        | Sequential             | 6.8 K  | train\n",
      "3  | seq_3M_encoder        | Sequential             | 61.5 K | train\n",
      "4  | seq_4M_encoder        | Sequential             | 40.3 K | train\n",
      "5  | goutallier_0M_encoder | Sequential             | 9.8 K  | train\n",
      "6  | clshead               | Sequential             | 737    | train\n",
      "7  | reghead               | Sequential             | 14.7 K | train\n",
      "8  | train_roc             | BinaryAUROC            | 0      | train\n",
      "9  | val_roc               | BinaryAUROC            | 0      | train\n",
      "10 | test_roc              | BinaryAUROC            | 0      | train\n",
      "11 | val_ap                | BinaryAveragePrecision | 0      | train\n",
      "12 | test_ap               | BinaryAveragePrecision | 0      | train\n",
      "13 | train_mse             | MeanSquaredError       | 0      | train\n",
      "14 | val_mse               | MeanSquaredError       | 0      | train\n",
      "15 | test_mse              | MeanSquaredError       | 0      | train\n",
      "--------------------------------------------------------------------------\n",
      "137 K     Trainable params\n",
      "0         Non-trainable params\n",
      "137 K     Total params\n",
      "0.549     Total estimated model params size (MB)\n",
      "61        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-08 23:42:12,233] Trial 3 finished with value: -0.7095365524291992 and parameters: {'batch_size': 32, 'reg_loss_weight': 0.35, 'static_encoder_n_layers': 1, 'static_encoder_units_0': 96, 'static_encoder_dropout_0': 0.2, 'static_encoder_batch_norm_0': False, 'seq_0M_encoder_n_layers': 1, 'seq_0M_encoder_units_0': 224, 'seq_0M_encoder_dropout_0': 0.1, 'seq_0M_encoder_batch_norm_0': True, 'seq_2M_encoder_n_layers': 2, 'seq_2M_encoder_units_0': 32, 'seq_2M_encoder_dropout_0': 0.45, 'seq_2M_encoder_batch_norm_0': False, 'seq_2M_encoder_units_1': 96, 'seq_2M_encoder_dropout_1': 0.1, 'seq_2M_encoder_batch_norm_1': False, 'seq_3M_encoder_n_layers': 3, 'seq_3M_encoder_units_0': 192, 'seq_3M_encoder_dropout_0': 0.4, 'seq_3M_encoder_batch_norm_0': False, 'seq_3M_encoder_units_1': 96, 'seq_3M_encoder_dropout_1': 0.5, 'seq_3M_encoder_batch_norm_1': False, 'seq_3M_encoder_units_2': 256, 'seq_3M_encoder_dropout_2': 0.15000000000000002, 'seq_3M_encoder_batch_norm_2': True, 'seq_4M_encoder_n_layers': 2, 'seq_4M_encoder_units_0': 64, 'seq_4M_encoder_dropout_0': 0.4, 'seq_4M_encoder_batch_norm_0': True, 'seq_4M_encoder_units_1': 160, 'seq_4M_encoder_dropout_1': 0.15000000000000002, 'seq_4M_encoder_batch_norm_1': True, 'goutallier_0M_encoder_n_layers': 3, 'goutallier_0M_encoder_units_0': 128, 'goutallier_0M_encoder_dropout_0': 0.25, 'goutallier_0M_encoder_batch_norm_0': False, 'goutallier_0M_encoder_units_1': 128, 'goutallier_0M_encoder_dropout_1': 0.30000000000000004, 'goutallier_0M_encoder_batch_norm_1': True, 'goutallier_0M_encoder_units_2': 128, 'goutallier_0M_encoder_dropout_2': 0.05, 'goutallier_0M_encoder_batch_norm_2': False, 'clshead_n_layers': 1, 'reghead_n_layers': 1, 'lr': 5.759658777988476e-07, 'weight_decay': 0.0001460339948576517}. Best is trial 1 with value: -0.7236107587814331.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.728585: 100%|██████████| 5/5 [08:03<00:00, 96.76s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-08 23:43:11,008] Trial 4 finished with value: -0.7285852432250977 and parameters: {'batch_size': 32, 'reg_loss_weight': 0.45000000000000007, 'static_encoder_n_layers': 1, 'static_encoder_units_0': 32, 'static_encoder_dropout_0': 0.30000000000000004, 'static_encoder_batch_norm_0': False, 'seq_0M_encoder_n_layers': 1, 'seq_0M_encoder_units_0': 160, 'seq_0M_encoder_dropout_0': 0.5, 'seq_0M_encoder_batch_norm_0': True, 'seq_2M_encoder_n_layers': 3, 'seq_2M_encoder_units_0': 32, 'seq_2M_encoder_dropout_0': 0.5, 'seq_2M_encoder_batch_norm_0': True, 'seq_2M_encoder_units_1': 96, 'seq_2M_encoder_dropout_1': 0.35000000000000003, 'seq_2M_encoder_batch_norm_1': False, 'seq_2M_encoder_units_2': 32, 'seq_2M_encoder_dropout_2': 0.2, 'seq_2M_encoder_batch_norm_2': False, 'seq_3M_encoder_n_layers': 2, 'seq_3M_encoder_units_0': 224, 'seq_3M_encoder_dropout_0': 0.4, 'seq_3M_encoder_batch_norm_0': False, 'seq_3M_encoder_units_1': 256, 'seq_3M_encoder_dropout_1': 0.30000000000000004, 'seq_3M_encoder_batch_norm_1': False, 'seq_4M_encoder_n_layers': 2, 'seq_4M_encoder_units_0': 192, 'seq_4M_encoder_dropout_0': 0.5, 'seq_4M_encoder_batch_norm_0': True, 'seq_4M_encoder_units_1': 192, 'seq_4M_encoder_dropout_1': 0.30000000000000004, 'seq_4M_encoder_batch_norm_1': False, 'goutallier_0M_encoder_n_layers': 2, 'goutallier_0M_encoder_units_0': 128, 'goutallier_0M_encoder_dropout_0': 0.0, 'goutallier_0M_encoder_batch_norm_0': True, 'goutallier_0M_encoder_units_1': 64, 'goutallier_0M_encoder_dropout_1': 0.5, 'goutallier_0M_encoder_batch_norm_1': True, 'clshead_n_layers': 1, 'reghead_n_layers': 1, 'lr': 5.97415220417267e-06, 'weight_decay': 3.815812355173024e-05}. Best is trial 4 with value: -0.7285852432250977.\n",
      "\n",
      "[Model 4] 최적화 완료!\n",
      "최고 성능 (음수 ROC AUC): -0.728585\n",
      "실제 최고 ROC AUC: 0.728585\n",
      "최적 파라미터:\n",
      "  batch_size: 32\n",
      "  reg_loss_weight: 0.45000000000000007\n",
      "  static_encoder_n_layers: 1\n",
      "  static_encoder_units_0: 32\n",
      "  static_encoder_dropout_0: 0.30000000000000004\n",
      "  static_encoder_batch_norm_0: False\n",
      "  seq_0M_encoder_n_layers: 1\n",
      "  seq_0M_encoder_units_0: 160\n",
      "  seq_0M_encoder_dropout_0: 0.5\n",
      "  seq_0M_encoder_batch_norm_0: True\n",
      "  seq_2M_encoder_n_layers: 3\n",
      "  seq_2M_encoder_units_0: 32\n",
      "  seq_2M_encoder_dropout_0: 0.5\n",
      "  seq_2M_encoder_batch_norm_0: True\n",
      "  seq_2M_encoder_units_1: 96\n",
      "  seq_2M_encoder_dropout_1: 0.35000000000000003\n",
      "  seq_2M_encoder_batch_norm_1: False\n",
      "  seq_2M_encoder_units_2: 32\n",
      "  seq_2M_encoder_dropout_2: 0.2\n",
      "  seq_2M_encoder_batch_norm_2: False\n",
      "  seq_3M_encoder_n_layers: 2\n",
      "  seq_3M_encoder_units_0: 224\n",
      "  seq_3M_encoder_dropout_0: 0.4\n",
      "  seq_3M_encoder_batch_norm_0: False\n",
      "  seq_3M_encoder_units_1: 256\n",
      "  seq_3M_encoder_dropout_1: 0.30000000000000004\n",
      "  seq_3M_encoder_batch_norm_1: False\n",
      "  seq_4M_encoder_n_layers: 2\n",
      "  seq_4M_encoder_units_0: 192\n",
      "  seq_4M_encoder_dropout_0: 0.5\n",
      "  seq_4M_encoder_batch_norm_0: True\n",
      "  seq_4M_encoder_units_1: 192\n",
      "  seq_4M_encoder_dropout_1: 0.30000000000000004\n",
      "  seq_4M_encoder_batch_norm_1: False\n",
      "  goutallier_0M_encoder_n_layers: 2\n",
      "  goutallier_0M_encoder_units_0: 128\n",
      "  goutallier_0M_encoder_dropout_0: 0.0\n",
      "  goutallier_0M_encoder_batch_norm_0: True\n",
      "  goutallier_0M_encoder_units_1: 64\n",
      "  goutallier_0M_encoder_dropout_1: 0.5\n",
      "  goutallier_0M_encoder_batch_norm_1: True\n",
      "  clshead_n_layers: 1\n",
      "  reghead_n_layers: 1\n",
      "  lr: 5.97415220417267e-06\n",
      "  weight_decay: 3.815812355173024e-05\n",
      "\n",
      "================================================================================\n",
      "모든 모델 최적화 완료!\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_trials = 5  # 각 모델당 시도 횟수 (필요에 따라 조정 가능)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"NAS 기반 Optuna 하이퍼파라미터 최적화 시작\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Model 1 최적화\n",
    "print(\"\\n[Model 1] 최적화 시작...\")\n",
    "study1 = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    study_name='sequential_mlp1_optimization',\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=10)\n",
    ")\n",
    "study1.optimize(optimize_model1, n_trials=n_trials, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\n[Model 1] 최적화 완료!\")\n",
    "print(f\"최고 성능: {study1.best_value:.6f}\")\n",
    "print(f\"최적 파라미터:\")\n",
    "for key, value in study1.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Model 2 최적화\n",
    "print(\"\\n[Model 2] 최적화 시작...\")\n",
    "study2 = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    study_name='sequential_mlp2_optimization',\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=10)\n",
    ")\n",
    "study2.optimize(optimize_model2, n_trials=n_trials, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\n[Model 2] 최적화 완료!\")\n",
    "print(f\"최고 성능: {study2.best_value:.6f}\")\n",
    "print(f\"최적 파라미터:\")\n",
    "for key, value in study2.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Model 3 최적화\n",
    "print(\"\\n[Model 3] 최적화 시작...\")\n",
    "study3 = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    study_name='sequential_mlp3_optimization',\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=10)\n",
    ")\n",
    "study3.optimize(optimize_model3, n_trials=n_trials, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\n[Model 3] 최적화 완료!\")\n",
    "print(f\"최고 성능: {study3.best_value:.6f}\")\n",
    "print(f\"최적 파라미터:\")\n",
    "for key, value in study3.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Model 4 최적화\n",
    "print(\"\\n[Model 4] 최적화 시작...\")\n",
    "study4 = optuna.create_study(\n",
    "    direction='minimize',  # 음수 ROC AUC를 최소화 = ROC AUC 최대화\n",
    "    study_name='sequential_mlp4_optimization',\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=10)\n",
    ")\n",
    "study4.optimize(optimize_model4, n_trials=n_trials, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\n[Model 4] 최적화 완료!\")\n",
    "print(f\"최고 성능 (음수 ROC AUC): {study4.best_value:.6f}\")\n",
    "print(f\"실제 최고 ROC AUC: {-study4.best_value:.6f}\")\n",
    "print(f\"최적 파라미터:\")\n",
    "for key, value in study4.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"모든 모델 최적화 완료!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730cfac5",
   "metadata": {},
   "source": [
    "### 개별 모델 및 Sequential 모델 성능 평가 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6119ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "성능 평가 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_individual_model(model, testloader, model_name):\n",
    "    \"\"\"개별 모델의 성능 평가\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    for batch in testloader:\n",
    "        if model_name == \"Model1\":\n",
    "            x_static, x_0M, x_0M_goutallier, y_2M = batch\n",
    "            pred = model(x_static, x_0M, x_0M_goutallier)\n",
    "            all_preds.append(pred)\n",
    "            all_targets.append(y_2M)\n",
    "        elif model_name == \"Model2\":\n",
    "            x_static, x_0M, x_2M, x_0M_goutallier, y_3M = batch\n",
    "            pred = model(x_static, x_0M, x_2M, x_0M_goutallier)\n",
    "            all_preds.append(pred)\n",
    "            all_targets.append(y_3M)\n",
    "        elif model_name == \"Model3\":\n",
    "            x_static, x_0M, x_2M, x_3M, x_0M_goutallier, y_4M = batch\n",
    "            pred = model(x_static, x_0M, x_2M, x_3M, x_0M_goutallier)\n",
    "            all_preds.append(pred)\n",
    "            all_targets.append(y_4M)\n",
    "        elif model_name == \"Model4\":\n",
    "            x_static, x_0M, x_2M, x_3M, x_4M, x_0M_goutallier, y_combined = batch\n",
    "            logits, regs, _ = model(x_static, x_0M, x_2M, x_3M, x_4M, x_0M_goutallier)\n",
    "            y_label = y_combined[:, seq_features_6M:seq_features_6M+1]\n",
    "            y_reg = torch.cat([y_combined[:, :seq_features_6M], y_combined[:, seq_features_6M+1:]], dim=1)\n",
    "            \n",
    "            all_preds.append({'logits': logits, 'regs': regs})\n",
    "            all_targets.append({'label': y_label, 'reg': y_reg})\n",
    "    \n",
    "    if model_name == \"Model4\":\n",
    "        # 분류 및 회귀 성능 계산\n",
    "        all_logits = torch.cat([p['logits'] for p in all_preds], dim=0)\n",
    "        all_regs = torch.cat([p['regs'] for p in all_preds], dim=0)\n",
    "        all_labels = torch.cat([t['label'] for t in all_targets], dim=0)\n",
    "        all_reg_targets = torch.cat([t['reg'] for t in all_targets], dim=0)\n",
    "        \n",
    "        mse = F.mse_loss(all_regs, all_reg_targets).item()\n",
    "        probs = all_logits.sigmoid().flatten()\n",
    "        labels_int = all_labels.flatten().to(torch.int)\n",
    "        \n",
    "        # 분류 성능 계산\n",
    "        pred_labels = (probs > 0.5).int().cpu().numpy()\n",
    "        labels_np = labels_int.cpu().numpy()\n",
    "        \n",
    "        roc_auc = roc_auc_score(labels_np, probs.cpu().numpy())\n",
    "        ap = average_precision_score(labels_np, probs.cpu().numpy())\n",
    "        accuracy = accuracy_score(labels_np, pred_labels)\n",
    "        \n",
    "        return {\n",
    "            'mse': mse,\n",
    "            'roc_auc': roc_auc,\n",
    "            'ap': ap,\n",
    "            'accuracy': accuracy\n",
    "        }\n",
    "    else:\n",
    "        # 회귀 성능만 계산\n",
    "        all_preds = torch.cat(all_preds, dim=0)\n",
    "        all_targets = torch.cat(all_targets, dim=0)\n",
    "        mse = F.mse_loss(all_preds, all_targets).item()\n",
    "        mae = F.l1_loss(all_preds, all_targets).item()\n",
    "        \n",
    "        return {\n",
    "            'mse': mse,\n",
    "            'mae': mae\n",
    "        }\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_sequential_model(sequential_model, testset_model1):\n",
    "    \"\"\"Sequential 모델의 성능 평가 (0M 입력만으로 전체 시계열 예측)\"\"\"\n",
    "    sequential_model.eval()\n",
    "    \n",
    "    all_pred_2M = []\n",
    "    all_pred_3M = []\n",
    "    all_pred_4M = []\n",
    "    all_pred_6M = []\n",
    "    all_pred_y_logits = []\n",
    "    all_pred_6M_goutallier = []\n",
    "    \n",
    "    all_true_2M = []\n",
    "    all_true_3M = []\n",
    "    all_true_4M = []\n",
    "    all_true_6M = []\n",
    "    all_true_y = []\n",
    "    all_true_6M_goutallier = []\n",
    "    \n",
    "    for i in range(len(testset_model1)):\n",
    "        x_static, x_0M, x_0M_goutallier, y_2M = testset_model1[i]\n",
    "        x_static = x_static.unsqueeze(0)\n",
    "        x_0M = x_0M.unsqueeze(0)\n",
    "        x_0M_goutallier = x_0M_goutallier.unsqueeze(0)\n",
    "        \n",
    "        # Sequential 모델 예측\n",
    "        predictions = sequential_model(x_static, x_0M, x_0M_goutallier)\n",
    "        \n",
    "        all_pred_2M.append(predictions['pred_2M'])\n",
    "        all_pred_3M.append(predictions['pred_3M'])\n",
    "        all_pred_4M.append(predictions['pred_4M'])\n",
    "        all_pred_6M.append(predictions['pred_6M'])\n",
    "        all_pred_y_logits.append(predictions['pred_y_logits'])\n",
    "        all_pred_6M_goutallier.append(predictions['pred_6M_goutallier'])\n",
    "        \n",
    "        # 실제 값 추출\n",
    "        _, _, _, _, y_3M = testset_model2[i]\n",
    "        _, _, _, _, _, y_4M = testset_model3[i]\n",
    "        _, _, _, _, _, _, y_combined = testset_model4[i]\n",
    "        \n",
    "        y_6M = y_combined[:seq_features_6M]\n",
    "        y_label = y_combined[seq_features_6M:seq_features_6M+1]\n",
    "        y_6M_goutallier = y_combined[seq_features_6M+1:]\n",
    "        \n",
    "        all_true_2M.append(y_2M)\n",
    "        all_true_3M.append(y_3M)\n",
    "        all_true_4M.append(y_4M)\n",
    "        all_true_6M.append(y_6M)\n",
    "        all_true_y.append(y_label)\n",
    "        all_true_6M_goutallier.append(y_6M_goutallier)\n",
    "    \n",
    "    # 텐서로 변환\n",
    "    pred_2M = torch.cat(all_pred_2M, dim=0)\n",
    "    pred_3M = torch.cat(all_pred_3M, dim=0)\n",
    "    pred_4M = torch.cat(all_pred_4M, dim=0)\n",
    "    pred_6M = torch.cat(all_pred_6M, dim=0)\n",
    "    pred_y_logits = torch.cat(all_pred_y_logits, dim=0)\n",
    "    pred_6M_goutallier = torch.cat(all_pred_6M_goutallier, dim=0)\n",
    "    \n",
    "    true_2M = torch.stack(all_true_2M)\n",
    "    true_3M = torch.stack(all_true_3M)\n",
    "    true_4M = torch.stack(all_true_4M)\n",
    "    true_6M = torch.stack(all_true_6M)\n",
    "    true_y = torch.stack(all_true_y)\n",
    "    true_6M_goutallier = torch.stack(all_true_6M_goutallier)\n",
    "    \n",
    "    # 성능 계산\n",
    "    mse_2M = F.mse_loss(pred_2M, true_2M).item()\n",
    "    mse_3M = F.mse_loss(pred_3M, true_3M).item()\n",
    "    mse_4M = F.mse_loss(pred_4M, true_4M).item()\n",
    "    mse_6M = F.mse_loss(pred_6M, true_6M).item()\n",
    "    mse_6M_goutallier = F.mse_loss(pred_6M_goutallier, true_6M_goutallier).item()\n",
    "    \n",
    "    mae_2M = F.l1_loss(pred_2M, true_2M).item()\n",
    "    mae_3M = F.l1_loss(pred_3M, true_3M).item()\n",
    "    mae_4M = F.l1_loss(pred_4M, true_4M).item()\n",
    "    mae_6M = F.l1_loss(pred_6M, true_6M).item()\n",
    "    mae_6M_goutallier = F.l1_loss(pred_6M_goutallier, true_6M_goutallier).item()\n",
    "    \n",
    "    # 분류 성능\n",
    "    pred_y_probs = pred_y_logits.sigmoid().flatten()\n",
    "    true_y_int = true_y.flatten().to(torch.int)\n",
    "    \n",
    "    # 분류 예측 및 성능 계산\n",
    "    pred_labels = (pred_y_probs > 0.5).int().cpu().numpy()\n",
    "    labels_np = true_y_int.cpu().numpy()\n",
    "    \n",
    "    roc_auc = roc_auc_score(labels_np, pred_y_probs.cpu().numpy())\n",
    "    ap = average_precision_score(labels_np, pred_y_probs.cpu().numpy())\n",
    "    accuracy = accuracy_score(labels_np, pred_labels)\n",
    "    \n",
    "    return {\n",
    "        'mse_2M': mse_2M,\n",
    "        'mse_3M': mse_3M,\n",
    "        'mse_4M': mse_4M,\n",
    "        'mse_6M': mse_6M,\n",
    "        'mse_6M_goutallier': mse_6M_goutallier,\n",
    "        'mae_2M': mae_2M,\n",
    "        'mae_3M': mae_3M,\n",
    "        'mae_4M': mae_4M,\n",
    "        'mae_6M': mae_6M,\n",
    "        'mae_6M_goutallier': mae_6M_goutallier,\n",
    "        'roc_auc': roc_auc,\n",
    "        'ap': ap,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "\n",
    "print(\"성능 평가 함수 정의 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599c2387",
   "metadata": {},
   "source": [
    "### 최적화된 파라미터로 최종 모델 생성 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7312cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "d:\\miniconda\\envs\\hospital\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type             | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | static_encoder        | Sequential       | 81.9 K | train\n",
      "1 | seq_0M_encoder        | Sequential       | 1.4 K  | train\n",
      "2 | goutallier_0M_encoder | Sequential       | 1.4 K  | train\n",
      "3 | output_head           | Sequential       | 81.1 K | train\n",
      "4 | train_mse             | MeanSquaredError | 0      | train\n",
      "5 | val_mse               | MeanSquaredError | 0      | train\n",
      "6 | test_mse              | MeanSquaredError | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "165 K     Trainable params\n",
      "0         Non-trainable params\n",
      "165 K     Total params\n",
      "0.663     Total estimated model params size (MB)\n",
      "32        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "최적화된 파라미터로 최종 모델 생성\n",
      "================================================================================\n",
      "\n",
      "[Model 1] 최종 모델 생성 중...\n",
      "[Model 2] 최종 모델 생성 중...\n",
      "[Model 3] 최종 모델 생성 중...\n",
      "[Model 4] 최종 모델 생성 중...\n",
      "\n",
      "최종 모델 생성 완료!\n",
      "\n",
      "================================================================================\n",
      "최종 모델 학습 시작\n",
      "================================================================================\n",
      "\n",
      "[Model 1] 학습 시작...\n",
      "Epoch 23: 100%|██████████| 225/225 [00:02<00:00, 91.74it/s, v_num=16, train/loss_step=0.995, val/loss=1.060, train/loss_epoch=0.749]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda\\envs\\hospital\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:433: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 111.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test/loss            0.95975661277771\n",
      "        test/mse            0.9597566723823547\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "[Model 1] 학습 완료 - Test MSE: 0.959757\n",
      "\n",
      "[Model 2] 학습 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type             | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | static_encoder        | Sequential       | 3.6 K  | train\n",
      "1 | seq_0M_encoder        | Sequential       | 1.4 K  | train\n",
      "2 | seq_2M_encoder        | Sequential       | 26.5 K | train\n",
      "3 | goutallier_0M_encoder | Sequential       | 30.8 K | train\n",
      "4 | output_head           | Sequential       | 131 K  | train\n",
      "5 | train_mse             | MeanSquaredError | 0      | train\n",
      "6 | val_mse               | MeanSquaredError | 0      | train\n",
      "7 | test_mse              | MeanSquaredError | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "193 K     Trainable params\n",
      "0         Non-trainable params\n",
      "193 K     Total params\n",
      "0.776     Total estimated model params size (MB)\n",
      "47        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 225/225 [00:03<00:00, 72.48it/s, v_num=17, train/loss_step=0.598, val/loss=0.851, train/loss_epoch=0.516]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 225/225 [00:03<00:00, 72.36it/s, v_num=17, train/loss_step=0.598, val/loss=0.851, train/loss_epoch=0.516]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 91.92it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test/loss           0.9455130696296692\n",
      "        test/mse             0.945513129234314\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "[Model 2] 학습 완료 - Test MSE: 0.945513\n",
      "\n",
      "[Model 3] 학습 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type             | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | static_encoder        | Sequential       | 7.4 K  | train\n",
      "1 | seq_0M_encoder        | Sequential       | 960    | train\n",
      "2 | seq_2M_encoder        | Sequential       | 7.1 K  | train\n",
      "3 | seq_3M_encoder        | Sequential       | 3.4 K  | train\n",
      "4 | goutallier_0M_encoder | Sequential       | 1.1 K  | train\n",
      "5 | output_head           | Sequential       | 84.3 K | train\n",
      "6 | train_mse             | MeanSquaredError | 0      | train\n",
      "7 | val_mse               | MeanSquaredError | 0      | train\n",
      "8 | test_mse              | MeanSquaredError | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "104 K     Trainable params\n",
      "0         Non-trainable params\n",
      "104 K     Total params\n",
      "0.417     Total estimated model params size (MB)\n",
      "45        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 113/113 [00:01<00:00, 68.12it/s, v_num=18, train/loss_step=0.610, val/loss=0.942, train/loss_epoch=0.595]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 64.52it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test/loss           1.3098684549331665\n",
      "        test/mse             1.309868335723877\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "[Model 3] 학습 완료 - Test MSE: 1.309868\n",
      "\n",
      "[Model 4] 학습 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                  | Type                   | Params | Mode \n",
      "--------------------------------------------------------------------------\n",
      "0  | static_encoder        | Sequential             | 896    | train\n",
      "1  | seq_0M_encoder        | Sequential             | 2.4 K  | train\n",
      "2  | seq_2M_encoder        | Sequential             | 6.8 K  | train\n",
      "3  | seq_3M_encoder        | Sequential             | 61.5 K | train\n",
      "4  | seq_4M_encoder        | Sequential             | 40.3 K | train\n",
      "5  | goutallier_0M_encoder | Sequential             | 9.8 K  | train\n",
      "6  | clshead               | Sequential             | 737    | train\n",
      "7  | reghead               | Sequential             | 14.7 K | train\n",
      "8  | train_roc             | BinaryAUROC            | 0      | train\n",
      "9  | val_roc               | BinaryAUROC            | 0      | train\n",
      "10 | test_roc              | BinaryAUROC            | 0      | train\n",
      "11 | val_ap                | BinaryAveragePrecision | 0      | train\n",
      "12 | test_ap               | BinaryAveragePrecision | 0      | train\n",
      "13 | train_mse             | MeanSquaredError       | 0      | train\n",
      "14 | val_mse               | MeanSquaredError       | 0      | train\n",
      "15 | test_mse              | MeanSquaredError       | 0      | train\n",
      "--------------------------------------------------------------------------\n",
      "137 K     Trainable params\n",
      "0         Non-trainable params\n",
      "137 K     Total params\n",
      "0.549     Total estimated model params size (MB)\n",
      "61        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 225/225 [00:04<00:00, 56.11it/s, v_num=19, train/loss_step=0.717, val/loss=0.666, train/loss_epoch=0.674]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 64.51it/s] \n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         test/ap            0.8241692781448364\n",
      "      test/clf_loss         0.5806913375854492\n",
      "        test/loss           0.7412012219429016\n",
      "        test/mse            1.1635527610778809\n",
      "      test/reg_loss         0.35668861865997314\n",
      "        test/roc            0.7784000039100647\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "[Model 4] 학습 완료 - Test ROC: 0.778400, Test AP: 0.824169\n",
      "\n",
      "================================================================================\n",
      "모든 최종 모델 학습 완료!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def create_final_model_from_study(study, model_class, model_kwargs):\n",
    "    \"\"\"최적화된 파라미터로 최종 모델 생성\"\"\"\n",
    "    best_trial = study.best_trial\n",
    "    model = model_class(trial=best_trial, **model_kwargs)\n",
    "    return model, best_trial.params\n",
    "\n",
    "# 최적화된 모델 생성\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"최적화된 파라미터로 최종 모델 생성\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Model 1 최종 모델\n",
    "print(\"\\n[Model 1] 최종 모델 생성 중...\")\n",
    "final_model1, best_params1 = create_final_model_from_study(\n",
    "    study1,\n",
    "    OptimizedSequentialMLP1,\n",
    "    {\n",
    "        'static_features': static_features,\n",
    "        'seq_0M_features': seq_features_0M,\n",
    "        'goutallier_0M_features': goutallier_features_0M,\n",
    "        'out_features_2M': seq_features_2M\n",
    "    }\n",
    ")\n",
    "\n",
    "# Model 2 최종 모델\n",
    "print(\"[Model 2] 최종 모델 생성 중...\")\n",
    "final_model2, best_params2 = create_final_model_from_study(\n",
    "    study2,\n",
    "    OptimizedSequentialMLP2,\n",
    "    {\n",
    "        'static_features': static_features,\n",
    "        'seq_0M_features': seq_features_0M,\n",
    "        'seq_2M_features': seq_features_2M,\n",
    "        'goutallier_0M_features': goutallier_features_0M,\n",
    "        'out_features_3M': seq_features_3M\n",
    "    }\n",
    ")\n",
    "\n",
    "# Model 3 최종 모델\n",
    "print(\"[Model 3] 최종 모델 생성 중...\")\n",
    "final_model3, best_params3 = create_final_model_from_study(\n",
    "    study3,\n",
    "    OptimizedSequentialMLP3,\n",
    "    {\n",
    "        'static_features': static_features,\n",
    "        'seq_0M_features': seq_features_0M,\n",
    "        'seq_2M_features': seq_features_2M,\n",
    "        'seq_3M_features': seq_features_3M,\n",
    "        'goutallier_0M_features': goutallier_features_0M,\n",
    "        'out_features_4M': seq_features_4M\n",
    "    }\n",
    ")\n",
    "\n",
    "# Model 4 최종 모델\n",
    "print(\"[Model 4] 최종 모델 생성 중...\")\n",
    "final_model4, best_params4 = create_final_model_from_study(\n",
    "    study4,\n",
    "    OptimizedSequentialMLP4,\n",
    "    {\n",
    "        'static_features': static_features,\n",
    "        'seq_0M_features': seq_features_0M,\n",
    "        'seq_2M_features': seq_features_2M,\n",
    "        'seq_3M_features': seq_features_3M,\n",
    "        'seq_4M_features': seq_features_4M,\n",
    "        'goutallier_0M_features': goutallier_features_0M,\n",
    "        'out_features_total': seq_features_6M + 1 + goutallier_features_6M\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\\n최종 모델 생성 완료!\")\n",
    "\n",
    "# 최종 모델 학습\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"최종 모델 학습 시작\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 최적 배치 크기 추출\n",
    "batch_size1 = best_params1.get('batch_size', 64)\n",
    "batch_size2 = best_params2.get('batch_size', 64)\n",
    "batch_size3 = best_params3.get('batch_size', 64)\n",
    "batch_size4 = best_params4.get('batch_size', 64)\n",
    "\n",
    "# Model 1 학습\n",
    "print(\"\\n[Model 1] 학습 시작...\")\n",
    "trainloader1_final = DataLoader(trainset_model1, batch_size=batch_size1, shuffle=True, pin_memory=True)\n",
    "valloader1_final = DataLoader(valset_model1, batch_size=batch_size1)\n",
    "testloader1_final = DataLoader(testset_model1, batch_size=batch_size1)\n",
    "\n",
    "trainer1_final = L.Trainer(\n",
    "    max_epochs=100,\n",
    "    gradient_clip_val=1.0,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(monitor='val/loss', mode='min', save_top_k=1, filename='final-model1-best'),\n",
    "        EarlyStopping(monitor='val/loss', mode='min', patience=15)\n",
    "    ]\n",
    ")\n",
    "\n",
    "trainer1_final.fit(final_model1, trainloader1_final, valloader1_final)\n",
    "test_result1_final = trainer1_final.test(final_model1, testloader1_final)\n",
    "print(f\"[Model 1] 학습 완료 - Test MSE: {test_result1_final[0]['test/mse']:.6f}\")\n",
    "\n",
    "# Model 2 학습\n",
    "print(\"\\n[Model 2] 학습 시작...\")\n",
    "trainloader2_final = DataLoader(trainset_model2, batch_size=batch_size2, shuffle=True, pin_memory=True)\n",
    "valloader2_final = DataLoader(valset_model2, batch_size=batch_size2)\n",
    "testloader2_final = DataLoader(testset_model2, batch_size=batch_size2)\n",
    "\n",
    "trainer2_final = L.Trainer(\n",
    "    max_epochs=100,\n",
    "    gradient_clip_val=1.0,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(monitor='val/loss', mode='min', save_top_k=1, filename='final-model2-best'),\n",
    "        EarlyStopping(monitor='val/loss', mode='min', patience=15)\n",
    "    ]\n",
    ")\n",
    "\n",
    "trainer2_final.fit(final_model2, trainloader2_final, valloader2_final)\n",
    "test_result2_final = trainer2_final.test(final_model2, testloader2_final)\n",
    "print(f\"[Model 2] 학습 완료 - Test MSE: {test_result2_final[0]['test/mse']:.6f}\")\n",
    "\n",
    "# Model 3 학습\n",
    "print(\"\\n[Model 3] 학습 시작...\")\n",
    "trainloader3_final = DataLoader(trainset_model3, batch_size=batch_size3, shuffle=True, pin_memory=True)\n",
    "valloader3_final = DataLoader(valset_model3, batch_size=batch_size3)\n",
    "testloader3_final = DataLoader(testset_model3, batch_size=batch_size3)\n",
    "\n",
    "trainer3_final = L.Trainer(\n",
    "    max_epochs=100,\n",
    "    gradient_clip_val=1.0,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(monitor='val/loss', mode='min', save_top_k=1, filename='final-model3-best'),\n",
    "        EarlyStopping(monitor='val/loss', mode='min', patience=15)\n",
    "    ]\n",
    ")\n",
    "\n",
    "trainer3_final.fit(final_model3, trainloader3_final, valloader3_final)\n",
    "test_result3_final = trainer3_final.test(final_model3, testloader3_final)\n",
    "print(f\"[Model 3] 학습 완료 - Test MSE: {test_result3_final[0]['test/mse']:.6f}\")\n",
    "\n",
    "# Model 4 학습\n",
    "print(\"\\n[Model 4] 학습 시작...\")\n",
    "trainloader4_final = DataLoader(trainset_model4, batch_size=batch_size4, shuffle=True, pin_memory=True)\n",
    "valloader4_final = DataLoader(valset_model4, batch_size=batch_size4)\n",
    "testloader4_final = DataLoader(testset_model4, batch_size=batch_size4)\n",
    "\n",
    "trainer4_final = L.Trainer(\n",
    "    max_epochs=100,\n",
    "    gradient_clip_val=1.0,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(monitor='val/roc', mode='max', save_top_k=1, filename='final-model4-best'),\n",
    "        EarlyStopping(monitor='val/roc', mode='max', patience=15)\n",
    "    ]\n",
    ")\n",
    "\n",
    "trainer4_final.fit(final_model4, trainloader4_final, valloader4_final)\n",
    "test_result4_final = trainer4_final.test(final_model4, testloader4_final)\n",
    "print(f\"[Model 4] 학습 완료 - Test ROC: {test_result4_final[0]['test/roc']:.6f}, Test AP: {test_result4_final[0]['test/ap']:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"모든 최종 모델 학습 완료!\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff29bb1f",
   "metadata": {},
   "source": [
    "### Sequential 모델 연결 및 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd6fba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "최적화된 Sequential 모델 생성 및 성능 평가\n",
      "================================================================================\n",
      "Sequential 모델 생성 완료\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "개별 모델 성능 평가\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Model 1] 평가 중...\n",
      "  MSE: 0.959757\n",
      "  MAE: 0.770331\n",
      "\n",
      "[Model 2] 평가 중...\n",
      "  MSE: 0.945513\n",
      "  MAE: 0.694760\n",
      "\n",
      "[Model 3] 평가 중...\n",
      "  MSE: 1.309868\n",
      "  MAE: 0.783733\n",
      "\n",
      "[Model 4] 평가 중...\n",
      "  MSE: 1.163553\n",
      "  ROC AUC: 0.778400\n",
      "  AP: 0.824169\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Sequential 모델 성능 평가 (0M 입력만으로 전체 시계열 예측)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[회귀 성능 - MSE]\n",
      "  2M 예측 MSE: 0.959757\n",
      "  3M 예측 MSE: 1.054726\n",
      "  4M 예측 MSE: 1.653644\n",
      "  6M 예측 MSE: 1.735145\n",
      "  6M Goutallier 예측 MSE: 0.875304\n",
      "\n",
      "[회귀 성능 - MAE]\n",
      "  2M 예측 MAE: 0.770331\n",
      "  3M 예측 MAE: 0.739567\n",
      "  4M 예측 MAE: 0.905311\n",
      "  6M 예측 MAE: 0.942031\n",
      "  6M Goutallier 예측 MAE: 0.414613\n",
      "\n",
      "[분류 성능]\n",
      "  ROC AUC: 0.602000\n",
      "  AP (Average Precision): 0.627212\n",
      "\n",
      "================================================================================\n",
      "성능 평가 요약\n",
      "================================================================================\n",
      "\n",
      "개별 모델 성능:\n",
      "  Model 1 (2M 예측): MSE=0.959757, MAE=0.770331\n",
      "  Model 2 (3M 예측): MSE=0.945513, MAE=0.694760\n",
      "  Model 3 (4M 예측): MSE=1.309868, MAE=0.783733\n",
      "  Model 4 (6M+분류): MSE=1.163553, ROC=0.778400, AP=0.824169\n",
      "\n",
      "Sequential 모델 성능:\n",
      "  전체 파이프라인: ROC=0.602000, AP=0.627212\n",
      "  중간 단계 예측: 2M MSE=0.959757, 3M MSE=1.054726, 4M MSE=1.653644, 6M MSE=1.735145\n",
      "\n",
      "================================================================================\n",
      "모든 평가 완료!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"최적화된 Sequential 모델 생성 및 성능 평가\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Sequential 모델 생성\n",
    "sequential_model = SequentialModel(final_model1, final_model2, final_model3, final_model4)\n",
    "print(\"Sequential 모델 생성 완료\")\n",
    "\n",
    "# Test DataLoader 생성\n",
    "batch_size = 64\n",
    "testloader1 = DataLoader(testset_model1, batch_size=batch_size)\n",
    "testloader2 = DataLoader(testset_model2, batch_size=batch_size)\n",
    "testloader3 = DataLoader(testset_model3, batch_size=batch_size)\n",
    "testloader4 = DataLoader(testset_model4, batch_size=batch_size)\n",
    "\n",
    "# 개별 모델 성능 평가\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"개별 모델 성능 평가\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"\\n[Model 1] 평가 중...\")\n",
    "model1_results = evaluate_individual_model(final_model1, testloader1, \"Model1\")\n",
    "print(f\"  MSE: {model1_results['mse']:.6f}\")\n",
    "print(f\"  MAE: {model1_results['mae']:.6f}\")\n",
    "\n",
    "print(\"\\n[Model 2] 평가 중...\")\n",
    "model2_results = evaluate_individual_model(final_model2, testloader2, \"Model2\")\n",
    "print(f\"  MSE: {model2_results['mse']:.6f}\")\n",
    "print(f\"  MAE: {model2_results['mae']:.6f}\")\n",
    "\n",
    "print(\"\\n[Model 3] 평가 중...\")\n",
    "model3_results = evaluate_individual_model(final_model3, testloader3, \"Model3\")\n",
    "print(f\"  MSE: {model3_results['mse']:.6f}\")\n",
    "print(f\"  MAE: {model3_results['mae']:.6f}\")\n",
    "\n",
    "print(\"\\n[Model 4] 평가 중...\")\n",
    "model4_results = evaluate_individual_model(final_model4, testloader4, \"Model4\")\n",
    "print(f\"  MSE: {model4_results['mse']:.6f}\")\n",
    "print(f\"  ROC AUC: {model4_results['roc_auc']:.6f}\")\n",
    "print(f\"  AP: {model4_results['ap']:.6f}\")\n",
    "print(f\"  Accuracy: {model4_results['accuracy']:.6f}\")\n",
    "\n",
    "# Sequential 모델 성능 평가\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Sequential 모델 성능 평가 (0M 입력만으로 전체 시계열 예측)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "sequential_results = evaluate_sequential_model(sequential_model, testset_model1)\n",
    "\n",
    "print(\"\\n[회귀 성능 - MSE]\")\n",
    "print(f\"  2M 예측 MSE: {sequential_results['mse_2M']:.6f}\")\n",
    "print(f\"  3M 예측 MSE: {sequential_results['mse_3M']:.6f}\")\n",
    "print(f\"  4M 예측 MSE: {sequential_results['mse_4M']:.6f}\")\n",
    "print(f\"  6M 예측 MSE: {sequential_results['mse_6M']:.6f}\")\n",
    "print(f\"  6M Goutallier 예측 MSE: {sequential_results['mse_6M_goutallier']:.6f}\")\n",
    "\n",
    "print(\"\\n[회귀 성능 - MAE]\")\n",
    "print(f\"  2M 예측 MAE: {sequential_results['mae_2M']:.6f}\")\n",
    "print(f\"  3M 예측 MAE: {sequential_results['mae_3M']:.6f}\")\n",
    "print(f\"  4M 예측 MAE: {sequential_results['mae_4M']:.6f}\")\n",
    "print(f\"  6M 예측 MAE: {sequential_results['mae_6M']:.6f}\")\n",
    "print(f\"  6M Goutallier 예측 MAE: {sequential_results['mae_6M_goutallier']:.6f}\")\n",
    "\n",
    "print(\"\\n[분류 성능]\")\n",
    "print(f\"  ROC AUC: {sequential_results['roc_auc']:.6f}\")\n",
    "print(f\"  AP (Average Precision): {sequential_results['ap']:.6f}\")\n",
    "print(f\"  Accuracy: {sequential_results['accuracy']:.6f}\")\n",
    "\n",
    "# 성능 요약\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"성능 평가 요약\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n개별 모델 성능:\")\n",
    "print(f\"  Model 1 (2M 예측): MSE={model1_results['mse']:.6f}, MAE={model1_results['mae']:.6f}\")\n",
    "print(f\"  Model 2 (3M 예측): MSE={model2_results['mse']:.6f}, MAE={model2_results['mae']:.6f}\")\n",
    "print(f\"  Model 3 (4M 예측): MSE={model3_results['mse']:.6f}, MAE={model3_results['mae']:.6f}\")\n",
    "print(f\"  Model 4 (6M+분류): MSE={model4_results['mse']:.6f}, ROC={model4_results['roc_auc']:.6f}, AP={model4_results['ap']:.6f}, Accuracy={model4_results['accuracy']:.6f}\")\n",
    "print(\"\\nSequential 모델 성능:\")\n",
    "print(f\"  전체 파이프라인: ROC={sequential_results['roc_auc']:.6f}, AP={sequential_results['ap']:.6f}, Accuracy={sequential_results['accuracy']:.6f}\")\n",
    "print(f\"  중간 단계 예측: 2M MSE={sequential_results['mse_2M']:.6f}, 3M MSE={sequential_results['mse_3M']:.6f}, 4M MSE={sequential_results['mse_4M']:.6f}, 6M MSE={sequential_results['mse_6M']:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"모든 평가 완료!\")\n",
    "print(\"=\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hospital",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
