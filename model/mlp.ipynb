{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b43411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, classification_report\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from torchmetrics.regression import MeanSquaredError, MeanAbsoluteError\n",
    "from torchmetrics.classification import BinaryAUROC, BinaryAveragePrecision\n",
    "from torchmetrics.classification import BinaryAccuracy, BinaryPrecision, BinaryRecall, BinaryF1Score\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a431bcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c42fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0fd065",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb8c992",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(X_train.columns)\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e04aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_columns = columns[:25]\n",
    "static_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7862c6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_columns = columns[25:-16]\n",
    "print(seq_columns[:12])\n",
    "print(seq_columns[12:19])\n",
    "print(seq_columns[19:31])\n",
    "print(seq_columns[31:43])\n",
    "print(seq_columns[43:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ed4d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "goutallier_columns = columns[-16:]\n",
    "goutallier_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a663ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(columns) == len(static_columns) + len(seq_columns) + len(goutallier_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb95606",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column = \"POD 6M retear\"\n",
    "output_columns = [\"6M ASES\", \"6M CSS\", \"6M KSS\", \"6M VAS(activity)\", \"6M VAS(resting)\"]\n",
    "input_columns = static_columns + [column for column in seq_columns if column not in output_columns] + goutallier_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690b23f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23baa483",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ba6ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[input_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2525c5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([y_train, X_train[output_columns]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4260e764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(split):\n",
    "  assert split in [\"train\", \"test\"]\n",
    "\n",
    "  X_file_name = f\"X_{split}.csv\"\n",
    "  y_file_name = f\"y_{split}.csv\"\n",
    "\n",
    "  X = pd.read_csv(X_file_name)\n",
    "  y = pd.read_csv(y_file_name)\n",
    "\n",
    "  X_np = X[input_columns].to_numpy()\n",
    "  X_static_np = X[static_columns].to_numpy()\n",
    "  X_seq_np = X[seq_columns].to_numpy()\n",
    "  X_goutallier_np = X[goutallier_columns].to_numpy()\n",
    "  y_np = pd.concat([y, X[output_columns]], axis=1).to_numpy()\n",
    "\n",
    "  X_tensor = torch.tensor(X_np, dtype=torch.float32)\n",
    "  X_static_tensor = torch.tensor(X_static_np, dtype=torch.float32)\n",
    "  X_seq_tensor = torch.tensor(X_seq_np, dtype=torch.float32)\n",
    "  X_goutallier_tensor = torch.tensor(X_goutallier_np, dtype=torch.float32)\n",
    "  y_tensor = torch.tensor(y_np, dtype=torch.float32)\n",
    "\n",
    "  return TensorDataset(X_tensor, X_static_tensor, X_seq_tensor, X_goutallier_tensor, y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4f36ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = get_dataset(\"train\")\n",
    "testset = get_dataset(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5cc6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = len(input_columns)\n",
    "static_features = len(static_columns)\n",
    "seq_features = len(seq_columns)\n",
    "goutallier_features = len(goutallier_columns)\n",
    "out_features = len([label_column]) + len(output_columns)\n",
    "\n",
    "in_features, static_features, seq_features, goutallier_features, out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0c1332",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(L.LightningModule):\n",
    "  def __init__(self, in_features, static_features, seq_features, goutallier_features, out_features):\n",
    "    super().__init__()\n",
    "    self.register_buffer('pos_weight', torch.tensor([1.0]))\n",
    "\n",
    "    dropout = 0.3\n",
    "    self.static_encoder = nn.Sequential(\n",
    "      nn.Linear(static_features, 64), \n",
    "      nn.LayerNorm(64), \n",
    "      nn.LeakyReLU(), \n",
    "      nn.Dropout(0.2),\n",
    "    )\n",
    "\n",
    "    self.seq_encoder = nn.Sequential(\n",
    "      nn.Linear(seq_features, 128), \n",
    "      nn.LayerNorm(128), \n",
    "      nn.LeakyReLU(), \n",
    "      nn.Dropout(0.2),\n",
    "    )\n",
    "\n",
    "    self.goutallier = nn.Sequential(\n",
    "      nn.Linear(goutallier_features, 64), \n",
    "      nn.LayerNorm(64), \n",
    "      nn.LeakyReLU(), \n",
    "      nn.Dropout(0.2),\n",
    "    )\n",
    "\n",
    "    feat_dim = 64 + 128 + 64\n",
    "    \n",
    "    self.clshead = nn.Sequential(\n",
    "      nn.Linear(feat_dim, 128),\n",
    "      nn.LayerNorm(128),\n",
    "      nn.ReLU(),\n",
    "\n",
    "      nn.Linear(128, 1)\n",
    "    )\n",
    "    \n",
    "    self.reghead = nn.Sequential(\n",
    "      nn.Linear(feat_dim, 256),\n",
    "      nn.LayerNorm(256),\n",
    "      nn.LeakyReLU(),\n",
    "\n",
    "      nn.Linear(256, 5)\n",
    "    )\n",
    "\n",
    "    self.train_roc = BinaryAUROC()\n",
    "    self.test_roc = BinaryAUROC()\n",
    "    self.test_ap = BinaryAveragePrecision()\n",
    "    self.val_roc = BinaryAUROC()\n",
    "    self.val_ap = BinaryAveragePrecision()\n",
    "\n",
    "    self.train_mse = MeanSquaredError()\n",
    "    self.test_mse  = MeanSquaredError()\n",
    "    self.train_mae = MeanAbsoluteError()\n",
    "    self.test_mae  = MeanAbsoluteError()\n",
    "\n",
    "  def forward(self, xb, xb_static, xb_seq, xb_goutallier):\n",
    "    static_features = self.static_encoder(xb_static)\n",
    "    seq_features = self.seq_encoder(xb_seq)\n",
    "    goutallier_features = self.goutallier(xb_goutallier)\n",
    "\n",
    "    combined_features = torch.cat([static_features, seq_features, goutallier_features], dim=1)\n",
    "    \n",
    "    logits = self.clshead(combined_features)\n",
    "    regs = self.reghead(combined_features)\n",
    "\n",
    "    return logits, regs\n",
    "\n",
    "  def _shared_step(self, batch, metric=True):\n",
    "    xb, xb_static, xb_seq, xb_goutallier, yb = batch\n",
    "    clf_targets = yb[:, :1]\n",
    "    reg_targets = yb[:, 1:]\n",
    "\n",
    "    logits, regs = self.forward(xb, xb_static, xb_seq, xb_goutallier)\n",
    "\n",
    "    clf_loss = F.binary_cross_entropy_with_logits(logits, clf_targets, pos_weight=self.pos_weight)\n",
    "    reg_loss = F.smooth_l1_loss(regs, reg_targets)\n",
    "    loss = clf_loss + reg_loss\n",
    "\n",
    "    return {\n",
    "      \"loss\": loss,\n",
    "      \"clf_loss\": clf_loss,\n",
    "      \"reg_loss\": reg_loss,\n",
    "      \"clf_logits\": logits.detach(),\n",
    "      \"clf_targets\": clf_targets.detach(),\n",
    "    }\n",
    "  \n",
    "  def training_step(self, batch, batch_idx):\n",
    "    out = self._shared_step(batch)\n",
    "\n",
    "    self.log(\"train/loss\", out[\"loss\"], on_epoch=True, prog_bar=True)\n",
    "    self.log(\"train/clf_loss\", out[\"clf_loss\"])\n",
    "    self.log(\"train/reg_loss\", out[\"reg_loss\"])\n",
    "\n",
    "    probs = out[\"clf_logits\"].sigmoid().flatten()\n",
    "    targets = out[\"clf_targets\"].flatten().to(torch.int)\n",
    "    self.train_roc.update(probs, targets)\n",
    "\n",
    "    return out[\"loss\"]\n",
    "\n",
    "  def test_step(self, batch, batch_idx):\n",
    "    out = self._shared_step(batch)\n",
    "\n",
    "    self.log(\"test/loss\", out[\"loss\"], prog_bar=True)\n",
    "    self.log(\"test/clf_loss\", out[\"clf_loss\"])\n",
    "    self.log(\"test/reg_loss\", out[\"reg_loss\"])\n",
    "\n",
    "    probs = out[\"clf_logits\"].sigmoid().flatten()\n",
    "    targets = out[\"clf_targets\"].flatten().to(torch.int)\n",
    "    self.test_roc.update(probs, targets)\n",
    "    self.test_ap.update(probs, targets)\n",
    "    \n",
    "    return out[\"loss\"]\n",
    "  \n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    out = self._shared_step(batch)\n",
    "\n",
    "    self.log(\"val/loss\", out[\"loss\"], prog_bar=True, on_epoch=True)\n",
    "    self.log(\"val/clf_loss\", out[\"clf_loss\"], on_epoch=True)\n",
    "    self.log(\"val/reg_loss\", out[\"reg_loss\"], on_epoch=True)\n",
    "\n",
    "    probs = out[\"clf_logits\"].sigmoid().flatten()\n",
    "    targets = out[\"clf_targets\"].flatten().to(torch.int)\n",
    "    self.val_roc.update(probs, targets)\n",
    "    self.val_ap.update(probs, targets)\n",
    "    \n",
    "    return out[\"loss\"]\n",
    "  \n",
    "  def on_train_epoch_end(self):\n",
    "    self.log(\"train/roc\", self.train_roc.compute())\n",
    "    self.train_roc.reset()\n",
    "\n",
    "  def on_test_epoch_end(self):\n",
    "    self.log(\"test/roc\", self.test_roc.compute())\n",
    "    self.log(\"test/ap\", self.test_ap.compute())\n",
    "    self.test_roc.reset()\n",
    "\n",
    "  def on_validation_epoch_end(self):\n",
    "    self.log(\"val/roc\", self.val_roc.compute())\n",
    "    self.log(\"val/ap\", self.val_ap.compute())\n",
    "    self.val_roc.reset()\n",
    "    self.val_ap.reset()\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "      optimizer = torch.optim.AdamW(self.parameters(), lr=5*1e-6, weight_decay=1e-4)\n",
    "\n",
    "      return {\n",
    "          \"optimizer\": optimizer,\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5239a5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistoryCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.train_losses = []\n",
    "        self.test_losses = []\n",
    "    \n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        if len(self.train_losses) == 0:\n",
    "            print(f\"[Train] Available metrics: {list(trainer.callback_metrics.keys())}\")\n",
    "        \n",
    "        train_loss = trainer.callback_metrics.get('train/loss_epoch')\n",
    "        if train_loss is not None:\n",
    "            self.train_losses.append(train_loss.item())\n",
    "        else:\n",
    "            print(f\"Warning: train/loss_epoch not found!\")\n",
    "    \n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        if len(self.test_losses) == 0:\n",
    "            print(f\"[Val] Available metrics: {list(trainer.callback_metrics.keys())}\")\n",
    "        \n",
    "        val_loss = trainer.callback_metrics.get('val/loss')\n",
    "        if val_loss is not None:\n",
    "            self.test_losses.append(val_loss.item())\n",
    "        else:\n",
    "            print(f\"Warning: val/loss not found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logs = []\n",
    "batch_size = 64\n",
    "num_experiments = 1\n",
    "\n",
    "test_logs = []\n",
    "models = []\n",
    "loss_histories = []\n",
    "\n",
    "for i in range(num_experiments):\n",
    "    mlp = MLP(in_features, static_features, seq_features, goutallier_features, out_features)\n",
    "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    testloader  = DataLoader(testset,  batch_size=batch_size)\n",
    "\n",
    "    loss_history_callback = LossHistoryCallback()\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=24,\n",
    "        callbacks=[\n",
    "            ModelCheckpoint(monitor='train/roc', mode='max', save_top_k=1),\n",
    "            loss_history_callback\n",
    "        ]\n",
    "    )\n",
    "    trainer.fit(mlp, trainloader, testloader)\n",
    "    test_result = trainer.test(mlp, testloader)\n",
    "    test_logs.append(test_result)\n",
    "    models.append(mlp)\n",
    "    loss_histories.append(loss_history_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee425a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_rocs = []\n",
    "individual_aps = []\n",
    "\n",
    "print(\"===== 개별 모델 성능 확인 =====\")\n",
    "for i, test_log in enumerate(test_logs):\n",
    "    roc = test_log[0][\"test/roc\"]\n",
    "    ap = test_log[0][\"test/ap\"]\n",
    "    individual_rocs.append(roc)\n",
    "    individual_aps.append(ap)\n",
    "    print(f\"모델 {i+1}: ROC AUC = {roc:.4f}, AP = {ap:.4f}\")\n",
    "\n",
    "individual_rocs = np.array(individual_rocs)\n",
    "individual_aps = np.array(individual_aps)\n",
    "\n",
    "print(f\"\\n개별 모델 ROC AUC: {individual_rocs.mean():.4f} ± {individual_rocs.std():.4f}\")\n",
    "print(f\"개별 모델 AP: {individual_aps.mean():.4f} ± {individual_aps.std():.4f}\")\n",
    "\n",
    "best_model_idx = np.argmax(individual_rocs)\n",
    "best_model = models[best_model_idx]\n",
    "\n",
    "print(f\"\\n===== 최고 성능 모델 선택 =====\")\n",
    "print(f\"최고 성능 모델: 모델 {best_model_idx + 1}\")\n",
    "print(f\"ROC AUC: {individual_rocs[best_model_idx]:.4f}\")\n",
    "print(f\"AP: {individual_aps[best_model_idx]:.4f}\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_best_model(model, dataloader):\n",
    "    model.eval()\n",
    "    all_logits = []\n",
    "    all_regs = []\n",
    "    clf_targets = []\n",
    "    reg_targets = []\n",
    "    \n",
    "    for xb, x_static, x_seq, x_goutallier, yb in dataloader:\n",
    "        logits, regs = model(xb, x_static, x_seq, x_goutallier)\n",
    "        all_logits.append(logits)\n",
    "        all_regs.append(regs)\n",
    "        clf_targets.append(yb[:, :1])\n",
    "        reg_targets.append(yb[:, 1:])\n",
    "    \n",
    "    logits = torch.cat(all_logits)\n",
    "    regs = torch.cat(all_regs)\n",
    "    clf_targets = torch.cat(clf_targets).to(torch.int).flatten()\n",
    "    reg_targets = torch.cat(reg_targets)\n",
    "    \n",
    "    return logits, regs, clf_targets, reg_targets\n",
    "\n",
    "best_logits, best_regs, clf_targets, reg_targets = predict_with_best_model(best_model, testloader)\n",
    "probs = best_logits.sigmoid()\n",
    "\n",
    "if probs.dim() > 1:\n",
    "    probs_flat = probs.flatten()\n",
    "else:\n",
    "    probs_flat = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0afac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_roc = roc_auc_score(clf_targets, probs_flat)\n",
    "best_ap = average_precision_score(clf_targets, probs_flat)\n",
    "    \n",
    "print(f\"\\n=== 최고 성능 모델 최종 성능 ===\")\n",
    "print(f\"ROC AUC: {best_roc:.4f}\")\n",
    "print(f\"AP: {best_ap:.4f}\")\n",
    "    \n",
    "threshold = 0.3\n",
    "predicted_labels = (probs_flat > threshold).int()\n",
    "print(f\"\\n=== 분류 성능 ===\")\n",
    "print(classification_report(clf_targets, predicted_labels, target_names=['Negative', 'Positive']))\n",
    "    \n",
    "mse = torch.nn.functional.mse_loss(best_regs, reg_targets).item()\n",
    "mae = torch.nn.functional.l1_loss(best_regs, reg_targets).item()\n",
    "    \n",
    "print(f\"\\n=== 회귀 성능 ===\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72215148",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_aps = np.array([test_log[0][\"test/ap\"] for test_log in test_logs])\n",
    "test_rocs = np.array([test_log[0][\"test/roc\"] for test_log in test_logs])\n",
    "pd.DataFrame({\"ROC AUC\": test_rocs, \"PR AUC\": test_aps}).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f25d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_set_stat(dataset):\n",
    "  _, _, _, _, y = dataset[:]\n",
    "  negative, positive = torch.bincount(y[:, 0].to(torch.int)).tolist()\n",
    "  samples = len(dataset)\n",
    "\n",
    "  print(f\"tatal   : {samples}\")\n",
    "  print(f\"negative: {negative:3} ({negative/samples*100:5.2f}%)\")\n",
    "  print(f\"positive: {positive:3} ({positive/samples*100:5.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee2341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"trainset (SMOTE)\")\n",
    "show_set_stat(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183d1b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"testset\")\n",
    "show_set_stat(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4763ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def forward_loader(model, dataloader):\n",
    "  all_logits = []\n",
    "  all_regs = []\n",
    "  all_clf_targets = []\n",
    "  all_reg_targets = []\n",
    "  \n",
    "  model.eval()\n",
    "  for xb, x_static, x_seq, x_goutallier, yb in dataloader:\n",
    "    logits, regs = model(xb, x_static, x_seq, x_goutallier)\n",
    "    all_logits.append(logits)\n",
    "    all_regs.append(regs)\n",
    "    all_clf_targets.append(yb[:, :1])\n",
    "    all_reg_targets.append(yb[:, 1:])\n",
    "\n",
    "  logits = torch.cat(all_logits).flatten()\n",
    "  regs = torch.cat(all_regs)\n",
    "  clf_targets = torch.cat(all_clf_targets).to(torch.int).flatten()\n",
    "  reg_targets = torch.cat(all_reg_targets)\n",
    "\n",
    "  return logits, regs, clf_targets, reg_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ae957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, regs, clf_targets, reg_targets = forward_loader(mlp, testloader)\n",
    "probs = logits.sigmoid()\n",
    "\n",
    "print(f\"logits.shape:      {logits.shape}\")\n",
    "print(f\"probs.shape:      {probs.shape}\")\n",
    "print(f\"regs.shape:        {regs.shape}\")\n",
    "print()\n",
    "print(f\"clf_targets.shape: {clf_targets.shape}\")\n",
    "print(f\"reg_targets.shape: {reg_targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad6143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions, recalls, thresholds = precision_recall_curve(clf_targets, probs)\n",
    "thresholds = np.append(thresholds, 1.0)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(thresholds, precisions, label='Precision', marker='o', markersize=3)\n",
    "plt.plot(thresholds, recalls, label='Recall', marker='x', markersize=3)\n",
    "\n",
    "plt.title(\"Precision & Recall vs Threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06428065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_score_distributions(\n",
    "  y_score, y_true, *,\n",
    "  bins=40,\n",
    "  title=None,\n",
    "  density=False,\n",
    "  th_lines=(0.5,),\n",
    "):\n",
    "  y_true = np.asarray(y_true).astype(int)\n",
    "  y_score = np.asarray(y_score)\n",
    "\n",
    "  x_main = y_score\n",
    "  x_label = \"Predicted probability\"\n",
    "\n",
    "  pos = x_main[y_true == 1]\n",
    "  neg = x_main[y_true == 0]\n",
    "\n",
    "  xmin = np.min(x_main)\n",
    "  xmax = np.max(x_main)\n",
    "  bins_edges = np.linspace(xmin, xmax, bins+1)\n",
    "\n",
    "  plt.figure(figsize=(9, 5.5))\n",
    "  plt.hist(neg, bins=bins_edges, alpha=0.55, density=density,\n",
    "           label=f\"Negative (n={len(neg)})\", edgecolor=\"white\", linewidth=0.5)\n",
    "  plt.hist(pos, bins=bins_edges, alpha=0.55, density=density,\n",
    "           label=f\"Positive (n={len(pos)})\", edgecolor=\"white\", linewidth=0.5)\n",
    "\n",
    "  if th_lines:\n",
    "    for th in th_lines:\n",
    "      plt.axvline(th, linestyle=\"--\", linewidth=1.5)\n",
    "\n",
    "  plt.xlabel(x_label)\n",
    "  plt.ylabel(\"Density\" if density else \"Count\")\n",
    "  plt.title(title or \"Score distributions by class\")\n",
    "  plt.legend(loc=\"best\")\n",
    "  plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590cb0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_thresholds = np.linspace(0, 1, 11)[1:-1].tolist() # [0.1, 0.2, ... , 0.9]\n",
    "\n",
    "def test_thresholds(y_score, y_true, thresholds=default_thresholds, verbose=True):\n",
    "  accuracies = []\n",
    "  precisions = []\n",
    "  recalls = []\n",
    "  f1s = []\n",
    "  for threshold in thresholds:\n",
    "    bin_acc = BinaryAccuracy(threshold)\n",
    "    bin_precison = BinaryPrecision(threshold)\n",
    "    bin_recall = BinaryRecall(threshold)\n",
    "    bin_f1 = BinaryF1Score(threshold)\n",
    "\n",
    "    bin_acc.update(y_score, y_true)\n",
    "    bin_precison.update(y_score, y_true)\n",
    "    bin_recall.update(y_score, y_true)\n",
    "    bin_f1.update(y_score, y_true)\n",
    "\n",
    "    accuracies.append(bin_acc.compute().item())\n",
    "    precisions.append(bin_precison.compute().item())\n",
    "    recalls.append(bin_recall.compute().item())\n",
    "    f1s.append(bin_f1.compute().item())\n",
    "\n",
    "  result = pd.DataFrame({\n",
    "    \"threshold\": thresholds,\n",
    "    \"accuracy\": accuracies,\n",
    "    \"precison\": precisions,\n",
    "    \"recall\": recalls,\n",
    "    \"f1\": f1s\n",
    "  }).set_index(\"threshold\")\n",
    "\n",
    "  if verbose:\n",
    "    print(result)\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fa07c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_range = np.arange(0.0, 1.01, 0.01)\n",
    "\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "specificities = []\n",
    "youden_indices = []\n",
    "\n",
    "y_true_np = clf_targets.cpu().numpy()\n",
    "probs_np = probs.cpu().numpy()\n",
    "\n",
    "for th in thresholds_range:\n",
    "    y_pred = (probs_np >= th).astype(int)\n",
    "    \n",
    "    tn = np.sum((y_pred == 0) & (y_true_np == 0))\n",
    "    fp = np.sum((y_pred == 1) & (y_true_np == 0))\n",
    "    fn = np.sum((y_pred == 0) & (y_true_np == 1))\n",
    "    tp = np.sum((y_pred == 1) & (y_true_np == 1))\n",
    "    \n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    youden = recall + specificity - 1\n",
    "    \n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    specificities.append(specificity)\n",
    "    youden_indices.append(youden)\n",
    "\n",
    "best_accuracy_th = thresholds_range[np.argmax(accuracies)]\n",
    "best_f1_th = thresholds_range[np.argmax(f1_scores)]\n",
    "best_youden_th = thresholds_range[np.argmax(youden_indices)]\n",
    "balanced_th = thresholds_range[np.argmin(np.abs(np.array(precisions) - np.array(recalls)))]\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(\" 최적 Threshold 결과\")\n",
    "print(f\"{'='*100}\\n\")\n",
    "\n",
    "print(f\"Accuracy 최대화:        Threshold = {best_accuracy_th:.3f}  (Accuracy = {max(accuracies):.4f})\")\n",
    "print(f\"F1 Score 최대화:        Threshold = {best_f1_th:.3f}  (F1 = {max(f1_scores):.4f})\")\n",
    "print(f\"Precision-Recall 균형:  Threshold = {balanced_th:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ccf794",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [best_accuracy_th]\n",
    "test_thresholds(probs, clf_targets, thresholds)\n",
    "plot_score_distributions(probs, clf_targets, bins=40, density=True, th_lines=thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0120c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_regression_summary(regs, reg_targets, output_columns):\n",
    "    \n",
    "    results = []\n",
    "    for i, col_name in enumerate(output_columns):\n",
    "        pred = regs[:, i]\n",
    "        true = reg_targets[:, i]\n",
    "        \n",
    "        mse = torch.mean((pred - true) ** 2).item()\n",
    "        mae = torch.mean(torch.abs(pred - true)).item()\n",
    "        rmse = torch.sqrt(torch.mean((pred - true) ** 2)).item()\n",
    "        \n",
    "        ss_res = torch.sum((true - pred) ** 2)\n",
    "        ss_tot = torch.sum((true - torch.mean(true)) ** 2)\n",
    "        r2 = 1 - (ss_res / ss_tot).item()\n",
    "        \n",
    "        results.append({\n",
    "            'Column': col_name,\n",
    "            'MSE': mse,\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'R²': r2\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    print(df.round(4))\n",
    "    \n",
    "    return df\n",
    "\n",
    "logits, regs, clf_targets, reg_targets = forward_loader(models[0], testloader)\n",
    "regression_summary = print_regression_summary(regs, reg_targets, output_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6d1ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(testset)\n",
    "# show_set_stat(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd512ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testloader = DataLoader(testset, batch_size=batch_size)\n",
    "# test_logs = trainer.test(mlp, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fef2459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_logits, test_regs, test_clf_targets, test_reg_targets = forward_loader(mlp, testloader)\n",
    "# test_probs = test_logits.sigmoid()\n",
    "# test_thresholds(test_probs, test_clf_targets, thresholds)\n",
    "# plot_score_distributions(test_probs, test_clf_targets, bins=40, density=True, th_lines=thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2e0404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae20aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_columns = seq_columns[:12] + goutallier_columns[:4] + goutallier_columns[8:12]\n",
    "# pre_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c980f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_columns = [column for column in columns if column not in static_columns + pre_columns + output_columns]\n",
    "# mean_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8db9a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_table = pd.read_csv(\"X_train.csv\")\n",
    "# mean_table[\"age_group\"] = mean_table[\"나이\"] // 10 * 10\n",
    "\n",
    "# group_columns = [\"성별 (M:1,F:2)\", \"age_group\"]\n",
    "# mean_table = mean_table.groupby(group_columns)[mean_columns].mean().reset_index()\n",
    "# mean_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eec593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_pre_with_mean_dataset(split):\n",
    "#   assert split in [\"val\", \"test\"]\n",
    "#   X = pd.read_csv(f\"X_{split}.csv\")\n",
    "#   y = pd.read_csv(f\"y_{split}.csv\")\n",
    "\n",
    "#   indices = pd.concat([X[\"성별 (M:1,F:2)\"], X[\"나이\"] // 10 * 10], axis=1)\n",
    "#   indices.columns = group_columns\n",
    "#   mean_values = indices.merge(mean_table, on=group_columns, how=\"left\")\n",
    "\n",
    "#   X[mean_columns] = mean_values[mean_columns]\n",
    "#   X_np = X[input_columns].to_numpy()\n",
    "#   y_np = pd.concat([y, X[output_columns]], axis=1).to_numpy()\n",
    "\n",
    "#   X_tensor = torch.tensor(X_np, dtype=torch.float32)\n",
    "#   y_tensor = torch.tensor(y_np, dtype=torch.float32)\n",
    "\n",
    "#   return TensorDataset(X_tensor, y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7049e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_pre_with_mean_set = get_pre_with_mean_dataset(\"val\")\n",
    "# val_pre_with_mean_loader = DataLoader(val_pre_with_mean_set, batch_size=batch_size)\n",
    "# val_pre_with_mean_logs = trainer.test(mlp, val_pre_with_mean_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041bc402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits, regs, clf_targets, reg_targets = forward_loader(mlp, val_pre_with_mean_loader)\n",
    "# probs = logits.sigmoid()\n",
    "# test_thresholds(probs, clf_targets, thresholds)\n",
    "# plot_score_distributions(probs, clf_targets, bins=40, density=False, th_lines=thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea548a47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87529f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fgsm_attack(data, data_grad, epsilon):\n",
    "#   sign_data_grad = data_grad.sign()\n",
    "#   perturbed_data = data + epsilon*sign_data_grad\n",
    "#   return perturbed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0709c5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_static_columns = len(static_columns)\n",
    "# num_goutallier_columns= len(goutallier_columns)\n",
    "# num_static_columns, num_goutallier_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e41405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fgsm_target_start = num_static_columns+12\n",
    "# fgsm_target_end = -num_goutallier_columns\n",
    "# fgsm_target_columns = input_columns[fgsm_target_start:fgsm_target_end]\n",
    "# fgsm_target_columns, len(fgsm_target_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f536bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 0: '6M ASES'          -> maximize\n",
    "# # 1: '6M CSS'           -> maximize\n",
    "# # 2: '6M KSS'           -> maximize\n",
    "# # 3: '6M VAS(activity)' -> minimize\n",
    "# # 4: '6M VAS(resting)'  -> minimize\n",
    "# maximize_indices = [0, 1, 2]\n",
    "# minimize_indices = [3, 4]\n",
    "\n",
    "# lambda_logits = 1.0\n",
    "# lambda_reg = 0.3\n",
    "# epsilon = 0.5\n",
    "\n",
    "# all_logits = []\n",
    "# all_regs = []\n",
    "# all_perturbed_xb = []\n",
    "# all_perturbed_logits = []\n",
    "# all_perturbed_regs = []\n",
    "\n",
    "# mlp.eval()\n",
    "# for xb, yb in val_pre_with_mean_loader:\n",
    "#   clf_targets = yb[:, :1]\n",
    "#   reg_targets = yb[:, 1:]\n",
    "\n",
    "#   xb.requires_grad = True\n",
    "#   logits, regs = mlp(xb)\n",
    "#   all_logits.append(logits.detach())\n",
    "#   all_regs.append(regs.detach())\n",
    "\n",
    "#   clf_loss = F.binary_cross_entropy_with_logits(logits, clf_targets)\n",
    "#   logits_dir_loss = -logits.mean()\n",
    "\n",
    "#   reg_inc_term = -regs[:, maximize_indices].mean()\n",
    "#   reg_dec_term = regs[:, minimize_indices].mean()\n",
    "#   reg_dir_loss = reg_inc_term + reg_dec_term\n",
    "\n",
    "#   loss = clf_loss + lambda_logits * logits_dir_loss + lambda_reg * reg_dir_loss\n",
    "\n",
    "#   mlp.zero_grad()\n",
    "#   loss.backward()\n",
    "\n",
    "#   xb_grad = xb.grad.data\n",
    "#   perturbed_xb = fgsm_attack(xb, xb_grad, epsilon)\n",
    "#   all_perturbed_xb.append(perturbed_xb.detach())\n",
    "\n",
    "#   perturbed_logits, perturbed_regs = mlp(perturbed_xb)\n",
    "#   all_perturbed_logits.append(perturbed_logits.detach())\n",
    "#   all_perturbed_regs.append(perturbed_regs.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b761ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits = torch.cat(all_logits).flatten()\n",
    "# regs = torch.cat(all_regs)\n",
    "# logits.shape, regs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce007506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perturbed_logits = torch.cat(all_perturbed_logits).flatten()\n",
    "# perturbed_regs = torch.cat(all_perturbed_regs)\n",
    "# perturbed_logits.shape, perturbed_regs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a136de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# probs = logits.sigmoid()\n",
    "# perturbed_probs = perturbed_logits.sigmoid()\n",
    "# probs.shape, perturbed_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe51f921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(label_column)\n",
    "# prob_results = pd.DataFrame({\n",
    "#   \"probability\": probs.flatten(),\n",
    "#   \"after probability\": perturbed_probs.flatten()\n",
    "# })\n",
    "# prob_results[\"delta\"] = prob_results[\"after probability\"] - prob_results[\"probability\"]\n",
    "# prob_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7476b9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e27a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_feature_results = []\n",
    "# for feature_idx in range(regs.size(1)):\n",
    "#   feature_column = output_columns[feature_idx]\n",
    "#   after_column = f\"after {feature_column}\"\n",
    "\n",
    "#   feature_results = pd.DataFrame({\n",
    "#     feature_column: regs[:, feature_idx],\n",
    "#     after_column: perturbed_regs[:, feature_idx]\n",
    "#   })\n",
    "#   feature_results[\"delta\"] = feature_results[after_column] - feature_results[feature_column]\n",
    "#   all_feature_results.append(feature_results)\n",
    "\n",
    "#   direction = \"maximize\" if feature_idx in maximize_indices else \"minimize\"\n",
    "#   print(f\"{feature_column} ({direction})\")\n",
    "#   print(feature_results)\n",
    "#   print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2d6218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feature_column, feature_results in zip(output_columns, all_feature_results):\n",
    "#   direction = \"maximize\" if feature_idx in maximize_indices else \"minimize\"\n",
    "#   print(f\"{feature_column} ({direction})\")\n",
    "#   print(feature_results.describe())\n",
    "#   print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
